{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858464162594172928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858460992073863168</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858459539296980995</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858455355948384257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  truthMedian    truthClass  truthMean\n",
       "0  858464162594172928     1.000000     clickbait   1.000000\n",
       "1  858462320779026433     0.000000  no-clickbait   0.133333\n",
       "2  858460992073863168     0.333333  no-clickbait   0.400000\n",
       "3  858459539296980995     0.333333  no-clickbait   0.266667\n",
       "4  858455355948384257     0.000000  no-clickbait   0.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_df = pd.DataFrame(columns=['id','truthMedian','truthClass','truthMean'])\n",
    "with open('data/truth.jsonl') as data:\n",
    "    for labelobj in data:\n",
    "        truth = json.loads(labelobj)\n",
    "        truthlabel = {'id': truth['id'], 'truthMedian': truth['truthMedian'], 'truthClass': truth['truthClass'], 'truthMean': truth['truthMean']}\n",
    "        truth_df = truth_df.append(truthlabel, ignore_index = True)\n",
    "truth_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>postText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>[UK’s response to modern slavery leaving victi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858421020331560960</td>\n",
       "      <td>[this is good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858368123753435136</td>\n",
       "      <td>[The \"forgotten\" Trump roast: Relive his bruta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858323428260139008</td>\n",
       "      <td>[Meet the happiest #dog in the world!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858283602626347008</td>\n",
       "      <td>[Tokyo's subway is shut down amid fears over a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           postText\n",
       "0  858462320779026433  [UK’s response to modern slavery leaving victi...\n",
       "1  858421020331560960                                     [this is good]\n",
       "2  858368123753435136  [The \"forgotten\" Trump roast: Relive his bruta...\n",
       "3  858323428260139008             [Meet the happiest #dog in the world!]\n",
       "4  858283602626347008  [Tokyo's subway is shut down amid fears over a..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_df = pd.DataFrame(columns=['id','postText'])\n",
    "with open('data/instances.jsonl') as data:\n",
    "\tfor instanceobj in data:\n",
    "\t\tinstance = json.loads(instanceobj)\n",
    "\t\tinstancerow = {'id': instance['id'], 'postText': instance['postText']}\n",
    "\t\tinstances_df = instances_df.append(instancerow, ignore_index=True)\n",
    "instances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  \\\n",
       "0  UK’s response to modern slavery leaving victim...     0.000000   \n",
       "1                                       this is good     1.000000   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...     0.333333   \n",
       "3               Meet the happiest #dog in the world!     1.000000   \n",
       "4  Tokyo's subway is shut down amid fears over an...     0.000000   \n",
       "\n",
       "     truthClass  truthMean  \n",
       "0  no-clickbait   0.133333  \n",
       "1     clickbait   1.000000  \n",
       "2  no-clickbait   0.466667  \n",
       "3     clickbait   0.933333  \n",
       "4  no-clickbait   0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = instances_df.join(truth_df.set_index('id'), on='id')\n",
    "dataset = dataset.drop(labels='id',axis=1)\n",
    "for i in range(len(dataset)):\n",
    "    dataset['postText'].values[i] = dataset['postText'].values[i][0]\n",
    "dataset['postText'].dropna(inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  UK’s response to modern slavery leaving victim...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...            1           0   \n",
       "3               Meet the happiest #dog in the world!            3           1   \n",
       "4  Tokyo's subway is shut down amid fears over an...            0           0   \n",
       "\n",
       "   truthMean  \n",
       "0   0.133333  \n",
       "1   1.000000  \n",
       "2   0.466667  \n",
       "3   0.933333  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toBinary(truthClass):\n",
    "    if truthClass == 'no-clickbait':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "dataset['truthClass'] = dataset['truthClass'].apply(toBinary)\n",
    "\n",
    "def toInteger(truthMedian):\n",
    "    return round(truthMedian*3)\n",
    "dataset['truthMedian'] = dataset['truthMedian'].apply(toInteger)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  uks response to modern slavery leaving victims...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  the forgotten trump roast relive his brutal 20...            1           0   \n",
       "3                 meet the happiest dog in the world            3           1   \n",
       "4  tokyos subway is shut down amid fears over an ...            0           0   \n",
       "\n",
       "   truthMean  \n",
       "0   0.133333  \n",
       "1   1.000000  \n",
       "2   0.466667  \n",
       "3   0.933333  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    return text\n",
    "dataset['postText'] = dataset['postText'].apply(cleanText)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_punc(postText):\n",
    "#     return len(postText)\n",
    "# dataset['numOfPunctuation'] =  dataset['postText'].apply(count_punc) - dataset['cleanPostText'].apply(count_punc)\n",
    "# dataset.drop(dataset[dataset['numOfPunctuation']>15].index , inplace = True)\n",
    "# dataset = dataset.reset_index()\n",
    "# numOfPunctuation = dataset[['numOfPunctuation']].values\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# dataset['numOfPunctuationNorm'] = min_max_scaler.fit_transform(numOfPunctuation)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.drop(['postText'],axis=1)\n",
    "# dataset = dataset.rename(columns = {'cleanPostText': 'postText'}, inplace = False)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfPunctuation']>0)])\n",
    "# non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import download\n",
    "# download('punkt')\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# def stemming(postText):\n",
    "#     ps = PorterStemmer()\n",
    "#     sentence = word_tokenize(postText)\n",
    "#     newsentence = []\n",
    "#     for word in sentence:\n",
    "#         newsentence.append(ps.stem(word))\n",
    "#     return ' '.join(newsentence)\n",
    "# dataset['stemmingPostText'] = dataset['postText'].apply(stemming)\n",
    "# #dataset['postText'] = dataset['postText'].apply(stemming)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# dataset_cb = dataset[dataset['truthClass'] == 1]\n",
    "# dataset_ncb = dataset[dataset['truthClass'] == 0]\n",
    "# cb_words_tuple = Counter(\" \".join(dataset_cb[\"stemmingPostText\"]).split()).most_common(300)\n",
    "# cb_words = [words for (words, count) in cb_words_tuple] \n",
    "# non_cb_words_tuple = Counter(\" \".join(dataset_ncb[\"stemmingPostText\"]).split()).most_common(350)\n",
    "# non_cb_words = [words for (words, count) in non_cb_words_tuple] \n",
    "# true_cb_words = []\n",
    "# for i in range(len(cb_words)):\n",
    "#     word = cb_words[i]\n",
    "#     if word not in non_cb_words[:50+i] and not word.isnumeric():\n",
    "#         true_cb_words.append(word)\n",
    "# #print(len(true_cb_words))\n",
    "# print(true_cb_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countlist = []\n",
    "# for index, row in dataset.iterrows(): \n",
    "#     words = row[\"postText\"].split()\n",
    "#     count = 0\n",
    "#     for word in words:\n",
    "#         if word in true_cb_words:\n",
    "#             count += 1 \n",
    "#     countlist.append(count)\n",
    "# dataset['clickbaitWords'] = countlist\n",
    "# numOfCbWords = dataset[['clickbaitWords']].values\n",
    "# dataset['clickbaitWordsNorm'] = min_max_scaler.fit_transform(numOfCbWords)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#clickbait titles with clickbait words] over [#clickbait title]\n",
    "# clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# clickbait_with_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['clickbaitWords']>0)])\n",
    "# clickbait_with_cb_words_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#non-clickbait titles without clickbait words] over [#non-clickbait titles]\n",
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "# non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==0) & (dataset['clickbaitWords']==0)])\n",
    "# non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numberCountlist = []\n",
    "# for index, row in dataset.iterrows(): \n",
    "#     words = row[\"postText\"].split()\n",
    "#     count = 0\n",
    "#     for word in words:\n",
    "#         if word.isnumeric():\n",
    "#             count += 1 \n",
    "#     numberCountlist.append(count)\n",
    "# dataset['numOfNumerics'] = numberCountlist\n",
    "# numOfNumerics = dataset[['numOfNumerics']].values\n",
    "# dataset['numOfNumericsNorm'] = min_max_scaler.fit_transform(numOfNumerics)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#clickbait titles with numOfnumerics words] over [#clickbait title]\n",
    "# clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfNumerics']>0)])\n",
    "# clickbait_with_numerics_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#non-clickbait titles without numOfnumerics words] over [#non-clickbait titles]\n",
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "# non_clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==0) & (dataset['numOfNumerics']>0)])\n",
    "# non_clickbait_with_numerics_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from subject_verb_object_extract import findSVOs, nlp\n",
    "# def extract(postText):\n",
    "#     tokens1 = nlp(postText)\n",
    "#     svos1 = findSVOs(tokens1)\n",
    "#     return svos1\n",
    "\n",
    "# dataset['SVO'] = dataset['postText'].apply(extract)\n",
    "# dataset.head()\n",
    "# president trump slams reporters use of anonymous sources despite using them himself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the glove word embedding file\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of titles with longest words\n",
    "maxLen = 0\n",
    "for i in range(len(dataset)):\n",
    "    sentence = dataset[\"postText\"][i]\n",
    "    if len(sentence.split()) > maxLen:\n",
    "        maxLen = len(sentence.split())\n",
    "        maxstr = sentence\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15630,)\n",
      "(3908,)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset to training and testing set\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "X_train, Y_train, Y_train_mean = np.array(train[\"postText\"].tolist()), np.array(train[\"truthMedian\"].tolist()), np.array(train[\"truthMean\"].tolist())\n",
    "# positive_test = test[test[\"truthClass\"] == 1].sample(n=900)\n",
    "# negative_test = test[test[\"truthClass\"] == 0].sample(n=900)\n",
    "# test = pd.concat([negative_test, positive_test]).sample(frac=1)\n",
    "X_test, Y_test, Y_test_mean = np.array(test[\"postText\"].tolist()), np.array(test[\"truthClass\"].tolist()), np.array(test[\"truthMean\"].tolist())\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):   \n",
    "    m = X.shape[0]  # number of training examples\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape \n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    for i in range(m):          \n",
    "        # Convert the ith training sentence in lower case and split is into words\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index.keys():\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j = j + 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train_indices =\n",
      " (15630, 25)\n"
     ]
    }
   ],
   "source": [
    "Indices = sentences_to_indices(X_train,word_to_index, maxLen)\n",
    "print(\"X_Train_indices =\\n\", Indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1        \n",
    "    # define dimensionality of your GloVe word vectors (= 50)\n",
    "    emb_dim = word_to_vec_map[\"happy\"].shape[0]      \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    # See instructions above to choose the correct shape.\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_len,emb_dim,trainable = False)\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,)) \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClickBait_LSTM(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with 2 units\n",
    "    X = Dense(4)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)  \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 25, 100)           40000100  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 25, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 40,381,032\n",
      "Trainable params: 380,932\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ClickBait_LSTM((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15630, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 4)\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "489/489 [==============================] - 11s 22ms/step - loss: 1.0356 - accuracy: 0.5417\n",
      "Epoch 2/20\n",
      "489/489 [==============================] - 11s 23ms/step - loss: 0.9679 - accuracy: 0.5690\n",
      "Epoch 3/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.9373 - accuracy: 0.5784\n",
      "Epoch 4/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.9134 - accuracy: 0.5917\n",
      "Epoch 5/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.8950 - accuracy: 0.5942\n",
      "Epoch 6/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.8749 - accuracy: 0.6093\n",
      "Epoch 7/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.8520 - accuracy: 0.6178\n",
      "Epoch 8/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.8251 - accuracy: 0.6302\n",
      "Epoch 9/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.7960 - accuracy: 0.6473\n",
      "Epoch 10/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.7572 - accuracy: 0.6589\n",
      "Epoch 11/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.7232 - accuracy: 0.6757\n",
      "Epoch 12/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.6782 - accuracy: 0.7033\n",
      "Epoch 13/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.6312 - accuracy: 0.7266\n",
      "Epoch 14/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.5975 - accuracy: 0.7452\n",
      "Epoch 15/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.5447 - accuracy: 0.7697\n",
      "Epoch 16/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.4972 - accuracy: 0.7939\n",
      "Epoch 17/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.4620 - accuracy: 0.8132\n",
      "Epoch 18/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.4174 - accuracy: 0.8360\n",
      "Epoch 19/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.3857 - accuracy: 0.8511\n",
      "Epoch 20/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.3599 - accuracy: 0.8619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2322d8cd8b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 20, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_binary(data):\n",
    "    binary = []\n",
    "    for i in range(len(data)):\n",
    "        if 2/3*data[i][3] + 1/3*data[i][2] > 2/3*data[i][0] + 1/3*data[i][1]:\n",
    "        #if data[i][3] + data[i][2] > data[i][0] + data[i][1]:\n",
    "            binary.append(1)\n",
    "        else:\n",
    "            binary.append(0)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error\n",
      "Accuracy 0.9594369801663468\n",
      "Precision 0.8833776917493347\n",
      "Recall 0.9600315540362871\n",
      "F1 score: 0.9201108870967742\n",
      "MSE 0.08625606028184069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,roc_auc_score, mean_squared_error \n",
    "y_train_pred_oh = model.predict(X_train_indices)\n",
    "y_train_pred_binary = onehot_to_binary(y_train_pred_oh)\n",
    "Y_train_binary = onehot_to_binary(Y_train_oh)\n",
    "\n",
    "print(\"Training Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_train_binary, y_train_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_train_binary, y_train_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_train_mean, y_train_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error\n",
      "Accuracy 0.8160184237461617\n",
      "Precision 0.6283566058002148\n",
      "Recall 0.6106471816283925\n",
      "F1 score: 0.6193753308628904\n",
      "MSE 0.13032070965181167\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "y_pred_onehot = model.predict(X_test_indices)\n",
    "y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "\n",
    "print(\"Testing Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_test, y_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_test, y_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_test, y_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_test, y_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_test_mean, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      2950\n",
      "           1       0.63      0.61      0.62       958\n",
      "\n",
      "    accuracy                           0.82      3908\n",
      "   macro avg       0.75      0.75      0.75      3908\n",
      "weighted avg       0.81      0.82      0.82      3908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE 0.07578300921035824\n"
     ]
    }
   ],
   "source": [
    "print('Minimum MSE %s' % mean_squared_error(Y_test_mean, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you ask chelsea handler the kardashians are responsible for trumps election\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.6216435e-02 8.9880633e-01 1.4496628e-02 4.8058660e-04]\n",
      "-------------\n",
      "derogatory remarks about women remarks on peoples upbringing  swami om has done it all biggboss\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9858838e-01 1.4102492e-03 3.5196206e-07 1.0024230e-06]\n",
      "-------------\n",
      "ryan reynolds thinks new wolverine film logan is going to change film in one big way\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7565132e-01 2.4281550e-02 4.8019228e-05 1.9089184e-05]\n",
      "-------------\n",
      "how victorias secret angels unwind after the show  vsfashionshow\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.39120394 0.59593743 0.01210014 0.00075841]\n",
      "-------------\n",
      "16 cheat sheets for if youre a foodie but also lazy af\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02613978 0.29978225 0.65054923 0.02352875]\n",
      "-------------\n",
      "seven years and 30m later we finally back our frontline troops premium\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02089571 0.8211557  0.15397197 0.00397666]\n",
      "-------------\n",
      "why manchester by the sea should win the best picture oscar\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.5430372e-01 1.4446081e-01 1.0116233e-03 2.2394230e-04]\n",
      "-------------\n",
      "an amazing deal for pc gamers assassinscreed\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02972789 0.31731763 0.6326974  0.02025708]\n",
      "-------------\n",
      "how much money does it take to make a snapchat founder disappear well\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.0318400e-02 9.4960904e-01 9.8513551e-03 2.2124007e-04]\n",
      "-------------\n",
      "the serial team is releasing a new truecrime show youll inevitably binge\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.1211940e-01 7.8103864e-01 6.5461984e-03 2.9576442e-04]\n",
      "-------------\n",
      "arkansas is racing to execute 8 men but a new hurdle may derail the plan\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.3585110e-01 6.3854180e-02 2.2162378e-04 7.3027477e-05]\n",
      "-------------\n",
      "horrific moment kneeling woman receives 100 lashes for having sex outside of marriage\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01394581 0.19340207 0.7662861  0.02636597]\n",
      "-------------\n",
      "how to dress for valentines day hold the romantic frills please writes kfinnigan premium\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.1860911e-02 9.5152855e-01 2.6105825e-02 5.0476706e-04]\n",
      "-------------\n",
      "how to ask for a promotion or pay rise  live chat\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00548368 0.03113713 0.44648474 0.51689446]\n",
      "-------------\n",
      "how bambi got its look from 1000yearold chinese art\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00396996 0.01387967 0.2809032  0.7012472 ]\n",
      "-------------\n",
      "now you can sign up for the see something say something newsletter\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02565774 0.284131   0.6711772  0.0190341 ]\n",
      "-------------\n",
      "goodbye geek glasses why aviators are this seasons biggest eyewear trend\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.01898398 0.83169085 0.1456553  0.00366986]\n",
      "-------------\n",
      "how robots could revolutionize your grocery store  via yahoofinance\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03690533 0.5301229  0.41985148 0.0131203 ]\n",
      "-------------\n",
      "about to get on a plane realdonaldtrumps revised travel ban could drop within 24 hours\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03551976 0.22115415 0.7034131  0.03991291]\n",
      "-------------\n",
      "freed chibok girls return home for a joyful christmas\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00544102 0.03461945 0.71506745 0.2448721 ]\n",
      "-------------\n",
      "why lima is the worlds best food city\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00861594 0.05261355 0.63629043 0.3024801 ]\n",
      "-------------\n",
      "cheeky chimp flips the finger at a tourist who took his picture in the forest\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00851858 0.08097012 0.85442716 0.05608417]\n",
      "-------------\n",
      "youll miss carrie fisher even more after watching ellen degeneres tribute\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.2461893e-01 5.6900656e-01 5.9276149e-03 4.4689333e-04]\n",
      "-------------\n",
      "china sentences hedge fund brother no1 to 5 and a half years in prison\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.8520273e-01 1.4770728e-02 1.5955731e-05 1.0519416e-05]\n",
      "-------------\n",
      "oil change\n",
      "rex tillersons climate change record\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [7.5957775e-01 2.3785529e-01 2.2480735e-03 3.1888965e-04]\n",
      "-------------\n",
      "why the world is worried about brazils taintedmeat probe\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03682273 0.8097212  0.14894521 0.00451091]\n",
      "-------------\n",
      "riseup \n",
      "\n",
      "an anonymous bettor placed a million dollar wager on the underdog falcons\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00943135 0.07962196 0.8574214  0.05352524]\n",
      "-------------\n",
      "analysis a conspiracy theoryspreading website now has a seat in the white house briefing room\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7414976e-01 2.5784165e-02 4.7204743e-05 1.8946519e-05]\n",
      "-------------\n",
      "valentines day is a busy time for private eyes  but not for the reason you think\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02610731 0.86055195 0.11019871 0.00314207]\n",
      "-------------\n",
      "democratic senator asks state department watchdog to probe maralago promotional material\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9078768e-01 9.1981078e-03 7.4381246e-06 6.7890569e-06]\n",
      "-------------\n",
      "trevor noahs terrifying vision of what is happening to america after trumps win\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9864024e-01 1.3584659e-03 3.2834157e-07 9.9875240e-07]\n",
      "-------------\n",
      "bank investors who havent focused on consumer credit risks in recent years should start paying attention\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.4822690e-01 6.4385706e-01 7.3881960e-03 5.2787532e-04]\n",
      "-------------\n",
      "heres an unbelievable twitter catfish story to get you through today\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00869516 0.04550463 0.46577615 0.48002407]\n",
      "-------------\n",
      "nasa engineers take a selfie with strange object that alien hunters were convinced was a ufo\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01566246 0.23248073 0.72982395 0.02203286]\n",
      "-------------\n",
      "centurylinkvoice new product launch testing the waters with social media\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.8204724e-01 6.1006904e-01 7.4054035e-03 4.7834861e-04]\n",
      "-------------\n",
      "youtubes mostviewed christmas video is a song we tried very hard to forget\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.1478846e-01 6.7897958e-01 5.8861235e-03 3.4589748e-04]\n",
      "-------------\n",
      "first read can religious leaders talk politics from the pulpit\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02327915 0.37511396 0.5848409  0.01676595]\n",
      "-------------\n",
      "singer mariahcarey performed on new years rockin eve on saturday night and it was not as anyone expected\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9843007e-01 1.5681457e-03 4.2895562e-07 1.2601407e-06]\n",
      "-------------\n",
      "here are five things trump could do quickly in financial deregulation push\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.3031533e-02 9.0038860e-01 6.3695856e-03 2.1034240e-04]\n",
      "-------------\n",
      "buddy is just trying to do him\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00391493 0.02056309 0.5379276  0.43759432]\n",
      "-------------\n",
      "could stem cells offer hope for autism\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01535376 0.33016703 0.6329098  0.02156944]\n",
      "-------------\n",
      "a ski safari in the dolomites with skiin stops for wine espresso and plenty of pasta\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0055753  0.0480978  0.82921416 0.11711276]\n",
      "-------------\n",
      "why silicon valley is so nervous about h1b reform\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02934461 0.58157414 0.37754992 0.01153136]\n",
      "-------------\n",
      "trumps phone call with taiwan president sparks china complaint\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.4522006e-01 8.4794927e-01 6.5957094e-03 2.3493393e-04]\n",
      "-------------\n",
      "burger king makes a whopper of a mess with google home ad\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.0054357e-01 8.9391840e-01 5.3727739e-03 1.6517425e-04]\n",
      "-------------\n",
      "26 texts youll understand if youve ever texted a straight guy\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00507735 0.02940999 0.64246756 0.32304516]\n",
      "-------------\n",
      "what a night nationalchampionship\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00915848 0.05663776 0.5238536  0.41035008]\n",
      "-------------\n",
      "white house social media director misused position by going after gop lawmaker ethics experts say\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7413200e-01 2.5803516e-02 4.3762837e-05 2.0666739e-05]\n",
      "-------------\n",
      "people are losing their minds over this chloë grace moretz doppelgänger\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00189311 0.00570394 0.14356528 0.8488377 ]\n",
      "-------------\n",
      "frank ocean just released another new song and people are losing it\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.4944429e-01 5.0350375e-02 1.5364158e-04 5.1742714e-05]\n",
      "-------------\n",
      "this case has done nothing but show lawyers at their worst\n",
      "\n",
      "otlonespn on the nfls concussion settlement\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00728563 0.04555056 0.653182   0.2939818 ]\n",
      "-------------\n",
      "explosive revelations by sptyagi\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.2452775e-02 9.2866051e-01 2.8161542e-02 7.2515907e-04]\n",
      "-------------\n",
      "judges may stop theresa mays brexit tomorrow\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9754262e-01 2.4549796e-03 7.8936409e-07 1.5869498e-06]\n",
      "-------------\n",
      "local mayors by sessionss definition there might not actually be sanctuary cities\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00541916 0.0371675  0.7459273  0.211486  ]\n",
      "-------------\n",
      "inventory of princes estate lists cash property and gold bars\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01403426 0.16654316 0.7917943  0.02762832]\n",
      "-------------\n",
      "7 plussize athletes talk about their life in sports\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00433154 0.02086299 0.48186126 0.49294427]\n",
      "-------------\n",
      "new on medium why every generation feels entitled\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01382788 0.13661516 0.81883806 0.0307188 ]\n",
      "-------------\n",
      "icymi the nfl mvp race is wiiiide open\n",
      "\n",
      "but a certain west coast qb is making a strong case at no 1\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.2157969e-01 1.7638184e-01 1.6089061e-03 4.2965909e-04]\n",
      "-------------\n",
      "im rich i dont give a fk\n",
      "\n",
      "footage of adrien broners arrest has been released \n",
      "\n",
      "\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7674191e-01 2.3218866e-02 2.9467958e-05 9.8029486e-06]\n",
      "-------------\n",
      "the reigning sb51 champs are looking like the most improved team of the offseason so far\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03744391 0.29014274 0.6481452  0.02426821]\n",
      "-------------\n",
      "meet the puppies drafted into this years puppy bowl\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.7080083e-02 9.6408147e-01 1.8504212e-02 3.3422731e-04]\n",
      "-------------\n",
      "of course ellen butchered raesremmurds name on tv but its pretty forgivable\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00826725 0.06833471 0.86274505 0.06065306]\n",
      "-------------\n",
      "what you need to know about devin nunes susan rice and the unmasking controversy\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.017703   0.15540007 0.78686064 0.04003631]\n",
      "-------------\n",
      "she documented her fight against ovariancancer on instagram\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00632559 0.03849221 0.55875045 0.39643174]\n",
      "-------------\n",
      "snowy hill proves to be every cars worst nightmare\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.7614521e-02 9.7060984e-01 1.1527381e-02 2.4814170e-04]\n",
      "-------------\n",
      "the fox news host sean hannity has been very upset with ted koppel this week\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.8399144e-01 1.5977485e-02 1.9248379e-05 1.1835308e-05]\n",
      "-------------\n",
      "heres why people are concerned over the closing of rikers island\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0115927  0.10196035 0.8483745  0.03807245]\n",
      "-------------\n",
      "here are 6 lgbtq events worth traveling for in 2017  via nbcout\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01069599 0.04882149 0.31161758 0.62886494]\n",
      "-------------\n",
      "presidentelect donald trump plays golf does that count as exercise\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9757725e-01 2.4204396e-03 8.1936849e-07 1.5291361e-06]\n",
      "-------------\n",
      "sakshimalik vs geetaphogat\n",
      "\n",
      "this match is totally worth a watch\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.0307441  0.49341118 0.46119955 0.01464512]\n",
      "-------------\n",
      "are you paying too much for your tax prep check this chart\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0078442  0.04295682 0.40624535 0.54295367]\n",
      "-------------\n",
      "joey badass mask off freestyle is pretty fire\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.6118471e-02 9.6982557e-01 1.3766593e-02 2.8943259e-04]\n",
      "-------------\n",
      "what we know about ubers selfdriving car crash\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02643654 0.2559406  0.6944155  0.02320731]\n",
      "-------------\n",
      "the cash me ousside girl is in kodakblack1ks new video\n",
      "\n",
      "and were all here for it\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00792816 0.05452114 0.74140775 0.196143  ]\n",
      "-------------\n",
      "testosterone gel shows no benefit for older mens memories study shows\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01263016 0.12166554 0.82084507 0.04485927]\n",
      "-------------\n",
      "heres a look back at 100 moments from obamas presidency\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.5935281e-02 9.4007492e-01 1.3634803e-02 3.5506079e-04]\n",
      "-------------\n",
      "snapchat just released a 35min video explaining why theyre worth 20b\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.4163153e-02 9.6171719e-01 1.3866309e-02 2.5339780e-04]\n",
      "-------------\n",
      "for tv series set in chicago grim facts collide with fiction\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7884047e-01 2.1109167e-02 3.2703290e-05 1.7703147e-05]\n",
      "-------------\n",
      "remembering the smell of death\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00634857 0.03659013 0.68570334 0.27135798]\n",
      "-------------\n",
      "these 5 charts illustrate the risks lurking in chinas economy\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01464607 0.10513305 0.80117273 0.0790481 ]\n",
      "-------------\n",
      "why investors may start driving harder bargains when uk companies consider refinancing\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.7037461e-01 5.2297014e-01 6.1429483e-03 5.1235070e-04]\n",
      "-------------\n",
      "heres what president trumps budget proposes to cut\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01189619 0.10045062 0.84093744 0.04671578]\n",
      "-------------\n",
      "moviereview befikre is predictable and tryinghardtobefun but is really just soppy\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01049361 0.09268639 0.8541155  0.04270456]\n",
      "-------------\n",
      "the 5 bollywood films coming out this summer that are mustsee\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00855538 0.04191208 0.2954234  0.6541092 ]\n",
      "-------------\n",
      "a great grandmother has been praying to a lord of the rings figurine for years\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.4079716  0.5839     0.00753855 0.00058992]\n",
      "-------------\n",
      "how the 20699word itunes tampcs became this years hottest graphic novel\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03510871 0.92441934 0.03951423 0.00095778]\n",
      "-------------\n",
      "the top 10 jobs among new immigrants\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00535862 0.03474027 0.7185471  0.24135399]\n",
      "-------------\n",
      "we need to stop being hysterical about turkey\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01177214 0.08834592 0.8428475  0.05703434]\n",
      "-------------\n",
      "heres how saudi arabia is keen to emulate the example of south korea\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03623883 0.49683937 0.452412   0.01450985]\n",
      "-------------\n",
      "surprise robots arent replacing humans in key areas of manufacturing\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9864239e-01 1.3563148e-03 3.1850561e-07 9.4136658e-07]\n",
      "-------------\n",
      "\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00785398 0.02665447 0.16631992 0.7991716 ]\n",
      "-------------\n",
      "donald trump just threatened toyota  but it looks like he got the facts wrong\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01211798 0.14840858 0.80550575 0.03396765]\n",
      "-------------\n",
      "watch emma stone natalie portman and more read means tweets about themselves at the oscars\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01969104 0.22235517 0.73194695 0.02600683]\n",
      "-------------\n",
      "one american town many different ways of being american\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00251379 0.00682751 0.082371   0.9082877 ]\n",
      "-------------\n",
      "11 amazing facts you didnt know about your skin\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00959459 0.04234138 0.2738511  0.6742129 ]\n",
      "-------------\n",
      "this 1 million watch is made of genuine swiss cheese\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01044834 0.05336207 0.36983147 0.5663581 ]\n",
      "-------------\n",
      "the atampttime warner merger isnt a horizontal merger and shouldnt be critiqued as such\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01992594 0.3607297  0.6023795  0.01696487]\n",
      "-------------\n",
      "these tips will keep you in the holiday spirit even if your flight is delayed\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00760646 0.03914486 0.31807283 0.6351758 ]\n",
      "-------------\n",
      "recipe swap share your blue cheese recipes  via guardiancook\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02101291 0.27525187 0.68503493 0.01870031]\n",
      "-------------\n",
      "10 tech trends that will dominate ces 2017\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [5.7798494e-02 9.1326308e-01 2.8074751e-02 8.6373900e-04]\n",
      "-------------\n",
      "apple said to be secretly working on diabetes holy grail\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9904329e-01 9.5575739e-04 1.8178577e-07 7.1082133e-07]\n",
      "-------------\n",
      "bitcoin is spiking\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00489875 0.0351002  0.8098987  0.1501024 ]\n",
      "-------------\n",
      "how trumps proposed social security payroll tax cut can kill the retirement benefit\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01727923 0.21380006 0.74626774 0.02265306]\n",
      "-------------\n",
      "the worlds bestyielding stock market is set to get even better\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03586351 0.9255224  0.0376125  0.00100168]\n",
      "-------------\n",
      "tygas apparently being sued for telling his crew to beat up a process server\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01357108 0.11534265 0.83432144 0.03676483]\n",
      "-------------\n",
      "mexican vigilantes amputate suspected thiefs hand\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9779105e-01 2.2068631e-03 6.9196926e-07 1.3975925e-06]\n",
      "-------------\n",
      "the rainbow people who meet around the world for meditations and naked gatherings\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.3737063e-02 9.5991755e-01 6.2220572e-03 1.2337309e-04]\n",
      "-------------\n",
      "these are the worlds most innovative economies\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.04304114 0.35439688 0.5712456  0.03131638]\n",
      "-------------\n",
      "my child is not required to share with yours\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03508686 0.83010215 0.13049832 0.00431264]\n",
      "-------------\n",
      "trumps closest advisor thinks there will be a war with china in a few years\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7357821e-01 2.6359184e-02 4.4806613e-05 1.7718157e-05]\n",
      "-------------\n",
      "ergo we need to create economic opportunities to prevent radicalization or something\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0270069  0.38705403 0.57079357 0.01514555]\n",
      "-------------\n",
      "four ways noaa benefits your life today\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00921885 0.08022739 0.85828435 0.05226935]\n",
      "-------------\n",
      "but last week she said we didnt need evidence did putin get to her\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.0978369e-02 8.8615358e-01 2.1995947e-02 8.7203353e-04]\n",
      "-------------\n",
      "the quest to pull off an alaskan oil miracle\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02678687 0.6708807  0.29421526 0.00811719]\n",
      "-------------\n",
      "it should be impossible to make jon snow looknot great but this game of throne statue pulls it off\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.6468183  0.3434746  0.00870615 0.00100095]\n",
      "-------------\n",
      "they call me mr glass house\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.1498234  0.5635788  0.26555094 0.0210468 ]\n",
      "-------------\n",
      "psst hey lefties he paved the way for celebrity presidencies\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.8762782e-02 9.5259565e-01 8.3845761e-03 2.5702696e-04]\n",
      "-------------\n",
      "sleeping passenger awakens to her headphones exploding during flight\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02658438 0.37610668 0.5802489  0.01706001]\n",
      "-------------\n",
      "florida high school flier tells women which prom dress makes them a good girl\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01960129 0.32240415 0.63535845 0.02263609]\n",
      "-------------\n",
      "is unicef helping all the child victims of peacekeeper sex abuse\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02535846 0.9298586  0.04371911 0.00106379]\n",
      "-------------\n",
      "so ericholder got real today about republicans who are trying to make it harder to vote  lpolgreen\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00811065 0.05233769 0.76172006 0.17783171]\n",
      "-------------\n",
      "these pictures of homeless people sleeping in empty graves sent shockwaves across iran\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01157446 0.09921536 0.8003709  0.08883931]\n",
      "-------------\n",
      "people like her make the world better hats off to her and her dog for saving lives\n",
      "respect humanity\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9836093e-01 1.6374342e-03 4.4912866e-07 1.1447845e-06]\n",
      "-------------\n",
      "european debt crisis its not just greece thats drowning in debt\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.0315839  0.71433234 0.24569395 0.0083898 ]\n",
      "-------------\n",
      "spanish uk resident feared insurance rule would force her to leave\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9379772e-01 6.1944090e-03 3.5460957e-06 4.2124179e-06]\n",
      "-------------\n",
      "these spring beauty launches are loved by katy perry jlo amp more\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03165318 0.7451264  0.21733093 0.0058895 ]\n",
      "-------------\n",
      "haunting photos show how rundown the abandoned detroit lions stadium has become\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02296746 0.22421466 0.72706    0.02575784]\n",
      "-------------\n",
      "jobs added in november more\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00362925 0.01911717 0.5226723  0.4545813 ]\n",
      "-------------\n",
      "a danish official cuts cake to celebrate an antiimmigration law but not everyone joins the party\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02745339 0.72512007 0.2409051  0.00652147]\n",
      "-------------\n",
      "to accept one and to hate the other would be racist no\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03947458 0.73501533 0.2183931  0.00711702]\n",
      "-------------\n",
      "how to live and learn from great loss\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02319142 0.2661964  0.6896628  0.0209494 ]\n",
      "-------------\n",
      "everyone loves bernie sanders except it seems the democratic party  trevor timm\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.6225863e-01 8.2275784e-01 1.4404570e-02 5.7899306e-04]\n",
      "-------------\n",
      "a max deal forjrue holiday thats how crazy free agency could get this year\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01294198 0.09720214 0.8234752  0.06638071]\n",
      "-------------\n",
      "bill maher just made a very serious point about the trump circus  by leemoran\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.3803910e-02 9.6053809e-01 5.5382974e-03 1.1969489e-04]\n",
      "-------------\n",
      "remembering whams last christmas on christmas day ripgeorgemichael\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00584907 0.03116644 0.5746559  0.3883287 ]\n",
      "-------------\n",
      "heres the best piece of advice sal khan received from bill gates\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01380664 0.13417791 0.81876266 0.03325283]\n",
      "-------------\n",
      "juicero and united two real time case studies in crisis pr for entrepreneurs\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.2448394e-01 7.6896095e-01 6.2518106e-03 3.0336634e-04]\n",
      "-------------\n",
      "irs phone scammers are getting more sophisticated\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00600721 0.03557146 0.66716665 0.2912546 ]\n",
      "-------------\n",
      "this woman found her tweenage time capsule from 1998 and its magical\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02127656 0.19169793 0.759817   0.02720851]\n",
      "-------------\n",
      "mystery of ancient egyptian legs likely solved theyre queen nefertaris knees\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00838842 0.07650797 0.8551559  0.0599477 ]\n",
      "-------------\n",
      "bird flu detected at chicken breeding facility in tennessee agriculture officials say\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9877375e-01 1.2250934e-03 2.9453074e-07 1.0001174e-06]\n",
      "-------------\n",
      "daylight saving time begins this weekend here are some tips for surviving the switch\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.7730677e-02 9.4444782e-01 7.6474082e-03 1.7420440e-04]\n",
      "-------------\n",
      "charles oakley still hates charles barkley as this savage tweet shows \n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.5584022e-02 9.1009712e-01 4.1878098e-03 1.3103934e-04]\n",
      "-------------\n",
      "135 films got a certificate from censor board\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04052787 0.48052132 0.46266195 0.01628884]\n",
      "-------------\n",
      "easter violence fugitive purportedly writes letter threatening churches\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.9933296e-01 4.9524057e-01 4.9624648e-03 4.6390039e-04]\n",
      "-------------\n",
      "people are so inspired by this restaurant giving away free meals\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00777827 0.0513232  0.7114196  0.22947897]\n",
      "-------------\n",
      "americas police are embracing drones could they soon be armed\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.5177011e-01 7.4089044e-01 7.0161885e-03 3.2325753e-04]\n",
      "-------------\n",
      "google ordered to explain why taxpayerfunded adverts appear alongside extremist material\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02348051 0.23534253 0.71973735 0.0214396 ]\n",
      "-------------\n",
      "january 9 is the day people are most likely to try and start an affair\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00650663 0.05186218 0.80767065 0.13396049]\n",
      "-------------\n",
      "how to tame frizzy hair the products that actually work\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01318311 0.12121684 0.83030736 0.03529267]\n",
      "-------------\n",
      "i sat in peugeots instinct concept car and it told me to relax\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01181236 0.09668077 0.8376207  0.05388612]\n",
      "-------------\n",
      "parents are furious at this bestselling author for buying 23600 worth of hatchimals\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03591062 0.84542376 0.11526097 0.00340473]\n",
      "-------------\n",
      "the exodus of oilprice optimists has begun as oil remains below 50 a barrel\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01677319 0.35130453 0.6097823  0.02214008]\n",
      "-------------\n",
      "this country just made ever citizen an organ donor unless they opt out\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.7830517e-01 7.1417356e-01 7.1431785e-03 3.7810486e-04]\n",
      "-------------\n",
      "uber gives restless employees a way to cash out\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.9794613e-02 9.0630639e-01 3.7749980e-03 1.2394592e-04]\n",
      "-------------\n",
      "hes the selfproclaimed biggest bust ever but for the first time in a long time greg odens life has direction\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02917458 0.19427153 0.70654553 0.0700084 ]\n",
      "-------------\n",
      "this is why most uk cops dont carry guns\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0055553  0.03025392 0.64492244 0.31926832]\n",
      "-------------\n",
      "this khloé kardashian campaign finally strips empowerment of all meaning  phoebejane boyd\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02133522 0.89654034 0.0802432  0.00188125]\n",
      "-------------\n",
      "the european countries where huge amounts of the population have moved\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00640179 0.0315448  0.4079226  0.55413085]\n",
      "-------------\n",
      "trump hasnt really stopped american jobs going to mexico\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01324835 0.16706884 0.79087186 0.02881086]\n",
      "-------------\n",
      "bambi rescued from frozen lake\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.2015007e-02 9.6239132e-01 5.4511297e-03 1.4260938e-04]\n",
      "-------------\n",
      "5 things for tuesday\n",
      "\n",
      " health care\n",
      " immigration\n",
      " north korea\n",
      " layoffs\n",
      " monuments\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00612882 0.04605868 0.7911055  0.156707  ]\n",
      "-------------\n",
      "everything we know and all that we dont know about the snap general election\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02118342 0.23156145 0.7213173  0.0259378 ]\n",
      "-------------\n",
      "mustsee video car slides off edge of moving ferry into open waters\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [5.3085856e-02 9.4315362e-01 3.6683190e-03 9.2210175e-05]\n",
      "-------------\n",
      "who should win the grammy for album of the year vote\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03386069 0.760378   0.20014253 0.00561873]\n",
      "-------------\n",
      "an alcoholfueled obscenity and racial slurlaced tirade have cost a miami senator his job\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.2920398e-02 9.6782225e-01 9.0715121e-03 1.8589052e-04]\n",
      "-------------\n",
      "tis the biggest season ever to set up a charitable giving account\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01955447 0.22142309 0.73547894 0.0235435 ]\n",
      "-------------\n",
      "lady gaga shows companies how to make a comeback\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02646576 0.49905473 0.46073428 0.01374521]\n",
      "-------------\n",
      "presenting the 30under30 in sports\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.0174756e-02 9.4766349e-01 1.1791438e-02 3.7045241e-04]\n",
      "-------------\n",
      "an economic surprise index is at a threeyear highwhy that is a warning sign for stocks\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.4291550e-01 5.6840055e-02 1.9030819e-04 5.4186075e-05]\n",
      "-------------\n",
      "ochziffs once highflying deal maker faces bribery charges\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00564859 0.05055842 0.8157712  0.12802176]\n",
      "-------------\n",
      "1 in 4 millennials living at home dont work or study \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02086373 0.45091537 0.5109098  0.0173111 ]\n",
      "-------------\n",
      "oh jeff bruh\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0048737  0.01558286 0.13628983 0.8432537 ]\n",
      "-------------\n",
      "twenty one pilots accepted their grammy in their underwear\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0224105  0.3608496  0.5983846  0.01835526]\n",
      "-------------\n",
      "why a rising numbers of criminals are using facebook live to film their acts\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00861189 0.05147311 0.59632325 0.34359172]\n",
      "-------------\n",
      "these are the lives that obamacare helped save\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01017803 0.0604761  0.55662686 0.3727191 ]\n",
      "-------------\n",
      "tourist who took camera inside north korea is shocked to discover a happy country\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.41606492 0.5738236  0.00950458 0.00060691]\n",
      "-------------\n",
      "sebastian gorka likes to be called dr gorka he gets his way only in conservative media\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7868627e-01 2.1264428e-02 3.3431952e-05 1.5791849e-05]\n",
      "-------------\n",
      "paragon of beauty\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02239517 0.67225885 0.2958961  0.00944988]\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Error Analysis\n",
    "for i in range(1000):\n",
    "    if Y_test[i] - y_pred_binary[i] != 0:\n",
    "        print(X_test[i])\n",
    "        print(\"Actual Label\",Y_test[i])\n",
    "        print(\"Prediction Lable\",y_pred_binary[i])\n",
    "        print(\"Prediction\",y_pred_onehot[i])\n",
    "        print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(test_string):\n",
    "    test_string = cleanText(test_string)\n",
    "    test = np.array([test_string])\n",
    "    test_indices = sentences_to_indices(test, word_to_index, max_len = maxLen)\n",
    "    y_pred_onehot = model.predict(test_indices)\n",
    "    y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "    if y_pred_binary == [1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "test_string = \"US election 2020: What is the presidential transition\"\n",
    "test(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
