{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858464162594172928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858460992073863168</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858459539296980995</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858455355948384257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  truthMedian    truthClass  truthMean\n",
       "0  858464162594172928     1.000000     clickbait   1.000000\n",
       "1  858462320779026433     0.000000  no-clickbait   0.133333\n",
       "2  858460992073863168     0.333333  no-clickbait   0.400000\n",
       "3  858459539296980995     0.333333  no-clickbait   0.266667\n",
       "4  858455355948384257     0.000000  no-clickbait   0.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_df = pd.DataFrame(columns=['id','truthMedian','truthClass','truthMean'])\n",
    "with open('data/truth.jsonl') as data:\n",
    "    for labelobj in data:\n",
    "        truth = json.loads(labelobj)\n",
    "        truthlabel = {'id': truth['id'], 'truthMedian': truth['truthMedian'], 'truthClass': truth['truthClass'], 'truthMean': truth['truthMean']}\n",
    "        truth_df = truth_df.append(truthlabel, ignore_index = True)\n",
    "truth_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>postText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>[UK’s response to modern slavery leaving victi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858421020331560960</td>\n",
       "      <td>[this is good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858368123753435136</td>\n",
       "      <td>[The \"forgotten\" Trump roast: Relive his bruta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858323428260139008</td>\n",
       "      <td>[Meet the happiest #dog in the world!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858283602626347008</td>\n",
       "      <td>[Tokyo's subway is shut down amid fears over a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           postText\n",
       "0  858462320779026433  [UK’s response to modern slavery leaving victi...\n",
       "1  858421020331560960                                     [this is good]\n",
       "2  858368123753435136  [The \"forgotten\" Trump roast: Relive his bruta...\n",
       "3  858323428260139008             [Meet the happiest #dog in the world!]\n",
       "4  858283602626347008  [Tokyo's subway is shut down amid fears over a..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_df = pd.DataFrame(columns=['id','postText'])\n",
    "with open('data/instances.jsonl') as data:\n",
    "\tfor instanceobj in data:\n",
    "\t\tinstance = json.loads(instanceobj)\n",
    "\t\tinstancerow = {'id': instance['id'], 'postText': instance['postText']}\n",
    "\t\tinstances_df = instances_df.append(instancerow, ignore_index=True)\n",
    "instances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  \\\n",
       "0  UK’s response to modern slavery leaving victim...     0.000000   \n",
       "1                                       this is good     1.000000   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...     0.333333   \n",
       "3               Meet the happiest #dog in the world!     1.000000   \n",
       "4  Tokyo's subway is shut down amid fears over an...     0.000000   \n",
       "\n",
       "     truthClass  truthMean  \n",
       "0  no-clickbait   0.133333  \n",
       "1     clickbait   1.000000  \n",
       "2  no-clickbait   0.466667  \n",
       "3     clickbait   0.933333  \n",
       "4  no-clickbait   0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = instances_df.join(truth_df.set_index('id'), on='id')\n",
    "dataset = dataset.drop(labels='id',axis=1)\n",
    "for i in range(len(dataset)):\n",
    "    dataset['postText'].values[i] = dataset['postText'].values[i][0]\n",
    "dataset['postText'].dropna(inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  UK’s response to modern slavery leaving victim...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...            1           0   \n",
       "3               Meet the happiest #dog in the world!            3           1   \n",
       "4  Tokyo's subway is shut down amid fears over an...            0           0   \n",
       "\n",
       "   truthMean  \n",
       "0   0.133333  \n",
       "1   1.000000  \n",
       "2   0.466667  \n",
       "3   0.933333  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toBinary(truthClass):\n",
    "    if truthClass == 'no-clickbait':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "dataset['truthClass'] = dataset['truthClass'].apply(toBinary)\n",
    "\n",
    "def toInteger(truthMedian):\n",
    "    return round(truthMedian*3)\n",
    "dataset['truthMedian'] = dataset['truthMedian'].apply(toInteger)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  uks response to modern slavery leaving victims...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  the forgotten trump roast relive his brutal 20...            1           0   \n",
       "3                 meet the happiest dog in the world            3           1   \n",
       "4  tokyos subway is shut down amid fears over an ...            0           0   \n",
       "\n",
       "   truthMean  \n",
       "0   0.133333  \n",
       "1   1.000000  \n",
       "2   0.466667  \n",
       "3   0.933333  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    return text\n",
    "dataset['postText'] = dataset['postText'].apply(cleanText)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_punc(postText):\n",
    "#     return len(postText)\n",
    "# dataset['numOfPunctuation'] =  dataset['postText'].apply(count_punc) - dataset['cleanPostText'].apply(count_punc)\n",
    "# dataset.drop(dataset[dataset['numOfPunctuation']>15].index , inplace = True)\n",
    "# dataset = dataset.reset_index()\n",
    "# numOfPunctuation = dataset[['numOfPunctuation']].values\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# dataset['numOfPunctuationNorm'] = min_max_scaler.fit_transform(numOfPunctuation)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.drop(['postText'],axis=1)\n",
    "# dataset = dataset.rename(columns = {'cleanPostText': 'postText'}, inplace = False)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfPunctuation']>0)])\n",
    "# non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import download\n",
    "# download('punkt')\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# def stemming(postText):\n",
    "#     ps = PorterStemmer()\n",
    "#     sentence = word_tokenize(postText)\n",
    "#     newsentence = []\n",
    "#     for word in sentence:\n",
    "#         newsentence.append(ps.stem(word))\n",
    "#     return ' '.join(newsentence)\n",
    "# dataset['stemmingPostText'] = dataset['postText'].apply(stemming)\n",
    "# #dataset['postText'] = dataset['postText'].apply(stemming)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# dataset_cb = dataset[dataset['truthClass'] == 1]\n",
    "# dataset_ncb = dataset[dataset['truthClass'] == 0]\n",
    "# cb_words_tuple = Counter(\" \".join(dataset_cb[\"stemmingPostText\"]).split()).most_common(300)\n",
    "# cb_words = [words for (words, count) in cb_words_tuple] \n",
    "# non_cb_words_tuple = Counter(\" \".join(dataset_ncb[\"stemmingPostText\"]).split()).most_common(350)\n",
    "# non_cb_words = [words for (words, count) in non_cb_words_tuple] \n",
    "# true_cb_words = []\n",
    "# for i in range(len(cb_words)):\n",
    "#     word = cb_words[i]\n",
    "#     if word not in non_cb_words[:50+i] and not word.isnumeric():\n",
    "#         true_cb_words.append(word)\n",
    "# #print(len(true_cb_words))\n",
    "# print(true_cb_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countlist = []\n",
    "# for index, row in dataset.iterrows(): \n",
    "#     words = row[\"postText\"].split()\n",
    "#     count = 0\n",
    "#     for word in words:\n",
    "#         if word in true_cb_words:\n",
    "#             count += 1 \n",
    "#     countlist.append(count)\n",
    "# dataset['clickbaitWords'] = countlist\n",
    "# numOfCbWords = dataset[['clickbaitWords']].values\n",
    "# dataset['clickbaitWordsNorm'] = min_max_scaler.fit_transform(numOfCbWords)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#clickbait titles with clickbait words] over [#clickbait title]\n",
    "# clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# clickbait_with_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['clickbaitWords']>0)])\n",
    "# clickbait_with_cb_words_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#non-clickbait titles without clickbait words] over [#non-clickbait titles]\n",
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "# non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==0) & (dataset['clickbaitWords']==0)])\n",
    "# non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numberCountlist = []\n",
    "# for index, row in dataset.iterrows(): \n",
    "#     words = row[\"postText\"].split()\n",
    "#     count = 0\n",
    "#     for word in words:\n",
    "#         if word.isnumeric():\n",
    "#             count += 1 \n",
    "#     numberCountlist.append(count)\n",
    "# dataset['numOfNumerics'] = numberCountlist\n",
    "# numOfNumerics = dataset[['numOfNumerics']].values\n",
    "# dataset['numOfNumericsNorm'] = min_max_scaler.fit_transform(numOfNumerics)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#clickbait titles with numOfnumerics words] over [#clickbait title]\n",
    "# clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfNumerics']>0)])\n",
    "# clickbait_with_numerics_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#non-clickbait titles without numOfnumerics words] over [#non-clickbait titles]\n",
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "# non_clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==0) & (dataset['numOfNumerics']>0)])\n",
    "# non_clickbait_with_numerics_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from subject_verb_object_extract import findSVOs, nlp\n",
    "# def extract(postText):\n",
    "#     tokens1 = nlp(postText)\n",
    "#     svos1 = findSVOs(tokens1)\n",
    "#     return svos1\n",
    "\n",
    "# dataset['SVO'] = dataset['postText'].apply(extract)\n",
    "# dataset.head()\n",
    "# president trump slams reporters use of anonymous sources despite using them himself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the glove word embedding file\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of titles with longest words\n",
    "maxLen = 0\n",
    "for i in range(len(dataset)):\n",
    "    sentence = dataset[\"postText\"][i]\n",
    "    if len(sentence.split()) > maxLen:\n",
    "        maxLen = len(sentence.split())\n",
    "        maxstr = sentence\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15630,)\n",
      "(3908,)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset to training and testing set\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "X_train, Y_train, Y_train_mean = np.array(train[\"postText\"].tolist()), np.array(train[\"truthMedian\"].tolist()), np.array(train[\"truthMean\"].tolist())\n",
    "# positive_test = test[test[\"truthClass\"] == 1].sample(n=900)\n",
    "# negative_test = test[test[\"truthClass\"] == 0].sample(n=900)\n",
    "# test = pd.concat([negative_test, positive_test]).sample(frac=1)\n",
    "X_test, Y_test, Y_test_mean = np.array(test[\"postText\"].tolist()), np.array(test[\"truthClass\"].tolist()), np.array(test[\"truthMean\"].tolist())\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):   \n",
    "    m = X.shape[0]  # number of training examples\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape \n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    for i in range(m):          \n",
    "        # Convert the ith training sentence in lower case and split is into words\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index.keys():\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j = j + 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train_indices =\n",
      " (15630, 25)\n"
     ]
    }
   ],
   "source": [
    "Indices = sentences_to_indices(X_train,word_to_index, maxLen)\n",
    "print(\"X_Train_indices =\\n\", Indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1        \n",
    "    # define dimensionality of your GloVe word vectors (= 50)\n",
    "    emb_dim = word_to_vec_map[\"happy\"].shape[0]      \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    # See instructions above to choose the correct shape.\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_len,emb_dim,trainable = False)\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,)) \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClickBait_LSTM(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with 2 units\n",
    "    X = Dense(4)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)  \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 25, 100)           40000100  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 25, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 40,381,032\n",
      "Trainable params: 380,932\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ClickBait_LSTM((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15630, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 4)\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "489/489 [==============================] - 10s 21ms/step - loss: 1.0395 - accuracy: 0.5445\n",
      "Epoch 2/20\n",
      "489/489 [==============================] - 11s 22ms/step - loss: 0.9708 - accuracy: 0.5698\n",
      "Epoch 3/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.9426 - accuracy: 0.5785\n",
      "Epoch 4/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.9195 - accuracy: 0.5870\n",
      "Epoch 5/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.9026 - accuracy: 0.5970\n",
      "Epoch 6/20\n",
      "489/489 [==============================] - 11s 23ms/step - loss: 0.8823 - accuracy: 0.6062\n",
      "Epoch 7/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.8580 - accuracy: 0.6175\n",
      "Epoch 8/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.8314 - accuracy: 0.6317\n",
      "Epoch 9/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.8001 - accuracy: 0.6430\n",
      "Epoch 10/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.7593 - accuracy: 0.6644\n",
      "Epoch 11/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.7306 - accuracy: 0.6814\n",
      "Epoch 12/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.6837 - accuracy: 0.7069\n",
      "Epoch 13/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.6371 - accuracy: 0.7306\n",
      "Epoch 14/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.5952 - accuracy: 0.7541\n",
      "Epoch 15/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.5526 - accuracy: 0.7724\n",
      "Epoch 16/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.5001 - accuracy: 0.8009\n",
      "Epoch 17/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.4610 - accuracy: 0.8178\n",
      "Epoch 18/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.4246 - accuracy: 0.8411\n",
      "Epoch 19/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.3772 - accuracy: 0.8593\n",
      "Epoch 20/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.3487 - accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17544c0e820>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 20, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_binary(data):\n",
    "    binary = []\n",
    "    for i in range(len(data)):\n",
    "        if 2/3*data[i][3] + 1/3*data[i][2] > 2/3*data[i][0] + 1/3*data[i][1]:\n",
    "        #if data[i][3] + data[i][2] > data[i][0] + data[i][1]:\n",
    "            binary.append(1)\n",
    "        else:\n",
    "            binary.append(0)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error\n",
      "Accuracy 0.9635956493921946\n",
      "Precision 0.9104328246184639\n",
      "Recall 0.9451948051948051\n",
      "F1 score: 0.9274882120555625\n",
      "MSE 0.08427610719961573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,roc_auc_score, mean_squared_error \n",
    "y_train_pred_oh = model.predict(X_train_indices)\n",
    "y_train_pred_binary = onehot_to_binary(y_train_pred_oh)\n",
    "Y_train_binary = onehot_to_binary(Y_train_oh)\n",
    "\n",
    "print(\"Training Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_train_binary, y_train_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_train_binary, y_train_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_train_mean, y_train_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error\n",
      "Accuracy 0.8208802456499488\n",
      "Precision 0.6163175303197354\n",
      "Recall 0.6136114160263447\n",
      "F1 score: 0.614961496149615\n",
      "MSE 0.13032412145655475\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "y_pred_onehot = model.predict(X_test_indices)\n",
    "y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "\n",
    "print(\"Testing Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_test, y_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_test, y_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_test, y_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_test, y_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_test_mean, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE 0.07692937563768065\n"
     ]
    }
   ],
   "source": [
    "print('Minimum MSE %s' % mean_squared_error(Y_test_mean, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the worlds strangest graveyards where unwanted products are left to rot\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01158964 0.07142603 0.6544437  0.26254067]\n",
      "-------------\n",
      "22 selfmade women who are the literal definition of black girl magic\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00264837 0.03426594 0.86107236 0.10201339]\n",
      "-------------\n",
      "chris pratt officially weighs in on that jurassic world theory\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.8023100e-02 9.5949054e-01 2.2322901e-02 1.6348090e-04]\n",
      "-------------\n",
      "paragon of beauty\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.0087670e-01 9.8332487e-02 4.5912486e-04 3.3176862e-04]\n",
      "-------------\n",
      "the top books of 2016 the timess critics make their picks\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.01861162 0.5363944  0.4355391  0.00945487]\n",
      "-------------\n",
      "their childhoods shouldnt be owned readers on children and social media\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.01529475 0.7402391  0.24178278 0.00268331]\n",
      "-------------\n",
      "watch gorillaz debut new humanz album in its entirety at secret show\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9745351e-01 2.5274239e-03 1.1862347e-06 1.7890723e-05]\n",
      "-------------\n",
      "a machine that used to be considered punishment is now a 14 billion fitness industry\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.8110723e-01 1.8810652e-02 2.5128211e-05 5.6908113e-05]\n",
      "-------------\n",
      "newtgingrich all real evidence of russian influence points to democrats\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00321046 0.10262229 0.87385267 0.02031454]\n",
      "-------------\n",
      "clever students smoke more weed\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00395586 0.07705805 0.8771276  0.04185844]\n",
      "-------------\n",
      "elon musks new venture could link brains with computers\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9234349e-01 7.5907717e-03 8.1566423e-06 5.7667054e-05]\n",
      "-------------\n",
      "money managers all agree one trade is really crowded but theyre loading up on it anyway\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.68979514 0.3057798  0.00341527 0.00100984]\n",
      "-------------\n",
      "david pogue tested 47 pillreminder apps to find the best  via yahoofinance\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.18557380e-02 9.66263294e-01 1.17909275e-02 9.01240564e-05]\n",
      "-------------\n",
      "a somali hijabi model walked for kanyes yeezy fashion line and it was badass af\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.98992205e-02 9.34782147e-01 1.51029425e-02 2.15593143e-04]\n",
      "-------------\n",
      "hoops wheels and moose heads playtime in the worlds most inhospitable places\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.6692856e-02 9.5740736e-01 1.5759114e-02 1.4076008e-04]\n",
      "-------------\n",
      "this gay man responded to a cruel tweet about him in the best way\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00738619 0.02601917 0.37619346 0.5904012 ]\n",
      "-------------\n",
      "these states are celebrating confederate memorial day on monday\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.8283110e-01 1.1593019e-01 7.0991402e-04 5.2869885e-04]\n",
      "-------------\n",
      "two men shoot giant fireworks at each other for fun\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.0083659  0.59597117 0.392236   0.00342699]\n",
      "-------------\n",
      "the experts have weighed in with their marchmadness picks and we take a look\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01030129 0.12211904 0.79293084 0.07464878]\n",
      "-------------\n",
      "nba player manages to make 500000 by refusing to shoot during teams final 4 games\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.00934328 0.570432   0.41662323 0.00360144]\n",
      "-------------\n",
      "this school bus driver saw a little boy without any gloves and decided to act\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.66195095 0.31892782 0.01290617 0.00621503]\n",
      "-------------\n",
      "do electors have to vote according to popular vote results in their states not necessarily\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01293104 0.29516217 0.67413735 0.01776939]\n",
      "-------------\n",
      "can you spot the hidden artist\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00913956 0.01102951 0.11686692 0.862964  ]\n",
      "-------------\n",
      "the best countries to visit with cheap currencies\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.3729374e-02 9.4220126e-01 2.3790661e-02 2.7880844e-04]\n",
      "-------------\n",
      "this japanese couple have been married for 37 years and wear matching outfits every day\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00856945 0.0323201  0.524039   0.4350715 ]\n",
      "-------------\n",
      "shocking school van driver raped children in his car\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.4811790e-02 8.9328653e-01 1.1629965e-02 2.7176578e-04]\n",
      "-------------\n",
      "one tokyo restaurants success and failure is decided by pandas having sex\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.8084433e-02 9.5129102e-01 3.0389287e-02 2.3522951e-04]\n",
      "-------------\n",
      "trump supporter cancels womans airbnb reservation because shes asian\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0022955  0.05628112 0.91135824 0.03006519]\n",
      "-------------\n",
      "talkingcar safety mandate hits unexpected opposition\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.1743680e-02 9.6463394e-01 2.3493111e-02 1.2926236e-04]\n",
      "-------------\n",
      "astonishing amazon anumeric people whose language has no words for numbers\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02293676 0.07299472 0.47921485 0.4248537 ]\n",
      "-------------\n",
      "theres a new slogan for brexit\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0182699  0.02426671 0.12335706 0.8341063 ]\n",
      "-------------\n",
      "icymi heres what you need to know about americas strike on syria\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.21055144 0.66872996 0.10777505 0.01294353]\n",
      "-------------\n",
      "four players to watch in the ncaa tournament\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00536425 0.15012565 0.8218072  0.02270285]\n",
      "-------------\n",
      "this is the brilliance your cable bill pays for\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04751838 0.85213435 0.09813568 0.00221164]\n",
      "-------------\n",
      "watch keitholbermann call realdonaldtrump a jackass 27 times\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00315465 0.05252329 0.8893991  0.05492287]\n",
      "-------------\n",
      "an unruly couple forced their flight to turn back police boarded and passengers cheered\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00232224 0.04784455 0.90842134 0.04141183]\n",
      "-------------\n",
      "reporter instantly regrets attempting to broadcast beside a large puddle\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.8968853e-01 8.0107456e-01 8.8678943e-03 3.6899961e-04]\n",
      "-------------\n",
      "justin theroux just posted a pic for jennifer anistons birthday and our hearts are melting\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.68866706e-01 3.09519283e-02 6.89104127e-05 1.12374626e-04]\n",
      "-------------\n",
      "1futures hndrxx on pace for no 1 debut\n",
      "\n",
      "whats your favorite track\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.0426485e-02 9.5817286e-01 3.1234911e-02 1.6569956e-04]\n",
      "-------------\n",
      "terrifying big chicken is scaring the internet\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00504032 0.18483026 0.7951707  0.01495872]\n",
      "-------------\n",
      "tribal consumerism is here to stay\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [5.5335425e-02 9.3070036e-01 1.3761039e-02 2.0326908e-04]\n",
      "-------------\n",
      "in his new book keithlaw says every baseball fan can agree on at least one thing\n",
      "\n",
      "the sac bunt is stupid\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.05015697 0.14216082 0.62151265 0.18616955]\n",
      "-------------\n",
      "the year in pictures\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.7361080e-02 9.4031340e-01 4.1983750e-02 3.4181442e-04]\n",
      "-------------\n",
      "lemonade just turned 1 lets remember how it blew us all away when we first listened to it\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00150901 0.01135622 0.8214074  0.16572736]\n",
      "-------------\n",
      "5 andradaymusic songs you should know womeninmusic\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01345634 0.01828732 0.14176224 0.82649416]\n",
      "-------------\n",
      "moment woman is struck by lightning on beach in brazil\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.6630618e-02 9.1063547e-01 6.2012870e-02 7.2111317e-04]\n",
      "-------------\n",
      "in front of a bluffer you always have to maintain a firm and dignified position one mexican legislator said\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00871406 0.11661164 0.81736803 0.05730626]\n",
      "-------------\n",
      "the article 50 case isnt gina millers first fight  and shes not afraid of making enemies\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00772746 0.0543618  0.7317254  0.20618542]\n",
      "-------------\n",
      "a detained iraqi refugee just delivered a stunning lesson on americas values to donald trump\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.00931155 0.73135    0.25762644 0.00171195]\n",
      "-------------\n",
      "cillizzacnn heres an easy way to understand all of president trumps recent flipflops\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01327685 0.11867951 0.7356118  0.1324318 ]\n",
      "-------------\n",
      "heres what you need to know before you go to a whitecollar sex party\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01024699 0.0676376  0.65600735 0.26610804]\n",
      "-------------\n",
      "the worlds first monster truck front flip will leave you grinning like a kid\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.01566453 0.51280344 0.463362   0.00817002]\n",
      "-------------\n",
      "this real walking robot looks like it just stepped out of transformers\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02402323 0.26667377 0.65446556 0.05483745]\n",
      "-------------\n",
      "this mit project is mapping trees in cities around the world using google street view\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00625193 0.12233147 0.837152   0.03426455]\n",
      "-------------\n",
      "why you need to bingewatch carrie fishers final tv show immediately\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.0198165  0.7241011  0.25214332 0.0039391 ]\n",
      "-------------\n",
      "the death of aaron hernandez brings up more questions than answers writes ian oconnor\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02593196 0.04784829 0.3772303  0.5489895 ]\n",
      "-------------\n",
      "uber driver saves 16yearold girl from sex trafficking\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9366260e-01 6.3094599e-03 4.4027761e-06 2.3555725e-05]\n",
      "-------------\n",
      "the hunger gamesstyle reality show where 30 people are left in siberian wilderness\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.0192648  0.7682092  0.20988925 0.00263668]\n",
      "-------------\n",
      "can cricket be saved from itself how the icc is flirting with essential reform  tim wigmore  via guardiansport\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0129645  0.2570325  0.7041562  0.02584686]\n",
      "-------------\n",
      "is it april 27 yet\n",
      "\n",
      "nfldraftscouts postsuper bowl big board\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00486027 0.07037956 0.86649317 0.05826707]\n",
      "-------------\n",
      "actor kal penn shares scripts revealing indian stereotypes in hollywood\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.3827212e-01 6.1334144e-02 2.0726027e-04 1.8641482e-04]\n",
      "-------------\n",
      "this hidden figures cosplay is the cutest\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.01201906 0.8266219  0.16007948 0.00127958]\n",
      "-------------\n",
      "this heartwarming photo perfectly captures a nonverbal boys special bond with deaf dog\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9022663e-01 9.7203981e-03 9.9662466e-06 4.3088836e-05]\n",
      "-------------\n",
      "crayola drops hints about dandelion crayons replacement\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00947555 0.4489651  0.53407276 0.00748663]\n",
      "-------------\n",
      "police pug excels at cuteness not at catching criminals\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0035934  0.15128507 0.8318535  0.01326799]\n",
      "-------------\n",
      "how allwoman death squads are taking over mexicos drug wars\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0172456  0.10413302 0.7061304  0.172491  ]\n",
      "-------------\n",
      "frenchman smashes sailing record\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.1881014e-02 9.6081215e-01 1.7167903e-02 1.3883965e-04]\n",
      "-------------\n",
      "your 9 needtoknow takeaways from this mornings 2017 golden globe nominations right here\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00490484 0.10116138 0.8576867  0.0362471 ]\n",
      "-------------\n",
      "duke a no 1 seed will usc make the dance\n",
      "\n",
      "our final predictions\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.00831364 0.6763898  0.31288743 0.00240909]\n",
      "-------------\n",
      "icymi even though he averages a tripledouble russell westbrook will not start in the allstar game\n",
      "\n",
      "see who is\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.3776766e-01 8.4862518e-01 1.3163514e-02 4.4356054e-04]\n",
      "-------------\n",
      "twenty years on where is the legacy of tiger woods defining masters triumph  via guardiansport\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.05880338 0.8953066  0.04496826 0.00092186]\n",
      "-------------\n",
      "21 savage kourtney kardashian burns we still havent recovered from\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.3143367e-01 8.5869247e-01 9.5888339e-03 2.8501946e-04]\n",
      "-------------\n",
      "this guy had to draw a spider in his biology class and people cant handle how bad it is\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0798271  0.2653716  0.48295084 0.17185041]\n",
      "-------------\n",
      "comcast wants be your new cellphone carrier heres everything you need to know\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.7521486e-02 9.0269285e-01 9.5815202e-03 2.0417341e-04]\n",
      "-------------\n",
      "jimmy kimmel shares some alternative facts about himself\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00407103 0.06664333 0.87898535 0.05030033]\n",
      "-------------\n",
      "fact checker sanderss convoluted claim that democrats are not trying to filibuster gorsuch\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00424607 0.06337328 0.86570054 0.06668013]\n",
      "-------------\n",
      "a basic design feature of facebooks advertising system makes it easy to create fake ads\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.0145354  0.53434145 0.4438884  0.00723472]\n",
      "-------------\n",
      "thats sad ted thats sad\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.01051252 0.5275309  0.4564387  0.00551783]\n",
      "-------------\n",
      "how 100 years have shaped western beauty beyond recognition\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00233695 0.06532883 0.9064407  0.02589364]\n",
      "-------------\n",
      "potus this isnt just a knock on barackobama weve been going down the wrong path for many years beyond him\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00550774 0.0558509  0.8591151  0.07952623]\n",
      "-------------\n",
      "burnfordapl\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02216254 0.03368841 0.14238521 0.80176383]\n",
      "-------------\n",
      "meet the 25 new billionaires who made our forbesbillionaires list for the 1st time in 2017\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.08325016 0.35653412 0.43817225 0.12204342]\n",
      "-------------\n",
      "the top movies of the last four years star women\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01914175 0.10909871 0.6131399  0.25861958]\n",
      "-------------\n",
      "january 9 is the day people are most likely to try and start an affair\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00706055 0.01665355 0.17991872 0.7963672 ]\n",
      "-------------\n",
      "corker on russia any time we have a country trying to discredit our democracy its an important issue to pursue\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01190164 0.21142304 0.74674237 0.02993294]\n",
      "-------------\n",
      "facebook killer found dead in vehicle\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.46209663 0.5318776  0.00540658 0.00061921]\n",
      "-------------\n",
      "wompity\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02216254 0.03368841 0.14238521 0.80176383]\n",
      "-------------\n",
      "theres evidence for how much exercise affects your health  more is not always better\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00556685 0.0632992  0.8363629  0.09477102]\n",
      "-------------\n",
      "baseball halloffamers heart transplant beats with inspiration\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00188697 0.03469317 0.9050958  0.05832405]\n",
      "-------------\n",
      "these hightech headphones could be game changers for the military\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.4678706e-01 7.4353993e-01 9.1433069e-03 5.2971300e-04]\n",
      "-------------\n",
      "amazon just created its own version of skype  heres how it works\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.5039546e-02 8.9986044e-01 8.4346458e-02 7.5354014e-04]\n",
      "-------------\n",
      "how obama made economic history during his eight years in office\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01396814 0.20166329 0.7407883  0.04358022]\n",
      "-------------\n",
      "the weeknd amp nav are up to their necks in models in someway video\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.73106503e-01 2.67248116e-02 5.69085460e-05 1.11691865e-04]\n",
      "-------------\n",
      "they think the rules dont apply to them and you know what they are right the rules dont\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.6375923  0.34837395 0.01041797 0.00361571]\n",
      "-------------\n",
      "that didnt take long trumps press secretary is already a meme\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0058993  0.10774212 0.84815216 0.03820641]\n",
      "-------------\n",
      "naked molerats are even stranger than anyone thought\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00321904 0.05059596 0.8915877  0.0545973 ]\n",
      "-------------\n",
      "17 tweets for people who both love and hate jughead on riverdale\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02094893 0.5456636  0.42253384 0.0108536 ]\n",
      "-------------\n",
      "could a planet like coruscant from star wars exist\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.485991   0.507418   0.00582122 0.00076977]\n",
      "-------------\n",
      "spanish uk resident feared insurance rule would force her to leave\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9749029e-02 8.8674766e-01 1.3169810e-02 3.3351092e-04]\n",
      "-------------\n",
      "police received an unusual complaint from a woman who claimed her drug dealer was ripping her off\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00571619 0.01908299 0.41640761 0.5587932 ]\n",
      "-------------\n",
      "go green and get happy with these earthday freebies\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00602491 0.09898788 0.8412024  0.05378481]\n",
      "-------------\n",
      "hello  again\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.621564e-02 8.953704e-01 8.765169e-02 7.623309e-04]\n",
      "-------------\n",
      "he said he can guarantee their acquittal if they renounce christianity and convert to islam\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00501681 0.08428052 0.86243576 0.04826689]\n",
      "-------------\n",
      "facebook really really wants you to use facebook live\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00383806 0.12467863 0.8525321  0.01895116]\n",
      "-------------\n",
      "trump shared a proverb with his irish friends which likely wasnt irish\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.38664228 0.6051166  0.00752947 0.00071168]\n",
      "-------------\n",
      "someone threw the veep music over that awkward trump nonsigning and its fantastic\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0121528  0.12810154 0.76200366 0.09774209]\n",
      "-------------\n",
      "what are the most popular nfl franchises in states that dont have a team\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01173072 0.05660442 0.6562401  0.2754247 ]\n",
      "-------------\n",
      "adpvoice does unlimited vacation time really work and for whom\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01069202 0.41115138 0.5690936  0.00906307]\n",
      "-------------\n",
      "shocked villagers capture monstrous snake that gorged on two of their goats\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9650359e-01 3.4427829e-03 2.8055381e-06 5.0875162e-05]\n",
      "-------------\n",
      "after her towns deal with wall street her water and sewer bill has jumped so much that shes thinking about moving\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00424457 0.10760931 0.8656282  0.02251795]\n",
      "-------------\n",
      "apple has a secret team working on the holy grail for treating diabetes  via cnbc\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.12519394 0.26594442 0.33432567 0.27453604]\n",
      "-------------\n",
      "the worst bond rout in three years deepened thursday\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.8708063e-01 1.2838077e-02 1.6328797e-05 6.4902211e-05]\n",
      "-------------\n",
      "the magics offseason plans may have accidentally been leaked in a tweet \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0053119  0.07258544 0.84709173 0.07501096]\n",
      "-------------\n",
      "smile this restaurants twoway mirror is filming you taking selfies\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00819593 0.28883308 0.68986636 0.01310458]\n",
      "-------------\n",
      "everyone loves bernie sanders except it seems the democratic party  trevor timm\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.0281958e-02 9.4935626e-01 4.0156029e-02 2.0575733e-04]\n",
      "-------------\n",
      "golfing with trump better leave your ego at the clubhouse\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.37352636 0.61868477 0.0071421  0.00064683]\n",
      "-------------\n",
      "this song naming all 270 london underground stations is pretty epic\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03973975 0.88000387 0.07889344 0.00136291]\n",
      "-------------\n",
      "how long do us retirees live compared to peers in other countries\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01908437 0.29468215 0.65928745 0.02694607]\n",
      "-------------\n",
      "this tweet about wendys chicken nuggets could become the most retweeted tweet ever\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02578859 0.89145654 0.08171348 0.00104129]\n",
      "-------------\n",
      "massive protests target trumps agenda\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.8172486e-01 1.8165357e-02 2.8053269e-05 8.1744882e-05]\n",
      "-------------\n",
      "kendrick lamars latest video features a woman with stretch marksand its gotten people talking\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00266945 0.047719   0.9002897  0.04932181]\n",
      "-------------\n",
      "fullhouse house sells to surprising buyer\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.5836313  0.4117285  0.00396879 0.00067139]\n",
      "-------------\n",
      "twitters hogging up your iphones storage heres how to get it back\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.01175171 0.6596314  0.3250315  0.00358541]\n",
      "-------------\n",
      "icymi with top two mens seeds out wholl win the australian open\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.07389322 0.12581095 0.24820125 0.5520946 ]\n",
      "-------------\n",
      "camera catches 2yearold twins having epic party after bedtime\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.09100617 0.7452853  0.15348573 0.01022286]\n",
      "-------------\n",
      "new music \n",
      "\n",
      " sza x trvisxx \n",
      "\n",
      "love galore\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.43277767 0.56046575 0.00611    0.00064655]\n",
      "-------------\n",
      "cutback crew for iss launch\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.7261260e-01 1.2598586e-01 8.1880757e-04 5.8288313e-04]\n",
      "-------------\n",
      "watch one man take on americas top 5 fears\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.01306005 0.839278   0.1464757  0.00118615]\n",
      "-------------\n",
      "perspective nurturing the fatherdaughter relationship i didnt have  via onparenting\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0028495  0.0660812  0.8978514  0.03321785]\n",
      "-------------\n",
      "this has been without question the hardest week of my life\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01623551 0.035796   0.2522126  0.6957559 ]\n",
      "-------------\n",
      "the curious case of the billiondollar lithium mine that sold on the cheap\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03137592 0.8703303  0.09669008 0.00160366]\n",
      "-------------\n",
      "storms lash eu\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.0156186e-01 8.8794160e-01 1.0246783e-02 2.4980976e-04]\n",
      "-------------\n",
      "the bbc kids and their parents are back in cartoon form\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00925697 0.4775538  0.5070902  0.0060991 ]\n",
      "-------------\n",
      "the keepers of the forest were thrown out of the forest by the forest department what a shame\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01040119 0.03876592 0.60348475 0.34734806]\n",
      "-------------\n",
      "woman pulled alive from the river thames beside the bridge where a major terror attack saw pedestrians hit by a car\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01807376 0.12121651 0.78965116 0.07105852]\n",
      "-------------\n",
      "trump elevates controversial aide to new role\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9677283e-01 3.2002409e-03 1.7812013e-06 2.5204812e-05]\n",
      "-------------\n",
      "10 years later britney spears headshaving moment is still unforgettable\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00750905 0.01907669 0.24324174 0.7301726 ]\n",
      "-------------\n",
      "army vet awarded bronze star for bravery in vietnam battle\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0017743  0.04814887 0.92346966 0.0266072 ]\n",
      "-------------\n",
      "why rihanna amp lady gaga are turning to unknown fashion students for fresh looks\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.1026218e-01 8.6543548e-01 2.3559246e-02 7.4309629e-04]\n",
      "-------------\n",
      "the 20yearold leading the march against revenge porn\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.6306536e-02 8.8940525e-01 9.3441561e-02 8.4668037e-04]\n",
      "-------------\n",
      "ancient chinese tombsweeping festival goes hitech\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.5171029e-01 8.3657455e-01 1.1330171e-02 3.8505919e-04]\n",
      "-------------\n",
      "billboards top 10 most popular holiday songs \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00482922 0.00615484 0.0778954  0.9111205 ]\n",
      "-------------\n",
      "uk police still think westminster attacker acted alone\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00368734 0.02737205 0.81981885 0.1491217 ]\n",
      "-------------\n",
      "inside camila cabellos fifth harmony exit where did it all go wrong\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00415187 0.05292908 0.85674256 0.08617643]\n",
      "-------------\n",
      "how to benefit from the battle between credit card companies\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01047412 0.16589233 0.7826848  0.04094877]\n",
      "-------------\n",
      "pence commuting chelsea mannings sentence was a mistake\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00262062 0.03839141 0.89678437 0.06220363]\n",
      "-------------\n",
      "questions linger from the probe into princes death\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.32834262 0.66257733 0.00840923 0.00067086]\n",
      "-------------\n",
      "one million moms throws fit over mags choice to include samesex parents\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00453181 0.05515738 0.8556233  0.08468752]\n",
      "-------------\n",
      "this 1 million watch is made of genuine swiss cheese\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00374719 0.02555688 0.6904843  0.28021157]\n",
      "-------------\n",
      "united is playing clean up this morning as it reveals its plan to make flying them less awful thoughts  lpolgreen\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00178541 0.02552089 0.91635513 0.05633856]\n",
      "-------------\n",
      "this fashion line is changing how we define nude  via yahoostyle\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00556284 0.09156784 0.8513809  0.05148842]\n",
      "-------------\n",
      "john mayer has more to say the outtakes\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.6037098  0.39200792 0.00361449 0.0006678 ]\n",
      "-------------\n",
      "conservatives are watching less football this season\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00757425 0.27819067 0.7025275  0.01170755]\n",
      "-------------\n",
      "icymi what else can you throw at us locals emerge from cyclone zone cyclonedebbie\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01425592 0.15242702 0.7586033  0.07471377]\n",
      "-------------\n",
      "why women are only important on womens day asks itsshalmali\n",
      "can we have an answer womensday\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02462283 0.13505296 0.649005   0.19131921]\n",
      "-------------\n",
      "2 of the us economys main engines are moving in different directions in the final quarter\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01879971 0.10673819 0.61149937 0.26296267]\n",
      "-------------\n",
      "climate change denier who says no one can explain global warming gets completely schooled by someone explaining it\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.9627949e-02 9.4860470e-01 2.1547033e-02 2.2031374e-04]\n",
      "-------------\n",
      "3 steps to picking the right credit card for you\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00817755 0.01419005 0.13187705 0.8457554 ]\n",
      "-------------\n",
      "they escorted me as if i were a terrorist\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.2209789e-02 9.1250455e-01 4.4575449e-02 7.1025168e-04]\n",
      "-------------\n",
      "the fashion industry really wants you to wear pajamas on the street dont do it\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.580462   0.41145632 0.00658134 0.00150043]\n",
      "-------------\n",
      "the nfl is in a loselose situation with player protests\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7949171e-01 2.0390455e-02 3.3186610e-05 8.4643281e-05]\n",
      "-------------\n",
      "these are the tube lines which will be be affected by the strike\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00358982 0.00543673 0.08187854 0.9090949 ]\n",
      "-------------\n",
      "if the sound of people chewing annoys you scientists just figured out why\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00589063 0.02522474 0.5858544  0.38303018]\n",
      "-------------\n",
      "twitter party at sxsw\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9678814e-01 3.1929950e-03 1.6224103e-06 1.7266328e-05]\n",
      "-------------\n",
      "thevoice crowns season 11 winner\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9568427e-01 4.2762016e-03 3.0402277e-06 3.6425630e-05]\n",
      "-------------\n",
      "russia should reinstate monarchy and appoint putin as royal emperor\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9371558e-01 6.2316419e-03 5.6636695e-06 4.7111560e-05]\n",
      "-------------\n",
      "9 of the most popular jobs football players take after retiring from the nfl\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0199242  0.03233929 0.16071428 0.78702223]\n",
      "-------------\n",
      "who is the person we need to talk to\n",
      "\n",
      "call mr trump\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00276364 0.04601925 0.9034234  0.04779368]\n",
      "-------------\n",
      "cate blanchett shares her secrets on having and keeping great skin\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.1796309e-02 8.9333087e-01 9.4231613e-02 6.4126117e-04]\n",
      "-------------\n",
      "angela merkels run for a 4th term gets complicated as a popular adversary joins the fray\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00404059 0.05606022 0.8962164  0.04368278]\n",
      "-------------\n",
      "is there a link between climate change and diabetes researchers are trying to find out\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.5287263e-02 9.6379250e-01 2.0789584e-02 1.3071636e-04]\n",
      "-------------\n",
      "this is why everyone buys milk bread and toilet paper when it snows\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03413901 0.7364585  0.22403115 0.00537142]\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Error Analysis\n",
    "for i in range(1000):\n",
    "    if Y_test[i] - y_pred_binary[i] != 0:\n",
    "        print(X_test[i])\n",
    "        print(\"Actual Label\",Y_test[i])\n",
    "        print(\"Prediction Lable\",y_pred_binary[i])\n",
    "        print(\"Prediction\",y_pred_onehot[i])\n",
    "        print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(test_string):\n",
    "    test_string = cleanText(test_string)\n",
    "    test = np.array([test_string])\n",
    "    test_indices = sentences_to_indices(test, word_to_index, max_len = maxLen)\n",
    "    y_pred_onehot = model.predict(test_indices)\n",
    "    y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "    if y_pred_binary == [1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "test_string = \"US election 2020: What is the presidential transition\"\n",
    "test(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
