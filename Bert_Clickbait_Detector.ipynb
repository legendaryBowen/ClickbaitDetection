{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bert_Clickbait_Detector.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-YbjCkzw0yU"
      },
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q tensorflow-text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-P1ZOA0FkVJ"
      },
      "source": [
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XgTpm9ZxoN9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optmizer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import json\n",
        "from utils import *\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtXcJ1xMy66V"
      },
      "source": [
        "train_df = pd.DataFrame(columns=['id','postText','truthMedian','truthClass','truthMean'])\n",
        "with open('train.json') as json_data:\n",
        "    data = json.load(json_data)\n",
        "    for instance in data:\n",
        "        train_instance = {'id': instance['text_id'], 'postText': instance['post_text'], 'truthMedian': instance['truth_median'], 'truthClass': instance['click_bait'], 'truthMean': instance['truth_mean']}\n",
        "        train_df = train_df.append(train_instance, ignore_index = True)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvkjmYQEzE-a"
      },
      "source": [
        "test_df = pd.DataFrame(columns=['id','postText','truthMedian','truthClass','truthMean'])\n",
        "with open('test.json') as json_data:\n",
        "    data = json.load(json_data)\n",
        "    for instance in data:\n",
        "        test_instance = {'id': instance['text_id'], 'postText': instance['post_text'], 'truthMedian': instance['truth_median'], 'truthClass': instance['click_bait'], 'truthMean': instance['truth_mean']}\n",
        "        test_df = test_df.append(test_instance, ignore_index = True)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUwE6ExFzGU-"
      },
      "source": [
        "# Remove all punctuations and clear the text\n",
        "train_df['postText'] = train_df['postText'].apply(cleanText)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2H3fdTYzKa2"
      },
      "source": [
        "# Remove all punctuations and clear the text\n",
        "test_df['postText'] = test_df['postText'].apply(cleanText)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whsVTXQqzNd9"
      },
      "source": [
        "X_train, Y_train = np.array(train_df[\"postText\"].tolist()), np.array(train_df[\"truthClass\"].tolist())\n",
        "X_test, Y_test = np.array(test_df[\"postText\"].tolist()), np.array(test_df[\"truthClass\"].tolist())\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ojA3HBq53A"
      },
      "source": [
        "print(X_test[0:10])\n",
        "print(Y_test[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8_ctG55-uTX"
      },
      "source": [
        "#@title Choose a BERT model to fine-tune\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1'\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SQi-jWd_jzq"
      },
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9-zCzJpnuwS"
      },
      "source": [
        "# text_test = ['this is such an amazing movie!']\n",
        "# text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "# print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "# print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "# print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "# print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "# print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXxYpK8ixL34"
      },
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OoF9mebuSZc"
      },
      "source": [
        "# bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "# print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "# print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "# print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "# print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "# print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aksj743St9ga"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout\n",
        "def build_classifier_model():\n",
        "  text_input = Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = Dropout(0.1)(net)\n",
        "  net = Dense(1, activation=None, name='classifier')(net)\n",
        "  return Model(text_input, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGMF8AZcB2Zy"
      },
      "source": [
        "bert_classifier = build_classifier_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EmzyHZXKIpm"
      },
      "source": [
        "bert_classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9eP2y9dbw32"
      },
      "source": [
        "steps_per_epoch = X_train.shape[0]\n",
        "epochs = 5\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "init_lr = 3e-4\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B05-lz64RMk8"
      },
      "source": [
        "import keras.backend as K\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0MTTK3cyQN5"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = [get_f1,  'accuracy']\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7GPDhR98jsD"
      },
      "source": [
        "bert_classifier.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtfDFAnN_Neu"
      },
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = bert_classifier.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=64, callbacks=[callback], shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slqB-urBV9sP"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "loss, get_f1, accuracy = bert_classifier.evaluate(X_test, Y_test)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'get_f1: {get_f1}')\n",
        "print(f'Accuracy: {accuracy}')\n",
        "Y_predict = bert_classifier.predict(X_test)\n",
        "Y_predict_binary = [1 if i >= 0.5 else 0 for [i] in Y_predict]\n",
        "print(\"Bert Testing report\")\n",
        "print(classification_report(Y_test, Y_predict_binary))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiythcODf0xo"
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['get_f1']\n",
        "val_loss = history_dict['val_get_f1']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'r', label='Training F1')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation F1')\n",
        "plt.title('Training and validation F1')\n",
        "# plt.xlabel('Epochs')\n",
        "plt.ylabel('F1')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUEWVskZjEF0"
      },
      "source": [
        "bert_classifier.save(\"BERT_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERNPtjjkvLQL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}