{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Should I Get Bings\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which TV Female Friend Group Do You Belong In\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The New \"Star Wars: The Force Awakens\" Trailer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Vine Of New York On \"Celebrity Big Brothe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Couple Did A Stunning Photo Shoot With Their...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText truthClass\n",
       "0                               Should I Get Bings\\n          1\n",
       "1    Which TV Female Friend Group Do You Belong In\\n          1\n",
       "2  The New \"Star Wars: The Force Awakens\" Trailer...          1\n",
       "3  This Vine Of New York On \"Celebrity Big Brothe...          1\n",
       "4  A Couple Did A Stunning Photo Shoot With Their...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['postText','truthClass'])\n",
    "with open('data/clickbait_data.txt') as data:\n",
    "    for sentence in data:\n",
    "        positive_case = {'truthClass': 1, 'postText': sentence}\n",
    "        df = df.append(positive_case, ignore_index = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7259</th>\n",
       "      <td>David Beckham Immortalized His Daughters Drawi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24285</th>\n",
       "      <td>Wikinews interviews spokesman for Greek far-le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10093</th>\n",
       "      <td>14 Pictures That Sum Up Christmas If You're Th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17258</th>\n",
       "      <td>Despite Torture Video, U.S. and Emirates Sign ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>Would You Be A Better Date Than My New Man\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                postText truthClass\n",
       "7259   David Beckham Immortalized His Daughters Drawi...          1\n",
       "24285  Wikinews interviews spokesman for Greek far-le...          0\n",
       "10093  14 Pictures That Sum Up Christmas If You're Th...          1\n",
       "17258  Despite Torture Video, U.S. and Emirates Sign ...          0\n",
       "5688        Would You Be A Better Date Than My New Man\\n          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/non_clickbait_data.txt', encoding='utf-8') as data:\n",
    "    for sentence in data:\n",
    "        negative_case = {'truthClass': 0, 'postText': sentence}\n",
    "        df = df.append(negative_case, ignore_index = True)\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16001, 2)\n",
      "(15999, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df[df['truthClass'] == 0].shape)\n",
    "print(df[df['truthClass'] == 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7259</th>\n",
       "      <td>david beckham immortalized his daughters drawi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24285</th>\n",
       "      <td>wikinews interviews spokesman for greek farlef...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10093</th>\n",
       "      <td>14 pictures that sum up christmas if youre the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17258</th>\n",
       "      <td>despite torture video us and emirates sign key...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>would you be a better date than my new man</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                postText truthClass\n",
       "7259   david beckham immortalized his daughters drawi...          1\n",
       "24285  wikinews interviews spokesman for greek farlef...          0\n",
       "10093  14 pictures that sum up christmas if youre the...          1\n",
       "17258  despite torture video us and emirates sign key...          0\n",
       "5688          would you be a better date than my new man          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    text = text[:-1]\n",
    "    return text\n",
    "df['postText'].dropna(inplace=True)\n",
    "df['postText'] = df['postText'].apply(cleanText)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLen = 0\n",
    "for i in range(len(df)):\n",
    "    sentence = df[\"postText\"][i]\n",
    "    if len(sentence.split()) > maxLen:\n",
    "        maxLen = len(sentence.split())\n",
    "        maxstr = sentence\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28800,)\n",
      "(3200,)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.1)\n",
    "X_train, Y_train = np.array(train[\"postText\"].tolist()), np.array(train[\"truthClass\"].tolist())\n",
    "X_test, Y_test = np.array(test[\"postText\"].tolist()), np.array(test[\"truthClass\"].tolist())\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):   \n",
    "    m = X.shape[0]  # number of training examples\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape \n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    for i in range(m):          \n",
    "        # Convert the ith training sentence in lower case and split is into words\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index.keys():\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j = j + 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train_indices =\n",
      " (28800, 26)\n"
     ]
    }
   ],
   "source": [
    "Indices = sentences_to_indices(X_train,word_to_index, maxLen)\n",
    "print(\"X_Train_indices =\\n\", Indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1        \n",
    "    # define dimensionality of your GloVe word vectors (= 50)\n",
    "    emb_dim = word_to_vec_map[\"happy\"].shape[0]      \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    # See instructions above to choose the correct shape.\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_len,emb_dim,trainable = False)\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,)) \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClickBait_LSTM(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with 2 units\n",
    "    X = Dense(2)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)  \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 26)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 26, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 26, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 26, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,540\n",
      "Trainable params: 223,490\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ClickBait_LSTM((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28800, 26)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 2)\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "450/450 [==============================] - 8s 17ms/step - loss: 0.1480 - accuracy: 0.9426\n",
      "Epoch 2/10\n",
      "450/450 [==============================] - 9s 21ms/step - loss: 0.0955 - accuracy: 0.9650\n",
      "Epoch 3/10\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.0832 - accuracy: 0.9704\n",
      "Epoch 4/10\n",
      "450/450 [==============================] - 12s 27ms/step - loss: 0.0722 - accuracy: 0.9747\n",
      "Epoch 5/10\n",
      "450/450 [==============================] - 12s 27ms/step - loss: 0.0663 - accuracy: 0.9772\n",
      "Epoch 6/10\n",
      "450/450 [==============================] - 12s 27ms/step - loss: 0.0581 - accuracy: 0.9794\n",
      "Epoch 7/10\n",
      "450/450 [==============================] - 12s 27ms/step - loss: 0.0522 - accuracy: 0.9816\n",
      "Epoch 8/10\n",
      "450/450 [==============================] - 12s 27ms/step - loss: 0.0473 - accuracy: 0.9847\n",
      "Epoch 9/10\n",
      "450/450 [==============================] - 12s 28ms/step - loss: 0.0407 - accuracy: 0.9861\n",
      "Epoch 10/10\n",
      "450/450 [==============================] - 13s 28ms/step - loss: 0.0363 - accuracy: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27418f89b20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 10, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_binary(data):\n",
    "    binary = []\n",
    "    for i in range(len(data)):\n",
    "        binary.append(1) if data[i][1] > data[i][0] else binary.append(0)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error\n",
      "Accuracy 0.9899305555555555\n",
      "Precision 0.982698488682213\n",
      "Recall 0.9974318039841744\n",
      "F1 score: 0.9900103341370996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,roc_auc_score, mean_squared_error \n",
    "y_train_pred_oh = model.predict(X_train_indices)\n",
    "y_train_pred_binary = onehot_to_binary(y_train_pred_oh)\n",
    "Y_train_binary = onehot_to_binary(Y_train_oh)\n",
    "\n",
    "print(\"Training Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_train_binary, y_train_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_train_binary, y_train_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error\n",
      "Accuracy 0.9640625\n",
      "Precision 0.9522351500306185\n",
      "Recall 0.9767587939698492\n",
      "F1 score: 0.9643410852713178\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "y_pred_onehot = model.predict(X_test_indices)\n",
    "y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "\n",
    "print(\"Testing Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_test, y_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_test, y_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_test, y_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1608\n",
      "           1       0.95      0.98      0.96      1592\n",
      "\n",
      "    accuracy                           0.96      3200\n",
      "   macro avg       0.96      0.96      0.96      3200\n",
      "weighted avg       0.96      0.96      0.96      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(test_string):\n",
    "    test_string = cleanText(test_string)\n",
    "    test = np.array([test_string])\n",
    "    test_indices = sentences_to_indices(test, word_to_index, max_len = maxLen)\n",
    "    y_pred_onehot = model.predict(test_indices)\n",
    "    y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "    return y_pred_binary == [1]\n",
    "\n",
    "test_string = \"first comes tinder then comes marriage\"\n",
    "test(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
