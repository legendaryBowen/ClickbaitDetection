{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, GRU, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth_df = pd.DataFrame(columns=['id','truthMedian','truthClass','truthMean'])\n",
    "# with open('data/truth.jsonl') as data:\n",
    "#     for labelobj in data:\n",
    "#         truth = json.loads(labelobj)\n",
    "#         truthlabel = {'id': truth['id'], 'truthMedian': truth['truthMedian'], 'truthClass': truth['truthClass'], 'truthMean': truth['truthMean']}\n",
    "#         truth_df = truth_df.append(truthlabel, ignore_index = True)\n",
    "# truth_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances_df = pd.DataFrame(columns=['id','postText'])\n",
    "# with open('data/instances.jsonl') as data:\n",
    "# \tfor instanceobj in data:\n",
    "# \t\tinstance = json.loads(instanceobj)\n",
    "# \t\tinstancerow = {'id': instance['id'], 'postText': instance['postText']}\n",
    "# \t\tinstances_df = instances_df.append(instancerow, ignore_index=True)\n",
    "# instances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = instances_df.join(truth_df.set_index('id'), on='id')\n",
    "# dataset = dataset.drop(labels='id',axis=1)\n",
    "# for i in range(len(dataset)):\n",
    "#     dataset['postText'].values[i] = dataset['postText'].values[i][0]\n",
    "# dataset['postText'].dropna(inplace=True)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the 'no-clickbait' or 'clickbait' to binary indicator\n",
    "# dataset['truthClass'] = dataset['truthClass'].apply(classToBinary)\n",
    "# # Convert floating number in 'truthMedian' column to integer\n",
    "# dataset['truthMedian'] = dataset['truthMedian'].apply(medianToInteger)\n",
    "# # Remove all punctuations and clear the text\n",
    "# dataset['postText'] = dataset['postText'].apply(cleanText)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # length of titles with longest words\n",
    "# maxLen = maxLengthInPostText(dataset)\n",
    "# maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the dataset to training and testing set\n",
    "# train, test = train_test_split(dataset, test_size=0.2)\n",
    "# X_train, Y_train, Y_train_mean = np.array(train[\"postText\"].tolist()), np.array(train[\"truthMedian\"].tolist()), np.array(train[\"truthMean\"].tolist())\n",
    "# X_test, Y_test, Y_test_mean = np.array(test[\"postText\"].tolist()), np.array(test[\"truthClass\"].tolist()), np.array(test[\"truthMean\"].tolist())\n",
    "# print(Y_train.shape)\n",
    "# print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=['id','postText','truthMedian','truthClass','truthMean'])\n",
    "with open('data/train.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "    for instance in data:\n",
    "        train_instance = {'id': instance['text_id'], 'postText': instance['post_text'], 'truthMedian': instance['truth_median'], 'truthClass': instance['click_bait'], 'truthMean': instance['truth_mean']}\n",
    "        train_df = train_df.append(train_instance, ignore_index = True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns=['id','postText','truthMedian','truthClass','truthMean'])\n",
    "with open('data/test.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "    for instance in data:\n",
    "        test_instance = {'id': instance['text_id'], 'postText': instance['post_text'], 'truthMedian': instance['truth_median'], 'truthClass': instance['click_bait'], 'truthMean': instance['truth_mean']}\n",
    "        test_df = test_df.append(test_instance, ignore_index = True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert floating number in 'truthMedian' column to integer\n",
    "train_df['truthMedian'] = train_df['truthMedian'].apply(medianToInteger)\n",
    "# Remove all punctuations and clear the text\n",
    "train_df['postText'] = train_df['postText'].apply(cleanText)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert floating number in 'truthMedian' column to integer\n",
    "test_df['truthMedian'] = test_df['truthMedian'].apply(medianToInteger)\n",
    "# Remove all punctuations and clear the text\n",
    "test_df['postText'] = test_df['postText'].apply(cleanText)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of titles with longest words\n",
    "maxLen = max(maxLengthInPostText(train_df), maxLengthInPostText(test_df))\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = np.array(train_df[\"postText\"].tolist()), np.array(train_df[\"truthMedian\"].tolist())\n",
    "X_test, Y_test = np.array(test_df[\"postText\"].tolist()), np.array(test_df[\"truthClass\"].tolist())\n",
    "print(X_train[0:10])\n",
    "print(Y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the glove word embedding file\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indices = sentences_to_indices(X_train,word_to_index, maxLen)\n",
    "print(\"X_Train_indices =\\n\", Indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClickBait_BiLSTM(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(embeddings)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with 2 units\n",
    "    X = Dense(4)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)  \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiLSTM_model = ClickBait_BiLSTM((maxLen,), word_to_vec_map, word_to_index)\n",
    "BiLSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiLSTM_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 4)\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiLSTM_model.fit(X_train_indices, Y_train_oh, epochs = 10, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,roc_auc_score, mean_squared_error, classification_report\n",
    "y_train_pred_oh = BiLSTM_model.predict(X_train_indices)\n",
    "y_train_pred_binary = onehot_to_binary(y_train_pred_oh)\n",
    "Y_train_binary = onehot_to_binary(Y_train_oh)\n",
    "\n",
    "print(\"LSTM Training Accuracy\")\n",
    "print('Accuracy %s' % accuracy_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_train_binary, y_train_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_train_binary, y_train_pred_binary))\n",
    "#print('MSE %s' % mean_squared_error(Y_train_mean, y_train_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "y_pred_onehot = BiLSTM_model.predict(X_test_indices)\n",
    "y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "\n",
    "print(\"LSTM Testing Accuracy\")\n",
    "print('Accuracy %s' % accuracy_score(Y_test, y_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_test, y_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_test, y_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_test, y_pred_binary))\n",
    "#print('MSE %s' % mean_squared_error(Y_test_mean, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LSTM Testing report\")\n",
    "print(classification_report(Y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our model\n",
    "BiLSTM_model.save(\"BiLSTM_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output to test_df\n",
    "def predict(headline):\n",
    "    headline = cleanText(headline)\n",
    "    headline_np = np.array([headline])\n",
    "    indices = sentences_to_indices(headline_np, word_to_index, max_len = maxLen)\n",
    "    #y_pred_onehot = lstm_model.predict(test_indices)\n",
    "    y_pred_onehot = BiGRU_model.predict(indices)\n",
    "    y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "    return 1 if y_pred_binary == [1] else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted_prob_LSTM'] = test_df['postText'].apply(predict)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Error Analysis\n",
    "for i in range(100):\n",
    "    if Y_test[i] - y_pred_binary[i] != 0:\n",
    "        print(X_test[i])\n",
    "        print(\"Actual Label\",Y_test[i])\n",
    "        print(\"Prediction Lable\",y_pred_binary[i])\n",
    "        print(\"Prediction\",y_pred_onehot[i])\n",
    "        print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = \"Here are 10 things you may not know\"\n",
    "predict(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
