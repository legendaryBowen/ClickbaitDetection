{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858464162594172928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858460992073863168</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858459539296980995</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858455355948384257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  truthMedian    truthClass  truthMean\n",
       "0  858464162594172928     1.000000     clickbait   1.000000\n",
       "1  858462320779026433     0.000000  no-clickbait   0.133333\n",
       "2  858460992073863168     0.333333  no-clickbait   0.400000\n",
       "3  858459539296980995     0.333333  no-clickbait   0.266667\n",
       "4  858455355948384257     0.000000  no-clickbait   0.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_df = pd.DataFrame(columns=['id','truthMedian','truthClass','truthMean'])\n",
    "with open('data/truth.jsonl') as data:\n",
    "    for labelobj in data:\n",
    "        truth = json.loads(labelobj)\n",
    "        truthlabel = {'id': truth['id'], 'truthMedian': truth['truthMedian'], 'truthClass': truth['truthClass'], 'truthMean': truth['truthMean']}\n",
    "        truth_df = truth_df.append(truthlabel, ignore_index = True)\n",
    "truth_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>postText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>[UK’s response to modern slavery leaving victi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858421020331560960</td>\n",
       "      <td>[this is good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858368123753435136</td>\n",
       "      <td>[The \"forgotten\" Trump roast: Relive his bruta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858323428260139008</td>\n",
       "      <td>[Meet the happiest #dog in the world!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858283602626347008</td>\n",
       "      <td>[Tokyo's subway is shut down amid fears over a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           postText\n",
       "0  858462320779026433  [UK’s response to modern slavery leaving victi...\n",
       "1  858421020331560960                                     [this is good]\n",
       "2  858368123753435136  [The \"forgotten\" Trump roast: Relive his bruta...\n",
       "3  858323428260139008             [Meet the happiest #dog in the world!]\n",
       "4  858283602626347008  [Tokyo's subway is shut down amid fears over a..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_df = pd.DataFrame(columns=['id','postText'])\n",
    "with open('data/instances.jsonl') as data:\n",
    "\tfor instanceobj in data:\n",
    "\t\tinstance = json.loads(instanceobj)\n",
    "\t\tinstancerow = {'id': instance['id'], 'postText': instance['postText']}\n",
    "\t\tinstances_df = instances_df.append(instancerow, ignore_index=True)\n",
    "instances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  \\\n",
       "0  UK’s response to modern slavery leaving victim...     0.000000   \n",
       "1                                       this is good     1.000000   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...     0.333333   \n",
       "3               Meet the happiest #dog in the world!     1.000000   \n",
       "4  Tokyo's subway is shut down amid fears over an...     0.000000   \n",
       "\n",
       "     truthClass  truthMean  \n",
       "0  no-clickbait   0.133333  \n",
       "1     clickbait   1.000000  \n",
       "2  no-clickbait   0.466667  \n",
       "3     clickbait   0.933333  \n",
       "4  no-clickbait   0.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = instances_df.join(truth_df.set_index('id'), on='id')\n",
    "dataset = dataset.drop(labels='id',axis=1)\n",
    "for i in range(len(dataset)):\n",
    "    dataset['postText'].values[i] = dataset['postText'].values[i][0]\n",
    "dataset['postText'].dropna(inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  UK’s response to modern slavery leaving victim...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...            1           0   \n",
       "3               Meet the happiest #dog in the world!            3           1   \n",
       "4  Tokyo's subway is shut down amid fears over an...            0           0   \n",
       "\n",
       "   truthMean  \n",
       "0   0.133333  \n",
       "1   1.000000  \n",
       "2   0.466667  \n",
       "3   0.933333  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toBinary(truthClass):\n",
    "    if truthClass == 'no-clickbait':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "dataset['truthClass'] = dataset['truthClass'].apply(toBinary)\n",
    "\n",
    "def toInteger(truthMedian):\n",
    "    return round(truthMedian*3)\n",
    "dataset['truthMedian'] = dataset['truthMedian'].apply(toInteger)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "      <th>cleanPostText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>this is good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  UK’s response to modern slavery leaving victim...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...            1           0   \n",
       "3               Meet the happiest #dog in the world!            3           1   \n",
       "4  Tokyo's subway is shut down amid fears over an...            0           0   \n",
       "\n",
       "   truthMean                                      cleanPostText  \n",
       "0   0.133333  uks response to modern slavery leaving victims...  \n",
       "1   1.000000                                       this is good  \n",
       "2   0.466667  the forgotten trump roast relive his brutal 20...  \n",
       "3   0.933333                 meet the happiest dog in the world  \n",
       "4   0.000000  tokyos subway is shut down amid fears over an ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    return text\n",
    "dataset['cleanPostText'] = dataset['postText'].apply(cleanText)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "      <th>cleanPostText</th>\n",
       "      <th>numOfPunctuation</th>\n",
       "      <th>numOfPunctuationNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>this is good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           postText  truthMedian  \\\n",
       "0      0  UK’s response to modern slavery leaving victim...            0   \n",
       "1      1                                       this is good            3   \n",
       "2      2  The \"forgotten\" Trump roast: Relive his brutal...            1   \n",
       "3      3               Meet the happiest #dog in the world!            3   \n",
       "4      4  Tokyo's subway is shut down amid fears over an...            0   \n",
       "\n",
       "   truthClass  truthMean                                      cleanPostText  \\\n",
       "0           0   0.133333  uks response to modern slavery leaving victims...   \n",
       "1           1   1.000000                                       this is good   \n",
       "2           0   0.466667  the forgotten trump roast relive his brutal 20...   \n",
       "3           1   0.933333                 meet the happiest dog in the world   \n",
       "4           0   0.000000  tokyos subway is shut down amid fears over an ...   \n",
       "\n",
       "   numOfPunctuation  numOfPunctuationNorm  \n",
       "0                 1              0.066667  \n",
       "1                 0              0.000000  \n",
       "2                 3              0.200000  \n",
       "3                 2              0.133333  \n",
       "4                 1              0.066667  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_punc(postText):\n",
    "    return len(postText)\n",
    "dataset['numOfPunctuation'] =  dataset['postText'].apply(count_punc) - dataset['cleanPostText'].apply(count_punc)\n",
    "dataset.drop(dataset[dataset['numOfPunctuation']>15].index , inplace = True)\n",
    "dataset = dataset.reset_index()\n",
    "numOfPunctuation = dataset[['numOfPunctuation']].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "dataset['numOfPunctuationNorm'] = min_max_scaler.fit_transform(numOfPunctuation)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "      <th>postText</th>\n",
       "      <th>numOfPunctuation</th>\n",
       "      <th>numOfPunctuationNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>this is good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  truthMedian  truthClass  truthMean  \\\n",
       "0      0            0           0   0.133333   \n",
       "1      1            3           1   1.000000   \n",
       "2      2            1           0   0.466667   \n",
       "3      3            3           1   0.933333   \n",
       "4      4            0           0   0.000000   \n",
       "\n",
       "                                            postText  numOfPunctuation  \\\n",
       "0  uks response to modern slavery leaving victims...                 1   \n",
       "1                                       this is good                 0   \n",
       "2  the forgotten trump roast relive his brutal 20...                 3   \n",
       "3                 meet the happiest dog in the world                 2   \n",
       "4  tokyos subway is shut down amid fears over an ...                 1   \n",
       "\n",
       "   numOfPunctuationNorm  \n",
       "0              0.066667  \n",
       "1              0.000000  \n",
       "2              0.200000  \n",
       "3              0.133333  \n",
       "4              0.066667  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop(['postText'],axis=1)\n",
    "dataset = dataset.rename(columns = {'cleanPostText': 'postText'}, inplace = False)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfPunctuation']>0)])\n",
    "# non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yuanb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "      <th>postText</th>\n",
       "      <th>numOfPunctuation</th>\n",
       "      <th>numOfPunctuationNorm</th>\n",
       "      <th>stemmingPostText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>uk respons to modern slaveri leav victim desti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>this is good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>thi is good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>the forgotten trump roast reliv hi brutal 2004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>tokyo subway is shut down amid fear over an im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  truthMedian  truthClass  truthMean  \\\n",
       "0      0            0           0   0.133333   \n",
       "1      1            3           1   1.000000   \n",
       "2      2            1           0   0.466667   \n",
       "3      3            3           1   0.933333   \n",
       "4      4            0           0   0.000000   \n",
       "\n",
       "                                            postText  numOfPunctuation  \\\n",
       "0  uks response to modern slavery leaving victims...                 1   \n",
       "1                                       this is good                 0   \n",
       "2  the forgotten trump roast relive his brutal 20...                 3   \n",
       "3                 meet the happiest dog in the world                 2   \n",
       "4  tokyos subway is shut down amid fears over an ...                 1   \n",
       "\n",
       "   numOfPunctuationNorm                                   stemmingPostText  \n",
       "0              0.066667  uk respons to modern slaveri leav victim desti...  \n",
       "1              0.000000                                        thi is good  \n",
       "2              0.200000  the forgotten trump roast reliv hi brutal 2004...  \n",
       "3              0.133333                 meet the happiest dog in the world  \n",
       "4              0.066667  tokyo subway is shut down amid fear over an im...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import download\n",
    "download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "def stemming(postText):\n",
    "    ps = PorterStemmer()\n",
    "    sentence = word_tokenize(postText)\n",
    "    newsentence = []\n",
    "    for word in sentence:\n",
    "        newsentence.append(ps.stem(word))\n",
    "    return ' '.join(newsentence)\n",
    "dataset['stemmingPostText'] = dataset['postText'].apply(stemming)\n",
    "#dataset['postText'] = dataset['postText'].apply(stemming)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['your', 'here', 'whi', 'these', 'thing', 'most', 'best', 'know', 'need', 'do', 'way', 'so', 'when', 'reveal', 'should', 'they', 'top', 'stori', 'some', 'happen']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "dataset_cb = dataset[dataset['truthClass'] == 1]\n",
    "dataset_ncb = dataset[dataset['truthClass'] == 0]\n",
    "cb_words_tuple = Counter(\" \".join(dataset_cb[\"stemmingPostText\"]).split()).most_common(300)\n",
    "cb_words = [words for (words, count) in cb_words_tuple] \n",
    "non_cb_words_tuple = Counter(\" \".join(dataset_ncb[\"stemmingPostText\"]).split()).most_common(350)\n",
    "non_cb_words = [words for (words, count) in non_cb_words_tuple] \n",
    "true_cb_words = []\n",
    "for i in range(len(cb_words)):\n",
    "    word = cb_words[i]\n",
    "    if word not in non_cb_words[:50+i] and not word.isnumeric():\n",
    "        true_cb_words.append(word)\n",
    "#print(len(true_cb_words))\n",
    "print(true_cb_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "      <th>postText</th>\n",
       "      <th>numOfPunctuation</th>\n",
       "      <th>numOfPunctuationNorm</th>\n",
       "      <th>stemmingPostText</th>\n",
       "      <th>clickbaitWords</th>\n",
       "      <th>clickbaitWordsNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>uk respons to modern slaveri leav victim desti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>this is good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>thi is good</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>the forgotten trump roast reliv hi brutal 2004...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>tokyo subway is shut down amid fear over an im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  truthMedian  truthClass  truthMean  \\\n",
       "0      0            0           0   0.133333   \n",
       "1      1            3           1   1.000000   \n",
       "2      2            1           0   0.466667   \n",
       "3      3            3           1   0.933333   \n",
       "4      4            0           0   0.000000   \n",
       "\n",
       "                                            postText  numOfPunctuation  \\\n",
       "0  uks response to modern slavery leaving victims...                 1   \n",
       "1                                       this is good                 0   \n",
       "2  the forgotten trump roast relive his brutal 20...                 3   \n",
       "3                 meet the happiest dog in the world                 2   \n",
       "4  tokyos subway is shut down amid fears over an ...                 1   \n",
       "\n",
       "   numOfPunctuationNorm                                   stemmingPostText  \\\n",
       "0              0.066667  uk respons to modern slaveri leav victim desti...   \n",
       "1              0.000000                                        thi is good   \n",
       "2              0.200000  the forgotten trump roast reliv hi brutal 2004...   \n",
       "3              0.133333                 meet the happiest dog in the world   \n",
       "4              0.066667  tokyo subway is shut down amid fear over an im...   \n",
       "\n",
       "   clickbaitWords  clickbaitWordsNorm  \n",
       "0               0               0.000  \n",
       "1               1               0.125  \n",
       "2               0               0.000  \n",
       "3               0               0.000  \n",
       "4               0               0.000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countlist = []\n",
    "for index, row in dataset.iterrows(): \n",
    "    words = row[\"postText\"].split()\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word in true_cb_words:\n",
    "            count += 1 \n",
    "    countlist.append(count)\n",
    "dataset['clickbaitWords'] = countlist\n",
    "numOfCbWords = dataset[['clickbaitWords']].values\n",
    "dataset['clickbaitWordsNorm'] = min_max_scaler.fit_transform(numOfCbWords)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5529634300126104"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The percentage of [#clickbait titles with clickbait words] over [#clickbait title]\n",
    "clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "clickbait_with_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['clickbaitWords']>0)])\n",
    "clickbait_with_cb_words_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6873984840281537"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The percentage of [#non-clickbait titles without clickbait words] over [#non-clickbait titles]\n",
    "non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==0) & (dataset['clickbaitWords']==0)])\n",
    "non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "      <th>postText</th>\n",
       "      <th>numOfPunctuation</th>\n",
       "      <th>numOfPunctuationNorm</th>\n",
       "      <th>stemmingPostText</th>\n",
       "      <th>clickbaitWords</th>\n",
       "      <th>clickbaitWordsNorm</th>\n",
       "      <th>numOfNumerics</th>\n",
       "      <th>numOfNumericsNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>uk respons to modern slaveri leav victim desti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>this is good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>thi is good</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>the forgotten trump roast reliv hi brutal 2004...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>tokyo subway is shut down amid fear over an im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  truthMedian  truthClass  truthMean  \\\n",
       "0      0            0           0   0.133333   \n",
       "1      1            3           1   1.000000   \n",
       "2      2            1           0   0.466667   \n",
       "3      3            3           1   0.933333   \n",
       "4      4            0           0   0.000000   \n",
       "\n",
       "                                            postText  numOfPunctuation  \\\n",
       "0  uks response to modern slavery leaving victims...                 1   \n",
       "1                                       this is good                 0   \n",
       "2  the forgotten trump roast relive his brutal 20...                 3   \n",
       "3                 meet the happiest dog in the world                 2   \n",
       "4  tokyos subway is shut down amid fears over an ...                 1   \n",
       "\n",
       "   numOfPunctuationNorm                                   stemmingPostText  \\\n",
       "0              0.066667  uk respons to modern slaveri leav victim desti...   \n",
       "1              0.000000                                        thi is good   \n",
       "2              0.200000  the forgotten trump roast reliv hi brutal 2004...   \n",
       "3              0.133333                 meet the happiest dog in the world   \n",
       "4              0.066667  tokyo subway is shut down amid fear over an im...   \n",
       "\n",
       "   clickbaitWords  clickbaitWordsNorm  numOfNumerics  numOfNumericsNorm  \n",
       "0               0               0.000              0              0.000  \n",
       "1               1               0.125              0              0.000  \n",
       "2               0               0.000              1              0.125  \n",
       "3               0               0.000              0              0.000  \n",
       "4               0               0.000              0              0.000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberCountlist = []\n",
    "for index, row in dataset.iterrows(): \n",
    "    words = row[\"postText\"].split()\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word.isnumeric():\n",
    "            count += 1 \n",
    "    numberCountlist.append(count)\n",
    "dataset['numOfNumerics'] = numberCountlist\n",
    "numOfNumerics = dataset[['numOfNumerics']].values\n",
    "dataset['numOfNumericsNorm'] = min_max_scaler.fit_transform(numOfNumerics)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22131147540983606"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The percentage of [#clickbait titles with numOfnumerics words] over [#clickbait title]\n",
    "clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfNumerics']>0)])\n",
    "clickbait_with_numerics_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15944775311315648"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The percentage of [#non-clickbait titles without numOfnumerics words] over [#non-clickbait titles]\n",
    "non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "non_clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==0) & (dataset['numOfNumerics']>0)])\n",
    "non_clickbait_with_numerics_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from subject_verb_object_extract import findSVOs, nlp\n",
    "# def extract(postText):\n",
    "#     tokens1 = nlp(postText)\n",
    "#     svos1 = findSVOs(tokens1)\n",
    "#     return svos1\n",
    "\n",
    "# dataset['SVO'] = dataset['postText'].apply(extract)\n",
    "# dataset.head()\n",
    "# president trump slams reporters use of anonymous sources despite using them himself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the glove word embedding file\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of titles with longest words\n",
    "maxLen = 0\n",
    "for i in range(len(dataset)):\n",
    "    sentence = dataset[\"postText\"][i]\n",
    "    if len(sentence.split()) > maxLen:\n",
    "        maxLen = len(sentence.split())\n",
    "        maxstr = sentence\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset to training and testing set\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "X_train, Y_train, Y_train_mean = np.array(train[\"postText\"].tolist()), np.array(train[\"truthMedian\"].tolist()), np.array(train[\"truthMean\"].tolist())\n",
    "# positive_test = test[test[\"truthClass\"] == 1].sample(n=900)\n",
    "# negative_test = test[test[\"truthClass\"] == 0].sample(n=900)\n",
    "# test = pd.concat([negative_test, positive_test]).sample(frac=1)\n",
    "X_test, Y_test, Y_test_mean = np.array(test[\"postText\"].tolist()), np.array(test[\"truthClass\"].tolist()), np.array(test[\"truthMean\"].tolist())\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):   \n",
    "    m = X.shape[0]  # number of training examples\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape \n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    for i in range(m):          \n",
    "        # Convert the ith training sentence in lower case and split is into words\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index.keys():\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j = j + 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indices = sentences_to_indices(X_train,word_to_index, maxLen)\n",
    "print(\"X_Train_indices =\\n\", Indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1        \n",
    "    # define dimensionality of your GloVe word vectors (= 50)\n",
    "    emb_dim = word_to_vec_map[\"happy\"].shape[0]      \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    # See instructions above to choose the correct shape.\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_len,emb_dim,trainable = False)\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,)) \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClickBait_LSTM(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with 2 units\n",
    "    X = Dense(4)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)  \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClickBait_LSTM((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 4)\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 20, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_binary(data):\n",
    "    binary = []\n",
    "    for i in range(len(data)):\n",
    "        if 2/3*data[i][3] + 1/3*data[i][2] > 2/3*data[i][0] + 1/3*data[i][1]:\n",
    "        #if data[i][3] + data[i][2] > data[i][0] + data[i][1]:\n",
    "            binary.append(1)\n",
    "        else:\n",
    "            binary.append(0)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,roc_auc_score, mean_squared_error \n",
    "y_train_pred_oh = model.predict(X_train_indices)\n",
    "y_train_pred_binary = onehot_to_binary(y_train_pred_oh)\n",
    "Y_train_binary = onehot_to_binary(Y_train_oh)\n",
    "\n",
    "print(\"Training Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_train_binary, y_train_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_train_binary, y_train_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_train_mean, y_train_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "y_pred_onehot = model.predict(X_test_indices)\n",
    "y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "\n",
    "print(\"Testing Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_test, y_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_test, y_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_test, y_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_test, y_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_test_mean, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum MSE %s' % mean_squared_error(Y_test_mean, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Error Analysis\n",
    "for i in range(1000):\n",
    "    if Y_test[i] - y_pred_binary[i] != 0:\n",
    "        print(X_test[i])\n",
    "        print(\"Actual Label\",Y_test[i])\n",
    "        print(\"Prediction Lable\",y_pred_binary[i])\n",
    "        print(\"Prediction\",y_pred_onehot[i])\n",
    "        print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test(test_string):\n",
    "    test_string = cleanText(test_string)\n",
    "    test = np.array([test_string])\n",
    "    test_indices = sentences_to_indices(test, word_to_index, max_len = maxLen)\n",
    "    y_pred_onehot = model.predict(test_indices)\n",
    "    y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "    if y_pred_binary == [1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "test_string = \"US election 2020: What is the presidential transition\"\n",
    "test(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
