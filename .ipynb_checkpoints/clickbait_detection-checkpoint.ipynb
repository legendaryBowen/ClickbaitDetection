{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yuanb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858464162594172928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858460992073863168</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858459539296980995</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858455355948384257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  truthMedian    truthClass  truthMean\n",
       "0  858464162594172928     1.000000     clickbait   1.000000\n",
       "1  858462320779026433     0.000000  no-clickbait   0.133333\n",
       "2  858460992073863168     0.333333  no-clickbait   0.400000\n",
       "3  858459539296980995     0.333333  no-clickbait   0.266667\n",
       "4  858455355948384257     0.000000  no-clickbait   0.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_df = pd.DataFrame(columns=['id','truthMedian','truthClass','truthMean'])\n",
    "with open('data/truth.jsonl') as data:\n",
    "    for labelobj in data:\n",
    "        truth = json.loads(labelobj)\n",
    "        truthlabel = {'id': truth['id'], 'truthMedian': truth['truthMedian'], 'truthClass': truth['truthClass'], 'truthMean': truth['truthMean']}\n",
    "        truth_df = truth_df.append(truthlabel, ignore_index = True)\n",
    "truth_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>postText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>[UK’s response to modern slavery leaving victi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858421020331560960</td>\n",
       "      <td>[this is good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858368123753435136</td>\n",
       "      <td>[The \"forgotten\" Trump roast: Relive his bruta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858323428260139008</td>\n",
       "      <td>[Meet the happiest #dog in the world!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858283602626347008</td>\n",
       "      <td>[Tokyo's subway is shut down amid fears over a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           postText\n",
       "0  858462320779026433  [UK’s response to modern slavery leaving victi...\n",
       "1  858421020331560960                                     [this is good]\n",
       "2  858368123753435136  [The \"forgotten\" Trump roast: Relive his bruta...\n",
       "3  858323428260139008             [Meet the happiest #dog in the world!]\n",
       "4  858283602626347008  [Tokyo's subway is shut down amid fears over a..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_df = pd.DataFrame(columns=['id','postText'])\n",
    "with open('data/instances.jsonl') as data:\n",
    "\tfor instanceobj in data:\n",
    "\t\tinstance = json.loads(instanceobj)\n",
    "\t\tinstancerow = {'id': instance['id'], 'postText': instance['postText']}\n",
    "\t\tinstances_df = instances_df.append(instancerow, ignore_index=True)\n",
    "instances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  \\\n",
       "0  UK’s response to modern slavery leaving victim...     0.000000   \n",
       "1                                       this is good     1.000000   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...     0.333333   \n",
       "3               Meet the happiest #dog in the world!     1.000000   \n",
       "4  Tokyo's subway is shut down amid fears over an...     0.000000   \n",
       "\n",
       "     truthClass  truthMean  \n",
       "0  no-clickbait   0.133333  \n",
       "1     clickbait   1.000000  \n",
       "2  no-clickbait   0.466667  \n",
       "3     clickbait   0.933333  \n",
       "4  no-clickbait   0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = instances_df.join(truth_df.set_index('id'), on='id')\n",
    "dataset = dataset.drop(labels='id',axis=1)\n",
    "for i in range(len(dataset)):\n",
    "    dataset['postText'].values[i] = dataset['postText'].values[i][0]\n",
    "dataset['postText'].dropna(inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  UK’s response to modern slavery leaving victim...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...            1           0   \n",
       "3               Meet the happiest #dog in the world!            3           1   \n",
       "4  Tokyo's subway is shut down amid fears over an...            0           0   \n",
       "\n",
       "   truthMean  \n",
       "0   0.133333  \n",
       "1   1.000000  \n",
       "2   0.466667  \n",
       "3   0.933333  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toBinary(truthClass):\n",
    "    if truthClass == 'no-clickbait':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "dataset['truthClass'] = dataset['truthClass'].apply(toBinary)\n",
    "\n",
    "def toInteger(truthMedian):\n",
    "    return round(truthMedian*3)\n",
    "dataset['truthMedian'] = dataset['truthMedian'].apply(toInteger)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  uks response to modern slavery leaving victims...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  the forgotten trump roast relive his brutal 20...            1           0   \n",
       "3                 meet the happiest dog in the world            3           1   \n",
       "4  tokyos subway is shut down amid fears over an ...            0           0   \n",
       "\n",
       "   truthMean  \n",
       "0   0.133333  \n",
       "1   1.000000  \n",
       "2   0.466667  \n",
       "3   0.933333  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    return text\n",
    "dataset['postText'] = dataset['postText'].apply(cleanText)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_punc(postText):\n",
    "#     return len(postText)\n",
    "# dataset['numOfPunctuation'] =  dataset['postText'].apply(count_punc) - dataset['cleanPostText'].apply(count_punc)\n",
    "# dataset.drop(dataset[dataset['numOfPunctuation']>15].index , inplace = True)\n",
    "# dataset = dataset.reset_index()\n",
    "# numOfPunctuation = dataset[['numOfPunctuation']].values\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# dataset['numOfPunctuationNorm'] = min_max_scaler.fit_transform(numOfPunctuation)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.drop(['postText'],axis=1)\n",
    "# dataset = dataset.rename(columns = {'cleanPostText': 'postText'}, inplace = False)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfPunctuation']>0)])\n",
    "# non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import download\n",
    "# download('punkt')\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# def stemming(postText):\n",
    "#     ps = PorterStemmer()\n",
    "#     sentence = word_tokenize(postText)\n",
    "#     newsentence = []\n",
    "#     for word in sentence:\n",
    "#         newsentence.append(ps.stem(word))\n",
    "#     return ' '.join(newsentence)\n",
    "# dataset['stemmingPostText'] = dataset['postText'].apply(stemming)\n",
    "# #dataset['postText'] = dataset['postText'].apply(stemming)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# dataset_cb = dataset[dataset['truthClass'] == 1]\n",
    "# dataset_ncb = dataset[dataset['truthClass'] == 0]\n",
    "# cb_words_tuple = Counter(\" \".join(dataset_cb[\"stemmingPostText\"]).split()).most_common(300)\n",
    "# cb_words = [words for (words, count) in cb_words_tuple] \n",
    "# non_cb_words_tuple = Counter(\" \".join(dataset_ncb[\"stemmingPostText\"]).split()).most_common(350)\n",
    "# non_cb_words = [words for (words, count) in non_cb_words_tuple] \n",
    "# true_cb_words = []\n",
    "# for i in range(len(cb_words)):\n",
    "#     word = cb_words[i]\n",
    "#     if word not in non_cb_words[:50+i] and not word.isnumeric():\n",
    "#         true_cb_words.append(word)\n",
    "# #print(len(true_cb_words))\n",
    "# print(true_cb_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countlist = []\n",
    "# for index, row in dataset.iterrows(): \n",
    "#     words = row[\"postText\"].split()\n",
    "#     count = 0\n",
    "#     for word in words:\n",
    "#         if word in true_cb_words:\n",
    "#             count += 1 \n",
    "#     countlist.append(count)\n",
    "# dataset['clickbaitWords'] = countlist\n",
    "# numOfCbWords = dataset[['clickbaitWords']].values\n",
    "# dataset['clickbaitWordsNorm'] = min_max_scaler.fit_transform(numOfCbWords)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#clickbait titles with clickbait words] over [#clickbait title]\n",
    "# clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# clickbait_with_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['clickbaitWords']>0)])\n",
    "# clickbait_with_cb_words_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#non-clickbait titles without clickbait words] over [#non-clickbait titles]\n",
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "# non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==0) & (dataset['clickbaitWords']==0)])\n",
    "# non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numberCountlist = []\n",
    "# for index, row in dataset.iterrows(): \n",
    "#     words = row[\"postText\"].split()\n",
    "#     count = 0\n",
    "#     for word in words:\n",
    "#         if word.isnumeric():\n",
    "#             count += 1 \n",
    "#     numberCountlist.append(count)\n",
    "# dataset['numOfNumerics'] = numberCountlist\n",
    "# numOfNumerics = dataset[['numOfNumerics']].values\n",
    "# dataset['numOfNumericsNorm'] = min_max_scaler.fit_transform(numOfNumerics)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#clickbait titles with numOfnumerics words] over [#clickbait title]\n",
    "# clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfNumerics']>0)])\n",
    "# clickbait_with_numerics_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#non-clickbait titles without numOfnumerics words] over [#non-clickbait titles]\n",
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "# non_clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==0) & (dataset['numOfNumerics']>0)])\n",
    "# non_clickbait_with_numerics_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from subject_verb_object_extract import findSVOs, nlp\n",
    "# def extract(postText):\n",
    "#     tokens1 = nlp(postText)\n",
    "#     svos1 = findSVOs(tokens1)\n",
    "#     return svos1\n",
    "\n",
    "# dataset['SVO'] = dataset['postText'].apply(extract)\n",
    "# dataset.head()\n",
    "# president trump slams reporters use of anonymous sources despite using them himself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the glove word embedding file\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of titles with longest words\n",
    "maxLen = 0\n",
    "for i in range(len(dataset)):\n",
    "    sentence = dataset[\"postText\"][i]\n",
    "    if len(sentence.split()) > maxLen:\n",
    "        maxLen = len(sentence.split())\n",
    "        maxstr = sentence\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15630,)\n",
      "(3908,)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset to training and testing set\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "X_train, Y_train, Y_train_mean = np.array(train[\"postText\"].tolist()), np.array(train[\"truthMedian\"].tolist()), np.array(train[\"truthMean\"].tolist())\n",
    "# positive_test = test[test[\"truthClass\"] == 1].sample(n=900)\n",
    "# negative_test = test[test[\"truthClass\"] == 0].sample(n=900)\n",
    "# test = pd.concat([negative_test, positive_test]).sample(frac=1)\n",
    "X_test, Y_test, Y_test_mean = np.array(test[\"postText\"].tolist()), np.array(test[\"truthClass\"].tolist()), np.array(test[\"truthMean\"].tolist())\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):   \n",
    "    m = X.shape[0]  # number of training examples\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape \n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    for i in range(m):          \n",
    "        # Convert the ith training sentence in lower case and split is into words\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index.keys():\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j = j + 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train_indices =\n",
      " (15630, 25)\n"
     ]
    }
   ],
   "source": [
    "Indices = sentences_to_indices(X_train,word_to_index, maxLen)\n",
    "print(\"X_Train_indices =\\n\", Indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1        \n",
    "    # define dimensionality of your GloVe word vectors (= 50)\n",
    "    emb_dim = word_to_vec_map[\"happy\"].shape[0]      \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    # See instructions above to choose the correct shape.\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_len,emb_dim,trainable = False)\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,)) \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClickBait_LSTM(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with 2 units\n",
    "    X = Dense(4)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)  \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 25, 100)           40000100  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 25, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 40,381,032\n",
      "Trainable params: 380,932\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ClickBait_LSTM((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15630, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 4)\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "489/489 [==============================] - 11s 23ms/step - loss: 1.0271 - accuracy: 0.5469\n",
      "Epoch 2/20\n",
      "489/489 [==============================] - 11s 22ms/step - loss: 0.9643 - accuracy: 0.5714\n",
      "Epoch 3/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.9327 - accuracy: 0.5865\n",
      "Epoch 4/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.9155 - accuracy: 0.5885\n",
      "Epoch 5/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.8982 - accuracy: 0.5984\n",
      "Epoch 6/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.8807 - accuracy: 0.6073\n",
      "Epoch 7/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.8566 - accuracy: 0.6183\n",
      "Epoch 8/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.8253 - accuracy: 0.6296\n",
      "Epoch 9/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.7976 - accuracy: 0.6476\n",
      "Epoch 10/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.7614 - accuracy: 0.6671\n",
      "Epoch 11/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.7233 - accuracy: 0.6796\n",
      "Epoch 12/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.6791 - accuracy: 0.7066\n",
      "Epoch 13/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.6343 - accuracy: 0.7289\n",
      "Epoch 14/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.5873 - accuracy: 0.7564\n",
      "Epoch 15/20\n",
      "489/489 [==============================] - 14s 28ms/step - loss: 0.5470 - accuracy: 0.7781\n",
      "Epoch 16/20\n",
      "489/489 [==============================] - 14s 28ms/step - loss: 0.5055 - accuracy: 0.8010\n",
      "Epoch 17/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.4554 - accuracy: 0.8221\n",
      "Epoch 18/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.4140 - accuracy: 0.8443\n",
      "Epoch 19/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.3797 - accuracy: 0.8605\n",
      "Epoch 20/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.3454 - accuracy: 0.8764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c243749670>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 20, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_binary(data):\n",
    "    binary = []\n",
    "    for i in range(len(data)):\n",
    "        if 2/3*data[i][3] + 1/3*data[i][2] > 2/3*data[i][0] + 1/3*data[i][1]:\n",
    "        #if data[i][3] + data[i][2] > data[i][0] + data[i][1]:\n",
    "            binary.append(1)\n",
    "        else:\n",
    "            binary.append(0)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error\n",
      "Accuracy 0.9629558541266795\n",
      "Precision 0.9004950495049505\n",
      "Recall 0.9536041939711665\n",
      "F1 score: 0.9262889879057925\n",
      "MSE 0.08610108765052217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,roc_auc_score, mean_squared_error \n",
    "y_train_pred_oh = model.predict(X_train_indices)\n",
    "y_train_pred_binary = onehot_to_binary(y_train_pred_oh)\n",
    "Y_train_binary = onehot_to_binary(Y_train_oh)\n",
    "\n",
    "print(\"Training Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_train_binary, y_train_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_train_binary, y_train_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_train_mean, y_train_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error\n",
      "Accuracy 0.8057830092118731\n",
      "Precision 0.6\n",
      "Recall 0.5930232558139535\n",
      "F1 score: 0.5964912280701755\n",
      "MSE 0.13597293301120486\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "y_pred_onehot = model.predict(X_test_indices)\n",
    "y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "\n",
    "print(\"Testing Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_test, y_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_test, y_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_test, y_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_test, y_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_test_mean, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE 0.0785693165000994\n"
     ]
    }
   ],
   "source": [
    "print('Minimum MSE %s' % mean_squared_error(Y_test_mean, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why gopro ran into so many issues with the muchhyped karma drone\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03423018 0.3365459  0.6161318  0.01309209]\n",
      "-------------\n",
      "the sports world made sure to celebrate nationalpuppyday \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0105765  0.0289276  0.17731339 0.7831825 ]\n",
      "-------------\n",
      "midyear budget update shows these arent ordinary times writes ianverrender myefo ausbiz\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02833071 0.33255282 0.62434167 0.01477483]\n",
      "-------------\n",
      "these forbesu30asia honorees are making the personal scaleable\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04404161 0.61206627 0.336851   0.00704107]\n",
      "-------------\n",
      "how ancestral climates may have shaped your nose\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0063024  0.03368429 0.8838067  0.07620656]\n",
      "-------------\n",
      "indias most valuable bank plans to launch the countrys biggest offering of perpetual debt\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01840625 0.12369101 0.8327326  0.02517008]\n",
      "-------------\n",
      "a great grandmother has been praying to a lord of the rings figurine for years\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.62248826 0.3738961  0.00288091 0.00073464]\n",
      "-------------\n",
      "morning briefing heres what you need to know to start your day\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.08087208 0.4459365  0.40512627 0.06806511]\n",
      "-------------\n",
      "i dont have a lot of tape at safety but im a pretty damn good safety\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.05906979 0.7167639  0.2196601  0.00450624]\n",
      "-------------\n",
      "theres no stopping a woman with a dream to travel and a motorbike to get her there inspired traveldiaries \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00576893 0.04091649 0.91406715 0.03924746]\n",
      "-------------\n",
      "heres how much millionaires would save under the gop obamacare repeal bill\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [6.7313462e-02 9.1826963e-01 1.3844699e-02 5.7219504e-04]\n",
      "-------------\n",
      "miserable cat with 5 pounds of matted fur undergoes incredible transformation\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.8978442e-01 1.0177336e-02 1.3728635e-05 2.4492874e-05]\n",
      "-------------\n",
      "this is hellfire  americas missile of choice that can hit a target five miles away\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03976501 0.15713784 0.59522015 0.20787707]\n",
      "-------------\n",
      "trump thinks government is just like business  but hes about to get a big shock\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.5499075e-02 9.3656826e-01 1.7514642e-02 4.1802478e-04]\n",
      "-------------\n",
      "way to go whosunilgrover best of luck \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00995334 0.03569059 0.7488977  0.20545846]\n",
      "-------------\n",
      "the first week numbers for joeybadass allamerikkkan badass are in\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02504953 0.35837314 0.60193634 0.01464106]\n",
      "-------------\n",
      "after her towns deal with wall street her water and sewer bill has jumped so much that shes thinking about moving\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00645209 0.03980434 0.8632744  0.09046921]\n",
      "-------------\n",
      "snakes are having a ball at this bengaluru football stadium\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.4376514  0.55640763 0.00512914 0.00081184]\n",
      "-------------\n",
      "22 selfmade women who are the literal definition of black girl magic\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01537142 0.08199435 0.8101915  0.09244277]\n",
      "-------------\n",
      "morning briefing heres what you need to know to start your day\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.08087208 0.4459365  0.40512627 0.06806511]\n",
      "-------------\n",
      "scientists have apparently discovered what makes the perfect breasts\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02778168 0.5993333  0.3665995  0.00628553]\n",
      "-------------\n",
      "why nicki wouldnt let kanye appear on right thru me even though he begged\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00874496 0.04818309 0.85432154 0.08875042]\n",
      "-------------\n",
      "a luxury music festival where tickets cost up to 12000 turned into a nightmare\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7189909e-01 2.7982872e-02 5.7687874e-05 6.0329781e-05]\n",
      "-------------\n",
      "5 of the coolest healthtech gadgets we saw at ces 2017 masces\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.07036771 0.38487992 0.5197634  0.02498894]\n",
      "-------------\n",
      "analysis what ahmadinejads run says about the state of iranian politics\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0274428  0.13055985 0.8035654  0.03843192]\n",
      "-------------\n",
      "what we can expect from rex tillersons state department\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01808018 0.18755801 0.775473   0.01888878]\n",
      "-------------\n",
      "teacher becomes one of the youngest people ever to die of dementia\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.2599226e-02 9.4121301e-01 2.5593948e-02 5.9391028e-04]\n",
      "-------------\n",
      "long island murders escort claims sex with cop near serial killers dumping ground\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [7.6512778e-01 2.3260841e-01 1.6694890e-03 5.9425418e-04]\n",
      "-------------\n",
      "icymi your best pictures from around australia this week via abcopen\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.06177992 0.5637282  0.36633003 0.00816192]\n",
      "-------------\n",
      "a growing number of analysts say the iphone 8 wont feature a curved screen after all\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.09831761 0.73923445 0.15716359 0.00528434]\n",
      "-------------\n",
      "xbox scorpio does this mean its game over for the ps4\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03533143 0.31915715 0.6317802  0.01373123]\n",
      "-------------\n",
      "the worlds most breathtaking pub crawl involves a helicopter\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00472621 0.03366327 0.9056833  0.05592725]\n",
      "-------------\n",
      "heres what nasa saw when it landed on saturns largest moon\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01363012 0.05878314 0.8460711  0.08151559]\n",
      "-------------\n",
      "former brady bunch star under fire after report of homophobic rant\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04168296 0.89331764 0.06345353 0.0015458 ]\n",
      "-------------\n",
      "9 people pose nude to show what body diversity really looks like\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.05156884 0.9046925  0.04269562 0.00104311]\n",
      "-------------\n",
      "who is ann donnelly the federal judge who blocked part of president trumps executive order on immigration\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.30980548 0.6779641  0.01094095 0.00128937]\n",
      "-------------\n",
      "an alcoholfueled obscenity and racial slurlaced tirade have cost a miami senator his job\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.1501266e-01 8.4345035e-02 3.8693979e-04 2.5544813e-04]\n",
      "-------------\n",
      "how victorias secret angels unwind after the show  vsfashionshow\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.1506919e-01 7.7599549e-01 8.1762020e-03 7.5905863e-04]\n",
      "-------------\n",
      "heres trumps plan to keep jobs in america\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.59057504 0.4045323  0.00381187 0.00108072]\n",
      "-------------\n",
      "yes i pelted stones yesterday but thats not what i want to do respect \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00572547 0.02305938 0.7420913  0.22912389]\n",
      "-------------\n",
      "baby dressed as a lion meets the real king of the jungle and its adorable\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [6.2902458e-02 9.1981369e-01 1.6650679e-02 6.3319685e-04]\n",
      "-------------\n",
      "will trump let his family run his empire\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.9304223e-02 9.3535930e-01 2.4650225e-02 6.8626873e-04]\n",
      "-------------\n",
      "donald trump wasnt happy with his state department finalists then he heard a new name\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.5700878e-01 4.2769998e-02 1.1828270e-04 1.0295501e-04]\n",
      "-------------\n",
      "kentucky teacher gets prison time for sex with underage student\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7749001e-01 2.2419864e-02 4.1447591e-05 4.8653852e-05]\n",
      "-------------\n",
      "could it also be time for a fresh wave of rachel dolezals and shaun kings\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.10090073 0.85522574 0.0422063  0.00166723]\n",
      "-------------\n",
      "our 2017 tax guide is here\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.7405865e-02 9.3062180e-01 2.1295000e-02 6.7726936e-04]\n",
      "-------------\n",
      "i felt lonely when i shared that photo social media v reality at christmas\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03505321 0.8829344  0.08041979 0.00159251]\n",
      "-------------\n",
      "we know where mh370 is scientists call for new search for missing jet\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03904716 0.3350033  0.6120106  0.01393901]\n",
      "-------------\n",
      "people are hysterical because cats are now allowed in the westminster dog show\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01067707 0.07821713 0.88713926 0.02396648]\n",
      "-------------\n",
      "how donald trumps calls to world leaders are upsetting decades of diplomacy\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.3406229e-01 8.5389006e-01 1.1336547e-02 7.1107672e-04]\n",
      "-------------\n",
      "walmart is reportedly about to buy the hottest mens clothing brand\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.8363566e-01 1.6304359e-02 2.4932968e-05 3.5045588e-05]\n",
      "-------------\n",
      "people have discovered the perfect way to mess with your cat\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.05100265 0.5165361  0.42291075 0.00955046]\n",
      "-------------\n",
      "marine le pen could be jailed for three years for distributing violent images over isis beheading tweets\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00983785 0.12048711 0.84782606 0.02184907]\n",
      "-------------\n",
      "its time to talk about one tree hill and the worst character on the show\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00725212 0.06425603 0.89712054 0.03137133]\n",
      "-------------\n",
      "see the incredible view of earth from spacexs historic mission\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00619062 0.05107822 0.907124   0.03560722]\n",
      "-------------\n",
      "a gang leader was sentenced in a fellow members stabbing decapitation\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.8577756e-01 1.4175093e-02 1.9443383e-05 2.7968395e-05]\n",
      "-------------\n",
      "grabbed them and attempted to drag them into a spare room\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.47103715 0.5227311  0.0051616  0.00107007]\n",
      "-------------\n",
      "you are not alone depression mentalhealth support\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01398906 0.12511885 0.8314008  0.02949128]\n",
      "-------------\n",
      "adpvoice does unlimited vacation time really work and for whom\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00860179 0.06794489 0.8750451  0.04840812]\n",
      "-------------\n",
      "despite the yuck factor leeches are big in russian medicine\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02242681 0.28165627 0.68247116 0.01344576]\n",
      "-------------\n",
      "a policeman on duty repeatedly slapped a retired soldier in a bank queue\n",
      "thisisit shameful\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.6434153  0.35221264 0.00345164 0.00092048]\n",
      "-------------\n",
      "heres why people love these llbean boots that sell out every winter\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02061211 0.07519611 0.6287979  0.27539393]\n",
      "-------------\n",
      "is a vegetarian diet really more environmentally friendly than eating meat\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01214344 0.12995194 0.8401013  0.01780325]\n",
      "-------------\n",
      "their dream build a website that people would visit every day that wasnt pornography\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03257862 0.4434731  0.51434004 0.00960829]\n",
      "-------------\n",
      "nicki minaj and aretha franklin are tied for the most hot 100 songs by a woman\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.6978666  0.29884782 0.00257874 0.00070686]\n",
      "-------------\n",
      "woman experimented on by nazis in bid to create aryan race reveals her lifelong search to find her true identity\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01739557 0.20375481 0.7629474  0.01590221]\n",
      "-------------\n",
      "gut bacteria might be the secret to treating autoimmune disease\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00508503 0.04919739 0.92108494 0.02463258]\n",
      "-------------\n",
      "this guy came up with a brilliant idea for solving dinner fights with his girlfriend\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.08149255 0.537158   0.36140165 0.01994782]\n",
      "-------------\n",
      "united airlines is no angel\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01012189 0.12683277 0.83831805 0.02472726]\n",
      "-------------\n",
      "in space no one can hear you scream with excitement\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.29252055 0.6992401  0.00739443 0.00084493]\n",
      "-------------\n",
      "google just uncovered the most dangerous android malware ever seen\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.3942851  0.5979891  0.00675846 0.00096735]\n",
      "-------------\n",
      "get ready for a bond meltdown\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02391992 0.8650022  0.10910863 0.00196927]\n",
      "-------------\n",
      "jennifer lopez amp alex rodriguez are reportedly dating\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02244578 0.35581732 0.60872155 0.01301529]\n",
      "-------------\n",
      "thx 4 clearing that up 4 us\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.3147138e-01 8.5780692e-01 1.0056682e-02 6.6494639e-04]\n",
      "-------------\n",
      "the tragic life of the princess with the sad eyes revealed\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [6.3358493e-02 9.1556752e-01 2.0421900e-02 6.5209105e-04]\n",
      "-------------\n",
      "former buddhist monk killed himself\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01003954 0.13152286 0.82949877 0.02893891]\n",
      "-------------\n",
      "nhl star recalls double life under fugitive dad\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.46777493 0.5258023  0.00529965 0.00112308]\n",
      "-------------\n",
      "revealed 10 of the most unusual homes for sale in 2016\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.14838374 0.7093304  0.13515967 0.00712617]\n",
      "-------------\n",
      "5 nba trades we want to see before the deadline\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.6280477e-02 9.2523324e-01 2.7883418e-02 6.0292199e-04]\n",
      "-------------\n",
      "vietnamese villagers free police hostages\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01589254 0.25728852 0.708767   0.01805201]\n",
      "-------------\n",
      "plussize guys tried asos new plussize line for men and totally slayed\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04217532 0.7907439  0.16449545 0.00258538]\n",
      "-------------\n",
      "schizophrenia risk for babies of pregnant mothers on diets\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0046037  0.03507248 0.92647266 0.03385111]\n",
      "-------------\n",
      "a mexican populist rises to face trumps america\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02551231 0.89171666 0.08138274 0.00138832]\n",
      "-------------\n",
      "irs phone scammers are getting more sophisticated\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.24158043 0.7492396  0.00832429 0.00085569]\n",
      "-------------\n",
      "ll bean recalls 3000 pairs of adjustable snowshoes\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02254806 0.40106165 0.56533056 0.01105966]\n",
      "-------------\n",
      "how coachella gained lady gaga after losing beyonce\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.7006557e-02 9.5040518e-01 1.2322250e-02 2.6603014e-04]\n",
      "-------------\n",
      "scientists claim breakthrough shows ageing process could be reversed\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.43390355 0.55948967 0.00559221 0.00101454]\n",
      "-------------\n",
      "a porn site decided to step in when this state voted against sex education\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01623107 0.08186565 0.8258019  0.07610133]\n",
      "-------------\n",
      "icymi woah where did that giant sinkhole come from sinkholes explained\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.676724e-02 9.367358e-01 1.599307e-02 5.038409e-04]\n",
      "-------------\n",
      "catch up on all the news you missed today\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [6.7107186e-02 9.0579456e-01 2.6367415e-02 7.3084427e-04]\n",
      "-------------\n",
      "new tool lets you customize what kinds of online ads you see\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02424189 0.17056833 0.77634156 0.02884826]\n",
      "-------------\n",
      "chris pratt officially weighs in on that jurassic world theory\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.62726057 0.36877313 0.00302661 0.00093967]\n",
      "-------------\n",
      "the inside story from beginning to end of the stolen jersey\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [6.7253754e-02 9.0973520e-01 2.2341290e-02 6.6974125e-04]\n",
      "-------------\n",
      "paul ryan dabbed and now everyones dragging him for it\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00666069 0.04282645 0.9000327  0.05048019]\n",
      "-------------\n",
      "deck the halls with a look back at the kardashian christmas cards through the years\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02112835 0.17290264 0.78163093 0.02433798]\n",
      "-------------\n",
      "seahawks receiver paul richardson just made one of the craziest catches we can remember\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00475328 0.02567783 0.85004157 0.11952738]\n",
      "-------------\n",
      "a timeline of events surrounding the suspicious death of prominent new york judge\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.0820326  0.7922806  0.12222917 0.00345759]\n",
      "-------------\n",
      "a 3yearold did a reddit ama and it is honestly the purest thing\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03271778 0.4487058  0.5076914  0.01088503]\n",
      "-------------\n",
      "i lost all my fingers asylum seekers make dangerous border crossing\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.0632930e-02 8.9178890e-01 1.6823821e-02 7.5436203e-04]\n",
      "-------------\n",
      "watch the obamas share dad jokes and more in their final holiday address\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00586569 0.02472594 0.77595353 0.19345482]\n",
      "-------------\n",
      "27 of our 2017 30under30 want their business to change the world\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00998409 0.0463074  0.8590541  0.08465446]\n",
      "-------------\n",
      "getting newborn babies to sleep involves cutting yourself some slack  health\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00609508 0.03922037 0.9074357  0.04724877]\n",
      "-------------\n",
      "shadowy portuguese hacker who rocked brand beckham with email expose is now on the run\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02802167 0.21219997 0.7435676  0.01621087]\n",
      "-------------\n",
      "liz truss could do for prison food what jamie oliver did in schools  lucy vincent\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00984862 0.05845607 0.88305527 0.04864012]\n",
      "-------------\n",
      "heres how photog anthonysupreme finds inspiration in las lesser known spots  promo\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04247883 0.6600076  0.29205897 0.00545463]\n",
      "-------------\n",
      "the 7 most expensive tv shows ever made\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00888446 0.02318925 0.14860389 0.8193224 ]\n",
      "-------------\n",
      "when listening to music through headphones how loud is too loud for kids\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.4215814e-01 8.4521478e-01 1.1877963e-02 7.4910908e-04]\n",
      "-------------\n",
      "rajkummarraos trapped looks promising \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00500075 0.03868699 0.8866463  0.06966601]\n",
      "-------------\n",
      "awesome teacher pranks students with gibberishfilled spelling test\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03352154 0.8094569  0.15458368 0.00243796]\n",
      "-------------\n",
      "just 28 perfect tweets from women about the oscars\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.07213813 0.822895   0.10237937 0.0025875 ]\n",
      "-------------\n",
      "the trailer for this summers shark movie just dropped\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04908167 0.88519245 0.06444483 0.0012811 ]\n",
      "-------------\n",
      "quote of the day\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.1171304e-01 1.8603754e-01 1.4856922e-03 7.6364574e-04]\n",
      "-------------\n",
      "chance the rapper just wants us all to relax and listen to his bath playlist\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.26211902 0.72855586 0.00853954 0.00078561]\n",
      "-------------\n",
      "jeff bezos tested this giant robot suit\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01212771 0.09805628 0.8639849  0.0258311 ]\n",
      "-------------\n",
      "sushmaswaraj is the perfect example of a politician who can resolve any issue within minutes respect\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00694685 0.03599174 0.8747366  0.08232482]\n",
      "-------------\n",
      "why filipino food is the next big thing again\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01334697 0.10646418 0.85133743 0.0288514 ]\n",
      "-------------\n",
      "gambia has shut down the internet\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02932343 0.2920273  0.6631919  0.01545731]\n",
      "-------------\n",
      "why rihanna amp lady gaga are turning to unknown fashion students for fresh looks\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.19469951 0.792145   0.0122254  0.00093009]\n",
      "-------------\n",
      "the latest holdup in the republicans plan to repeal and replace obamacare\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.48488787 0.50968134 0.00450461 0.00092615]\n",
      "-------------\n",
      "markzuckerberg is training with the most demanding and the most adorable trainer \n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03906935 0.65761936 0.29745    0.00586121]\n",
      "-------------\n",
      "lady gagas versace superbowl 2017 style scored big with fashion experts\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00998611 0.07895451 0.8808791  0.03018026]\n",
      "-------------\n",
      "kitkats are going to get less sugary\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00272964 0.00590147 0.06077778 0.9305911 ]\n",
      "-------------\n",
      "can the sea help manage mental illness\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02725529 0.68886256 0.2786793  0.0052028 ]\n",
      "-------------\n",
      "13 things to know about this weeks charts katy perrys rhythm already no 1 on trending140\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01092888 0.06107193 0.8815914  0.04640782]\n",
      "-------------\n",
      "it looked like a glorious night of schadenfreude for patriots loathers then it all changed\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.10283349 0.87533927 0.02088311 0.0009442 ]\n",
      "-------------\n",
      "bbc news had the wrong subtitles for donald trumps inauguration and its amazing\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01027644 0.08042566 0.8728571  0.03644076]\n",
      "-------------\n",
      "this is why your team wont win the super bowl next year yes your team talking to you\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.08595584 0.6544423  0.2503471  0.00925476]\n",
      "-------------\n",
      "trumps twitter account explains his rise to the white house\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.37922361 0.61289144 0.00680893 0.00107614]\n",
      "-------------\n",
      "the good the bad and the unknown about marijuanas health effects\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01750419 0.05687281 0.37665895 0.5489641 ]\n",
      "-------------\n",
      "four ways technology is transforming the museum experience\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.591005e-01 8.316073e-01 8.674919e-03 6.172914e-04]\n",
      "-------------\n",
      "the original tammatamma singer anuradhapaudwal strongly feels people sell trash in the name of trend these days\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00938839 0.0362964  0.7717551  0.18256015]\n",
      "-------------\n",
      "cat owner learns the hard way to read those amazon descriptions carefully\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.55783725 0.43797594 0.00348916 0.0006976 ]\n",
      "-------------\n",
      "the new status symbol what im so busy really tells your friends\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.0123833e-01 8.8701838e-01 1.1154893e-02 5.8833300e-04]\n",
      "-------------\n",
      "alys fowler how to give your seedlings the best start in life\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.12746544e-01 8.74771833e-01 1.18960952e-02 5.85512782e-04]\n",
      "-------------\n",
      "gulp water increasingly unaffordable for many americans\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.9855167e-02 9.3372679e-01 2.5720494e-02 6.9759978e-04]\n",
      "-------------\n",
      "antidowry summit sparks call for australian law against ancient tradition\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.04213352 0.3690513  0.576522   0.01229318]\n",
      "-------------\n",
      "anzacday in photos\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01251539 0.09282611 0.8496482  0.0450103 ]\n",
      "-------------\n",
      "tesla spikes after elon musk tweets a semitruck is coming\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01906185 0.2765025  0.68947697 0.01495864]\n",
      "-------------\n",
      "the heartwrenching story of chinas mask boy\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00869154 0.05122612 0.89486647 0.0452159 ]\n",
      "-------------\n",
      "why green lantern can still recover and become the multimovie franchise we deserve\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.1884679e-02 9.4072443e-01 1.7014533e-02 3.7633206e-04]\n",
      "-------------\n",
      "this dad had the sweetest response when his daughter asked for a pride flag for christmas\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.06889208 0.8118703  0.11623325 0.00300446]\n",
      "-------------\n",
      "deep thoughts with mika breinski\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04618707 0.7931759  0.1577966  0.00284051]\n",
      "-------------\n",
      "watch these dads doing ballet with their daughters\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.0410985e-01 7.8646863e-01 8.7369811e-03 6.8461400e-04]\n",
      "-------------\n",
      "dont play identity politics the primal scream of the straight white male  hadley freeman\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.59824920e-01 3.99493612e-02 1.18805234e-04 1.06850144e-04]\n",
      "-------------\n",
      "french newspaper releases the terrifying police report from kim kardashians paris robbery\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.3897319e-01 6.0635854e-02 2.2300726e-04 1.6795965e-04]\n",
      "-------------\n",
      "21 gifts for the gwyneth paltrow in your life\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.06064334 0.8428104  0.09451959 0.00202669]\n",
      "-------------\n",
      "this study debunks the idea that theres a beauty premium in salaries\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.7484789e-02 9.1005009e-01 4.1640084e-02 8.2493253e-04]\n",
      "-------------\n",
      "the worst bond rout in three years deepened thursday\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.6841221  0.31225258 0.00269294 0.00093244]\n",
      "-------------\n",
      "benedict cumberbatch is a bit frazzled in this deleted doctor strange scene\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01780548 0.2788283  0.68512833 0.01823791]\n",
      "-------------\n",
      "one nyt readers reaction to april the giraffe an internet star giving birth\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00708693 0.04755158 0.9108605  0.03450094]\n",
      "-------------\n",
      "analysis how milo yiannopoulos proves the gop is stuck in opposition mode\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02365711 0.19525419 0.7537523  0.02733649]\n",
      "-------------\n",
      "this quickthinking fast food worker saved a toddlers life\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00652186 0.0162431  0.11327651 0.86395854]\n",
      "-------------\n",
      "all the previews picks and bracket breakdowns from this years marchmadness  via nbcsports\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03369118 0.42361197 0.5312213  0.0114756 ]\n",
      "-------------\n",
      "message to realdonaldtrump kingjames sports a safety pin in si cover photo\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02061762 0.28913128 0.67666423 0.01358686]\n",
      "-------------\n",
      "\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.06077676 0.08110369 0.21420597 0.64391357]\n",
      "-------------\n",
      "running is the first thing that comes to mind for most and with good reason\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03570346 0.2977256  0.6448811  0.02168983]\n",
      "-------------\n",
      "in the latest airline episode captured on video a delta pilot can be seen smacking a woman to break up a fight\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.32410753 0.65384805 0.01901983 0.00302457]\n",
      "-------------\n",
      "cabin crew help deliver baby at 42000 feet\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00982148 0.13083643 0.83298135 0.02636078]\n",
      "-------------\n",
      "the lowest prices in a decade have really helped liquefied natural gas\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02248161 0.27113292 0.6896833  0.01670214]\n",
      "-------------\n",
      "the best time to buy airline tickets and other travel advice for 2017\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03223199 0.11015695 0.65920717 0.19840379]\n",
      "-------------\n",
      "in the tradition of the late and great justice antonin scalia\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.08908197 0.8669738  0.0421611  0.00178313]\n",
      "-------------\n",
      "wwe superstar charlotte flair reveals her wrestlemania fitness and diet plans\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03421975 0.78311926 0.17973357 0.00292746]\n",
      "-------------\n",
      "another twist in the yadavpariwar yadavakhilesh can party now\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02443581 0.08354006 0.72215706 0.16986716]\n",
      "-------------\n",
      "photos brisbanes bigwet\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01658427 0.14104778 0.7984245  0.04394334]\n",
      "-------------\n",
      "centurylinkvoice get your daily fibernetwork\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.04760979 0.16956896 0.7046759  0.07814535]\n",
      "-------------\n",
      "this ebay billionairebacked startup is trying to unravel routes of informal transport\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.07479093 0.8864038  0.03770983 0.00109541]\n",
      "-------------\n",
      "the worlds top fashion designers are refusing to dress melania trump\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.06092485 0.35354197 0.5675664  0.01796678]\n",
      "-------------\n",
      " valkilmer is the unexpected twitter god you need to follow right now\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01289748 0.03893943 0.25108704 0.6970761 ]\n",
      "-------------\n",
      "dreyfuss says he made a mistake in voting for hillary clinton in 2016 \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00267175 0.00548401 0.09497925 0.896865  ]\n",
      "-------------\n",
      "sturgeon said she wants another scottish independence referendum here we examine what she said  and what she meant\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [3.5222735e-02 9.4801730e-01 1.6308038e-02 4.5195076e-04]\n",
      "-------------\n",
      "persuasive\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01064965 0.01749195 0.08947781 0.8823806 ]\n",
      "-------------\n",
      "this former vogue model was found dead at 21\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.8290771e-01 1.7030431e-02 2.7205531e-05 3.4667624e-05]\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Error Analysis\n",
    "for i in range(1000):\n",
    "    if Y_test[i] - y_pred_binary[i] != 0:\n",
    "        print(X_test[i])\n",
    "        print(\"Actual Label\",Y_test[i])\n",
    "        print(\"Prediction Lable\",y_pred_binary[i])\n",
    "        print(\"Prediction\",y_pred_onehot[i])\n",
    "        print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(test_string):\n",
    "    test_string = cleanText(test_string)\n",
    "    test = np.array([test_string])\n",
    "    test_indices = sentences_to_indices(test, word_to_index, max_len = maxLen)\n",
    "    y_pred_onehot = model.predict(test_indices)\n",
    "    y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "    if y_pred_binary == [1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "test_string = \"US election 2020: What is the presidential transition\"\n",
    "test(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
