{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858464162594172928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858460992073863168</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858459539296980995</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858455355948384257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  truthMedian    truthClass  truthMean\n",
       "0  858464162594172928     1.000000     clickbait   1.000000\n",
       "1  858462320779026433     0.000000  no-clickbait   0.133333\n",
       "2  858460992073863168     0.333333  no-clickbait   0.400000\n",
       "3  858459539296980995     0.333333  no-clickbait   0.266667\n",
       "4  858455355948384257     0.000000  no-clickbait   0.000000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_df = pd.DataFrame(columns=['id','truthMedian','truthClass','truthMean'])\n",
    "with open('data/truth.jsonl') as data:\n",
    "    for labelobj in data:\n",
    "        truth = json.loads(labelobj)\n",
    "        truthlabel = {'id': truth['id'], 'truthMedian': truth['truthMedian'], 'truthClass': truth['truthClass'], 'truthMean': truth['truthMean']}\n",
    "        truth_df = truth_df.append(truthlabel, ignore_index = True)\n",
    "truth_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>postText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858462320779026433</td>\n",
       "      <td>[UK’s response to modern slavery leaving victi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858421020331560960</td>\n",
       "      <td>[this is good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858368123753435136</td>\n",
       "      <td>[The \"forgotten\" Trump roast: Relive his bruta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858323428260139008</td>\n",
       "      <td>[Meet the happiest #dog in the world!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858283602626347008</td>\n",
       "      <td>[Tokyo's subway is shut down amid fears over a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           postText\n",
       "0  858462320779026433  [UK’s response to modern slavery leaving victi...\n",
       "1  858421020331560960                                     [this is good]\n",
       "2  858368123753435136  [The \"forgotten\" Trump roast: Relive his bruta...\n",
       "3  858323428260139008             [Meet the happiest #dog in the world!]\n",
       "4  858283602626347008  [Tokyo's subway is shut down amid fears over a..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_df = pd.DataFrame(columns=['id','postText'])\n",
    "with open('data/instances.jsonl') as data:\n",
    "\tfor instanceobj in data:\n",
    "\t\tinstance = json.loads(instanceobj)\n",
    "\t\tinstancerow = {'id': instance['id'], 'postText': instance['postText']}\n",
    "\t\tinstances_df = instances_df.append(instancerow, ignore_index=True)\n",
    "instances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  \\\n",
       "0  UK’s response to modern slavery leaving victim...     0.000000   \n",
       "1                                       this is good     1.000000   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...     0.333333   \n",
       "3               Meet the happiest #dog in the world!     1.000000   \n",
       "4  Tokyo's subway is shut down amid fears over an...     0.000000   \n",
       "\n",
       "     truthClass  truthMean  \n",
       "0  no-clickbait   0.133333  \n",
       "1     clickbait   1.000000  \n",
       "2  no-clickbait   0.466667  \n",
       "3     clickbait   0.933333  \n",
       "4  no-clickbait   0.000000  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = instances_df.join(truth_df.set_index('id'), on='id')\n",
    "dataset = dataset.drop(labels='id',axis=1)\n",
    "for i in range(len(dataset)):\n",
    "    dataset['postText'].values[i] = dataset['postText'].values[i][0]\n",
    "dataset['postText'].dropna(inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  UK’s response to modern slavery leaving victim...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...            1           0   \n",
       "3               Meet the happiest #dog in the world!            3           1   \n",
       "4  Tokyo's subway is shut down amid fears over an...            0           0   \n",
       "\n",
       "   truthMean  \n",
       "0   0.133333  \n",
       "1   1.000000  \n",
       "2   0.466667  \n",
       "3   0.933333  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toBinary(truthClass):\n",
    "    if truthClass == 'no-clickbait':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "dataset['truthClass'] = dataset['truthClass'].apply(toBinary)\n",
    "\n",
    "def toInteger(truthMedian):\n",
    "    return round(truthMedian*3)\n",
    "dataset['truthMedian'] = dataset['truthMedian'].apply(toInteger)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uks response to modern slavery leaving victims...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the forgotten trump roast relive his brutal 20...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet the happiest dog in the world</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tokyos subway is shut down amid fears over an ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  truthMedian  truthClass  \\\n",
       "0  uks response to modern slavery leaving victims...            0           0   \n",
       "1                                       this is good            3           1   \n",
       "2  the forgotten trump roast relive his brutal 20...            1           0   \n",
       "3                 meet the happiest dog in the world            3           1   \n",
       "4  tokyos subway is shut down amid fears over an ...            0           0   \n",
       "\n",
       "   truthMean  \n",
       "0   0.133333  \n",
       "1   1.000000  \n",
       "2   0.466667  \n",
       "3   0.933333  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    return text\n",
    "dataset['postText'] = dataset['postText'].apply(cleanText)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_punc(postText):\n",
    "#     return len(postText)\n",
    "# dataset['numOfPunctuation'] =  dataset['postText'].apply(count_punc) - dataset['cleanPostText'].apply(count_punc)\n",
    "# dataset.drop(dataset[dataset['numOfPunctuation']>15].index , inplace = True)\n",
    "# dataset = dataset.reset_index()\n",
    "# numOfPunctuation = dataset[['numOfPunctuation']].values\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# dataset['numOfPunctuationNorm'] = min_max_scaler.fit_transform(numOfPunctuation)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.drop(['postText'],axis=1)\n",
    "# dataset = dataset.rename(columns = {'cleanPostText': 'postText'}, inplace = False)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfPunctuation']>0)])\n",
    "# non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import download\n",
    "# download('punkt')\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# def stemming(postText):\n",
    "#     ps = PorterStemmer()\n",
    "#     sentence = word_tokenize(postText)\n",
    "#     newsentence = []\n",
    "#     for word in sentence:\n",
    "#         newsentence.append(ps.stem(word))\n",
    "#     return ' '.join(newsentence)\n",
    "# dataset['stemmingPostText'] = dataset['postText'].apply(stemming)\n",
    "# #dataset['postText'] = dataset['postText'].apply(stemming)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# dataset_cb = dataset[dataset['truthClass'] == 1]\n",
    "# dataset_ncb = dataset[dataset['truthClass'] == 0]\n",
    "# cb_words_tuple = Counter(\" \".join(dataset_cb[\"stemmingPostText\"]).split()).most_common(300)\n",
    "# cb_words = [words for (words, count) in cb_words_tuple] \n",
    "# non_cb_words_tuple = Counter(\" \".join(dataset_ncb[\"stemmingPostText\"]).split()).most_common(350)\n",
    "# non_cb_words = [words for (words, count) in non_cb_words_tuple] \n",
    "# true_cb_words = []\n",
    "# for i in range(len(cb_words)):\n",
    "#     word = cb_words[i]\n",
    "#     if word not in non_cb_words[:50+i] and not word.isnumeric():\n",
    "#         true_cb_words.append(word)\n",
    "# #print(len(true_cb_words))\n",
    "# print(true_cb_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countlist = []\n",
    "# for index, row in dataset.iterrows(): \n",
    "#     words = row[\"postText\"].split()\n",
    "#     count = 0\n",
    "#     for word in words:\n",
    "#         if word in true_cb_words:\n",
    "#             count += 1 \n",
    "#     countlist.append(count)\n",
    "# dataset['clickbaitWords'] = countlist\n",
    "# numOfCbWords = dataset[['clickbaitWords']].values\n",
    "# dataset['clickbaitWordsNorm'] = min_max_scaler.fit_transform(numOfCbWords)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#clickbait titles with clickbait words] over [#clickbait title]\n",
    "# clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# clickbait_with_cb_words_len = len(dataset[(dataset['truthClass']==1) & (dataset['clickbaitWords']>0)])\n",
    "# clickbait_with_cb_words_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#non-clickbait titles without clickbait words] over [#non-clickbait titles]\n",
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "# non_clickbait_without_cb_words_len = len(dataset[(dataset['truthClass']==0) & (dataset['clickbaitWords']==0)])\n",
    "# non_clickbait_without_cb_words_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numberCountlist = []\n",
    "# for index, row in dataset.iterrows(): \n",
    "#     words = row[\"postText\"].split()\n",
    "#     count = 0\n",
    "#     for word in words:\n",
    "#         if word.isnumeric():\n",
    "#             count += 1 \n",
    "#     numberCountlist.append(count)\n",
    "# dataset['numOfNumerics'] = numberCountlist\n",
    "# numOfNumerics = dataset[['numOfNumerics']].values\n",
    "# dataset['numOfNumericsNorm'] = min_max_scaler.fit_transform(numOfNumerics)\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#clickbait titles with numOfnumerics words] over [#clickbait title]\n",
    "# clickbait_len = len(dataset[(dataset['truthClass']==1)])\n",
    "# clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==1) & (dataset['numOfNumerics']>0)])\n",
    "# clickbait_with_numerics_len/clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of [#non-clickbait titles without numOfnumerics words] over [#non-clickbait titles]\n",
    "# non_clickbait_len = len(dataset[(dataset['truthClass']==0)])\n",
    "# non_clickbait_with_numerics_len = len(dataset[(dataset['truthClass']==0) & (dataset['numOfNumerics']>0)])\n",
    "# non_clickbait_with_numerics_len/non_clickbait_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from subject_verb_object_extract import findSVOs, nlp\n",
    "# def extract(postText):\n",
    "#     tokens1 = nlp(postText)\n",
    "#     svos1 = findSVOs(tokens1)\n",
    "#     return svos1\n",
    "\n",
    "# dataset['SVO'] = dataset['postText'].apply(extract)\n",
    "# dataset.head()\n",
    "# president trump slams reporters use of anonymous sources despite using them himself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the glove word embedding file\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of titles with longest words\n",
    "maxLen = 0\n",
    "for i in range(len(dataset)):\n",
    "    sentence = dataset[\"postText\"][i]\n",
    "    if len(sentence.split()) > maxLen:\n",
    "        maxLen = len(sentence.split())\n",
    "        maxstr = sentence\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15630,)\n",
      "(3908,)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset to training and testing set\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "X_train, Y_train, Y_train_mean = np.array(train[\"postText\"].tolist()), np.array(train[\"truthMedian\"].tolist()), np.array(train[\"truthMean\"].tolist())\n",
    "# positive_test = test[test[\"truthClass\"] == 1].sample(n=900)\n",
    "# negative_test = test[test[\"truthClass\"] == 0].sample(n=900)\n",
    "# test = pd.concat([negative_test, positive_test]).sample(frac=1)\n",
    "X_test, Y_test, Y_test_mean = np.array(test[\"postText\"].tolist()), np.array(test[\"truthClass\"].tolist()), np.array(test[\"truthMean\"].tolist())\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):   \n",
    "    m = X.shape[0]  # number of training examples\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape \n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    for i in range(m):          \n",
    "        # Convert the ith training sentence in lower case and split is into words\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index.keys():\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j = j + 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train_indices =\n",
      " (15630, 25)\n"
     ]
    }
   ],
   "source": [
    "Indices = sentences_to_indices(X_train,word_to_index, maxLen)\n",
    "print(\"X_Train_indices =\\n\", Indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1        \n",
    "    # define dimensionality of your GloVe word vectors (= 50)\n",
    "    emb_dim = word_to_vec_map[\"happy\"].shape[0]      \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    # See instructions above to choose the correct shape.\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_len,emb_dim,trainable = False)\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,)) \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClickBait_LSTM(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with 2 units\n",
    "    X = Dense(4)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)  \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 25, 100)           40000100  \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 25, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 25, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 40,381,032\n",
      "Trainable params: 380,932\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ClickBait_LSTM((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15630, 25)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 4)\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "489/489 [==============================] - 11s 22ms/step - loss: 0.4951 - accuracy: 0.8011\n",
      "Epoch 2/20\n",
      "489/489 [==============================] - 11s 23ms/step - loss: 0.4296 - accuracy: 0.8323\n",
      "Epoch 3/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.3968 - accuracy: 0.8506\n",
      "Epoch 4/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.3569 - accuracy: 0.8660\n",
      "Epoch 5/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.3239 - accuracy: 0.8789\n",
      "Epoch 6/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.3011 - accuracy: 0.8902\n",
      "Epoch 7/20\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.2806 - accuracy: 0.8988\n",
      "Epoch 8/20\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.2611 - accuracy: 0.9074\n",
      "Epoch 9/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.2417 - accuracy: 0.9182\n",
      "Epoch 10/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.2323 - accuracy: 0.9194\n",
      "Epoch 11/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.2132 - accuracy: 0.9275\n",
      "Epoch 12/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.2066 - accuracy: 0.9296\n",
      "Epoch 13/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.1900 - accuracy: 0.9383\n",
      "Epoch 14/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.1834 - accuracy: 0.9379\n",
      "Epoch 15/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.1840 - accuracy: 0.9395\n",
      "Epoch 16/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.1827 - accuracy: 0.9385\n",
      "Epoch 17/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.1656 - accuracy: 0.9448\n",
      "Epoch 18/20\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.1497 - accuracy: 0.9492\n",
      "Epoch 19/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.1440 - accuracy: 0.9534\n",
      "Epoch 20/20\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.1501 - accuracy: 0.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d24e2d5280>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 20, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_binary(data):\n",
    "    binary = []\n",
    "    for i in range(len(data)):\n",
    "        if 2/3*data[i][3] + 1/3*data[i][2] > 2/3*data[i][0] + 1/3*data[i][1]:\n",
    "        #if data[i][3] + data[i][2] > data[i][0] + data[i][1]:\n",
    "            binary.append(1)\n",
    "        else:\n",
    "            binary.append(0)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error\n",
      "Accuracy 0.9861804222648752\n",
      "Precision 0.9683328971473436\n",
      "Recall 0.9749670619235836\n",
      "F1 score: 0.9716386554621849\n",
      "MSE 0.08040577237322648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,roc_auc_score, mean_squared_error \n",
    "y_train_pred_oh = model.predict(X_train_indices)\n",
    "y_train_pred_binary = onehot_to_binary(y_train_pred_oh)\n",
    "Y_train_binary = onehot_to_binary(Y_train_oh)\n",
    "\n",
    "print(\"Training Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_train_binary, y_train_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_train_binary, y_train_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_train_binary, y_train_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_train_mean, y_train_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error\n",
      "Accuracy 0.8236949846468782\n",
      "Precision 0.661610268378063\n",
      "Recall 0.5869565217391305\n",
      "F1 score: 0.6220515633571037\n",
      "MSE 0.13014329579868986\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "y_pred_onehot = model.predict(X_test_indices)\n",
    "y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "\n",
    "print(\"Testing Error\")\n",
    "print('Accuracy %s' % accuracy_score(Y_test, y_pred_binary))\n",
    "print('Precision %s' % precision_score(Y_test, y_pred_binary))\n",
    "print('Recall %s' % recall_score(Y_test, y_pred_binary))\n",
    "print('F1 score: %s' % f1_score(Y_test, y_pred_binary))\n",
    "print('MSE %s' % mean_squared_error(Y_test_mean, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE 0.07533265097030707\n"
     ]
    }
   ],
   "source": [
    "print('Minimum MSE %s' % mean_squared_error(Y_test_mean, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnostic medical sonographer is the least stressful job of 2017 see more\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03048823 0.40089285 0.5306556  0.03796333]\n",
      "-------------\n",
      "the difference between donald trump and justin trudeau in two pictures\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.27626538 0.62381214 0.09103101 0.00889147]\n",
      "-------------\n",
      "the perfect way to cook rice so that its perfectly fluffy and never sticks to the pan\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.37360004 0.5559347  0.06305259 0.00741267]\n",
      "-------------\n",
      "for instance lowpotency antibiotic drugs were found to be diluted with paracetamol\n",
      "thisisit\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [7.3322910e-01 2.6232275e-01 4.1640382e-03 2.8406092e-04]\n",
      "-------------\n",
      "135 films got a certificate from censor board\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.09521299 0.7942034  0.10587152 0.0047121 ]\n",
      "-------------\n",
      "the young women leading change in asia  forbesu30asia\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01237589 0.08373686 0.48906505 0.4148222 ]\n",
      "-------------\n",
      "the sisters act owning the world of fashion and vying for the top title\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.08016554 0.5002687  0.37307554 0.04649023]\n",
      "-------------\n",
      "dale cavese the football chant that took over the internet and the world\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.3002504  0.6426435  0.05328801 0.00381807]\n",
      "-------------\n",
      "ghetto talent\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.07435559 0.87455124 0.04986777 0.00122543]\n",
      "-------------\n",
      "heres what you need to know before you go to a whitecollar sex party\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03926451 0.13317357 0.4438176  0.3837443 ]\n",
      "-------------\n",
      "syria has destroyed the taboo on chemical weapons heres how it can be restored premium\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00512211 0.05888921 0.71073276 0.22525597]\n",
      "-------------\n",
      "why investing in 2016s worstperforming industries may be best for your portfolio\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01309124 0.10762257 0.63118446 0.24810182]\n",
      "-------------\n",
      "how one mans pause became a haunting symbol of aleppos destruction\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0148924  0.07582042 0.49473312 0.41455412]\n",
      "-------------\n",
      "the next facebook wall street sizes up snaps ipo\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [6.4845270e-01 3.4534770e-01 5.8688368e-03 3.3076238e-04]\n",
      "-------------\n",
      "just some guys in england driving a tank to the gas station\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.06546487 0.71102726 0.21155539 0.01195248]\n",
      "-------------\n",
      "amber heard says she was warned coming out as bisexual would end her career\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.07243556 0.19707353 0.43262225 0.29786858]\n",
      "-------------\n",
      "is lipstick toxic gwyneth paltrow thinks so  via yahoobeauty\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.02365647 0.58611387 0.3757037  0.01452602]\n",
      "-------------\n",
      "beautyandthebeast has broken 5 boxoffice records already\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00612407 0.09569789 0.7084007  0.18977731]\n",
      "-------------\n",
      "presenting the 30under30 in sports\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7932136e-01 2.0546487e-02 9.8934586e-05 3.3231761e-05]\n",
      "-------------\n",
      "the selfhealing even functioned when the material was cut into two entirely separate pieces \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00735347 0.03699768 0.41384646 0.5418024 ]\n",
      "-------------\n",
      "someone threw the veep music over that awkward trump nonsigning and its fantastic\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.05236275 0.44709286 0.45784867 0.04269571]\n",
      "-------------\n",
      "yes really 1984 is now sold out on amazon\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.3602189  0.5813718  0.05354624 0.00486299]\n",
      "-------------\n",
      "woman snapping selfies on californias highest bridge falls 60 feet\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9896824e-01 1.0208655e-03 3.4863722e-06 7.4758877e-06]\n",
      "-------------\n",
      "theres a 20 chance you have a particular form of synesthesia\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.12188037 0.8287069  0.04794608 0.0014666 ]\n",
      "-------------\n",
      "the worlds most pointless signs revealed\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0057798  0.01841735 0.15499055 0.8208123 ]\n",
      "-------------\n",
      "eating at disneylands newest restaurant costs as much as your rent\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0172967  0.4328418  0.5213439  0.02851755]\n",
      "-------------\n",
      "why rihanna amp lady gaga are turning to unknown fashion students for fresh looks\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.06909927 0.667305   0.25030828 0.01328753]\n",
      "-------------\n",
      "bug that plagues soldiers is enemy no 1 on whos superbug list\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.4710044e-01 1.5096372e-01 1.7732600e-03 1.6254393e-04]\n",
      "-------------\n",
      "so many shows so little time one tip watch everything twice as fast\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.09009502 0.37764522 0.4253726  0.1068871 ]\n",
      "-------------\n",
      "calling your boss a nasty motherfucker shouldnt get you fired judges rule\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00490194 0.13803475 0.80364764 0.05341568]\n",
      "-------------\n",
      "a threeday wedding celebration do learn some restraint says country life\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.05184148 0.45534003 0.44814178 0.04467678]\n",
      "-------------\n",
      "this hole is also known as the ear pit and connects the ear to the sinuses inside\n",
      "thisisit healthmeup\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.13951561 0.71458083 0.1363888  0.0095147 ]\n",
      "-------------\n",
      "confused 3yearold has some serious questions about easter traditions\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.05648619 0.88846636 0.05386747 0.00118   ]\n",
      "-------------\n",
      "quote of the day\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.4502670e-01 5.4517824e-02 3.8287725e-04 7.2562878e-05]\n",
      "-------------\n",
      "chris pratt officially weighs in on that jurassic world theory\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9491042e-01 5.0620269e-03 1.5989999e-05 1.1533629e-05]\n",
      "-------------\n",
      "its an idea from back when pop warner coached football  but it could revolutionize the game all over again\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.31613275 0.55013275 0.11628284 0.01745161]\n",
      "-------------\n",
      "james corden suggests a new catchphrase for americas economy  by leemoran\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9661046e-01 3.3643460e-03 1.2197381e-05 1.2924966e-05]\n",
      "-------------\n",
      "trumps house freedom caucus tweet draws response from conservative members\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04889799 0.84922636 0.0994007  0.00247504]\n",
      "-------------\n",
      "seattle jogger shares the 5 selfdefense tips she drew on to defeat rapist\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.21169673 0.7519711  0.03511385 0.00121832]\n",
      "-------------\n",
      "the truth about those solar jobs numbers youve been seeing\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.14052698 0.76290184 0.09230745 0.00426373]\n",
      "-------------\n",
      "best and worst of ncaas opening week  via yahoosports\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02814389 0.22447136 0.5741748  0.17320992]\n",
      "-------------\n",
      "save thousands of dollars a year by investing in these 10 smart home solutions\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03706642 0.58174956 0.3626727  0.01851136]\n",
      "-------------\n",
      "introducing our firstever tally of americas wealthiest celebrities\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.2394871e-01 7.5363725e-02 6.0556160e-04 8.1964019e-05]\n",
      "-------------\n",
      "panasonics gh5 is here to slay all other 4k mirrorless cameras photog nerds time to freak out  mashces\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02262516 0.4399641  0.51141846 0.02599236]\n",
      "-------------\n",
      "an antimuslim hate group is bragging about its influence in trumps white house\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0233897  0.18442027 0.6647397  0.1274503 ]\n",
      "-------------\n",
      "this study debunks the idea that theres a beauty premium in salaries\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.6980048e-01 7.2003525e-01 9.9272747e-03 2.3696067e-04]\n",
      "-------------\n",
      "whats more important who writes a story on socialmedia or who shares it\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01616001 0.12308876 0.62116075 0.23959047]\n",
      "-------------\n",
      "review a sweeney todd that gets into your face\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01451315 0.06448444 0.45147327 0.46952915]\n",
      "-------------\n",
      "seanhannity the left is in a pre911 mentality\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00728084 0.04715981 0.37961856 0.5659408 ]\n",
      "-------------\n",
      "how to safely clean your dirty disgusting smartphone\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01256773 0.05603392 0.38829097 0.54310733]\n",
      "-------------\n",
      "its time to talk about one tree hill and the worst character on the show\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03164196 0.25454557 0.61343485 0.10037757]\n",
      "-------------\n",
      "cat shreds on a sled\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00294149 0.06668088 0.81566286 0.11471473]\n",
      "-------------\n",
      "the rise of social media in government\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00959129 0.14172897 0.7208251  0.12785469]\n",
      "-------------\n",
      "watch this car effortlessly drift and move sidetoside\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00420599 0.02885092 0.31533062 0.6516125 ]\n",
      "-------------\n",
      "trump was caught practicing his speech so the internet made jokes\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.08566954 0.74360555 0.16252726 0.00819769]\n",
      "-------------\n",
      "reeperbahn rendezvous the glorious dive bar photos of anders petersen\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00605988 0.16955799 0.77376896 0.05061316]\n",
      "-------------\n",
      "phase a fulltime job into parttime then retirement\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00500204 0.0476259  0.54425716 0.40311486]\n",
      "-------------\n",
      "report of terminally ill boy who died in santas arms called into question\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.7052283e-01 7.1859652e-01 1.0607585e-02 2.7308069e-04]\n",
      "-------------\n",
      "whats the no 1 ranking worth for the top golfers maybe nothing more than an ego boost\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00414096 0.02804973 0.4235266  0.54428273]\n",
      "-------------\n",
      "icymi how a young mans suicide is transforming a rural community  pic pauline carrigan\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [5.5700213e-01 4.3367156e-01 8.8525685e-03 4.7375029e-04]\n",
      "-------------\n",
      "internet points out irony of trump screening finding dory during muslimban\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00848174 0.07975372 0.6675443  0.24422027]\n",
      "-------------\n",
      "why people are attending the womens march on washington in their own words\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01698994 0.21617772 0.6909566  0.07587573]\n",
      "-------------\n",
      "migosmania how the atlanta rap trio mastered the sound of silence\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01060619 0.19274643 0.74289536 0.05375203]\n",
      "-------------\n",
      "live now join us for a chat about the best ways to give back during the holidays\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.11533475 0.6416534  0.22391555 0.0190963 ]\n",
      "-------------\n",
      "nigerias starving children who fled boko haram\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.4581201e-02 9.0491098e-01 4.9613800e-02 8.9405495e-04]\n",
      "-------------\n",
      "raiders punter marquette king had a savage response to travis kelce stealing his dance\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03658736 0.74988055 0.2072166  0.00631544]\n",
      "-------------\n",
      "analysis donald trump hasnt changed but conservatives have and cpac just proved it\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02048738 0.11331225 0.5932835  0.27291697]\n",
      "-------------\n",
      "well played\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.1193013  0.8315298  0.04760601 0.00156289]\n",
      "-------------\n",
      "teen wants to take his grandma to prom but his high school says no\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.5201862e-01 5.3790408e-01 9.6705165e-03 4.0676745e-04]\n",
      "-------------\n",
      "cat owner learns the hard way to read those amazon descriptions carefully\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.3309589e-01 8.3501893e-01 3.1086348e-02 7.9871865e-04]\n",
      "-------------\n",
      "6 sciencethemed twitter bots that dole out humor factual information and galactic perspective\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.04685108 0.18645138 0.536406   0.2302916 ]\n",
      "-------------\n",
      "dabbing makes politicians look like a stunned circus bear  stuart heritage\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.0554857e-01 9.3676083e-02 7.0294173e-04 7.2416449e-05]\n",
      "-------------\n",
      "is the united airlines man being smeared in the media even the right david dao it doesnt matter\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.26331094 0.67910826 0.05415485 0.00342588]\n",
      "-------------\n",
      "when is it ok to cry at work\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.3160331e-01 6.7721874e-02 5.7389151e-04 1.0082144e-04]\n",
      "-------------\n",
      "key points of the budget 2017  at a glance\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [7.1042553e-02 9.1238308e-01 1.6354501e-02 2.1976909e-04]\n",
      "-------------\n",
      "she saved the life of the girl she babysits respect humanity\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02226218 0.13817136 0.5761025  0.26346397]\n",
      "-------------\n",
      "trudeau throws some gradea shade at trump\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00544403 0.1141221  0.80805004 0.07238384]\n",
      "-------------\n",
      "things took an an ugly turn when a batsman shoulderbarged a bowler after he celebrated after taking his wicket\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03509119 0.17435256 0.5696903  0.22086596]\n",
      "-------------\n",
      "nicki minaj and aretha franklin are tied for the most hot 100 songs by a woman\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.8954562e-01 1.0757822e-01 2.3584832e-03 5.1771343e-04]\n",
      "-------------\n",
      "american bans syrian behind nominated film from attending oscars\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.95799005e-01 4.17768490e-03 1.28798065e-05 1.04619758e-05]\n",
      "-------------\n",
      "5 things for tuesday\n",
      "\n",
      " health care\n",
      " immigration\n",
      " north korea\n",
      " layoffs\n",
      " monuments\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01369737 0.13678993 0.7127252  0.13678744]\n",
      "-------------\n",
      "eight kinds of love to celebrate on valentinesday\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02686377 0.08376577 0.3561829  0.5331875 ]\n",
      "-------------\n",
      "these photos posted by people of color in love make a beautiful point\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02484288 0.10558392 0.48722368 0.38234952]\n",
      "-------------\n",
      "bestselling business books\n",
      "\n",
      "1 strengthsfinder 20\n",
      "2 blink\n",
      "3 good to great\n",
      "\n",
      "more\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0193969  0.16779837 0.69367063 0.11913411]\n",
      "-------------\n",
      "moby says hell dj at trumps inauguration under this one condition\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.97017860e-01 2.95675918e-03 1.15106395e-05 1.39556632e-05]\n",
      "-------------\n",
      "the rainbow people who meet around the world for meditations and naked gatherings\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.2043805e-01 7.8763783e-02 6.9809257e-04 1.0019732e-04]\n",
      "-------------\n",
      "adpvoice 3 ways to equalize the treatment of women in the workplace\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00713862 0.03267666 0.29146728 0.6687175 ]\n",
      "-------------\n",
      "have you decorated your christmas tree yet if so we want to see it telexmas\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.10715435 0.5064183  0.33667523 0.04975217]\n",
      "-------------\n",
      "the 2017 oscarnoms are here tune in now to see who made the cut\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.25773752 0.6092247  0.11931611 0.01372166]\n",
      "-------------\n",
      "netflix is reinventing reality tv by making the same show six times\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.51768756 0.46284685 0.01814233 0.00132328]\n",
      "-------------\n",
      "the oscars had their most chaotic conclusion ever on sunday night but a relatively small audience was watching it\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0562477  0.23251206 0.50449455 0.20674571]\n",
      "-------------\n",
      "4 solutions to common tax issues  via yahoofinance\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00601561 0.05829274 0.60716885 0.3285228 ]\n",
      "-------------\n",
      "john legends twitter hacked series of bizarre antitrump tweets posted\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02302604 0.22288509 0.677664   0.0764249 ]\n",
      "-------------\n",
      "ges jeff immelt on trump and globalization\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9819249e-01 1.7931286e-03 5.7294665e-06 8.6902992e-06]\n",
      "-------------\n",
      "michael phelps teaches 7montholdson to swim under water\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00282786 0.1141395  0.81500906 0.0680236 ]\n",
      "-------------\n",
      "exnba player arrested in alleged kidnapping robbery assault  via nbcsports\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01171599 0.39199603 0.5691115  0.02717653]\n",
      "-------------\n",
      "homelands patinkinmandy dismisses antirefugee fervor as false fear\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00620271 0.3958049  0.5811451  0.01684719]\n",
      "-------------\n",
      "so much for stiff upper lips britons grouse about yet another election\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.139556   0.81894493 0.04027313 0.0012259 ]\n",
      "-------------\n",
      "big splits memorable moments and tragic losses the year in pop culture\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [4.0182114e-01 5.8360749e-01 1.3996548e-02 5.7494116e-04]\n",
      "-------------\n",
      "chef roasts diner who left note calling christmas music offensive\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.40805572e-01 8.51326704e-01 7.76366889e-03 1.04030536e-04]\n",
      "-------------\n",
      "can you spot the hidden artist\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03380223 0.17495826 0.5772284  0.21401109]\n",
      "-------------\n",
      "uber gives restless employees a way to cash out\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [1.0311451e-01 8.7259305e-01 2.3825003e-02 4.6739087e-04]\n",
      "-------------\n",
      "these unitedairlines memes \n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03375892 0.09157307 0.36169478 0.5129733 ]\n",
      "-------------\n",
      "airliners of the future may sport some very unusual designs  via nbcnewsmach\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03804777 0.5230413  0.41835862 0.02055235]\n",
      "-------------\n",
      "the usmexico barrier isnt always on true border leaving this family on south side and slowing firefighter access\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.24048558 0.7015187  0.0548444  0.00315133]\n",
      "-------------\n",
      "heal thyself meet the doctors living with the conditions they treat\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.4747738  0.5010353  0.02258557 0.00160533]\n",
      "-------------\n",
      "donald trumps first 100 days in tweets\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.4976031e-01 7.3885739e-01 1.1133635e-02 2.4866912e-04]\n",
      "-------------\n",
      "festival drops event where a woman was set to appear onstage with her rapist\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03046718 0.11901767 0.47541812 0.3750971 ]\n",
      "-------------\n",
      "what does scotlands new push for independence mean analysis by jamesglenday\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03330769 0.2866932  0.6007361  0.07926302]\n",
      "-------------\n",
      "a record number of poor kids are eating breakfast  thanks to a program many conservatives hate\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.09075595 0.80678475 0.09844311 0.00401623]\n",
      "-------------\n",
      "cinnabon fails the galaxy with terrible tweet about carrie fishers death\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [2.0728643e-01 7.7584416e-01 1.6454499e-02 4.1489978e-04]\n",
      "-------------\n",
      "baseball team values 2017\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00354699 0.02808064 0.33702058 0.63135177]\n",
      "-------------\n",
      "hilarious photos capture petty acts of revenge around the world\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00683876 0.032177   0.31670806 0.64427614]\n",
      "-------------\n",
      "after its brexittrump reversal heres what the left must do\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01115566 0.04688402 0.32648817 0.61547214]\n",
      "-------------\n",
      "watch larry wilmore tell milo yiannopoulos go fk yourself on realtimers\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.04650597 0.4146895  0.48079503 0.05800947]\n",
      "-------------\n",
      "us official suggests president trump is not tied to twostate solution\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01505504 0.3322559  0.6109533  0.04173583]\n",
      "-------------\n",
      "psychologists have identified 10 factors that explain why and how we fall in love\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.1358077  0.74026597 0.116741   0.00718535]\n",
      "-------------\n",
      "ancient chinese tombsweeping festival goes hitech\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.6035516e-01 3.9387304e-02 2.1228200e-04 4.5299632e-05]\n",
      "-------------\n",
      "jimmy garoppolo confuses nfl fans and media with instagram post about leaving patriots\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02941205 0.25216106 0.63785285 0.08057412]\n",
      "-------------\n",
      "senator schumer trump should label china a currency manipulator\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02344278 0.47462216 0.4769933  0.02494175]\n",
      "-------------\n",
      "clumsy creatures get themselves into all sorts of scrapes \n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [5.8461922e-01 4.0934560e-01 5.7893922e-03 2.4585117e-04]\n",
      "-------------\n",
      "peeps on top of pizza debate\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01516262 0.1542281  0.728081   0.10252821]\n",
      "-------------\n",
      "100000 public money given to suspected illegal faith schools\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9808758e-01 1.8997329e-03 5.2650489e-06 7.3922815e-06]\n",
      "-------------\n",
      "fbi arrested the troll who sent that seizureinducing tweet to a journalist with epilepsy\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0130024  0.14790496 0.745912   0.0931806 ]\n",
      "-------------\n",
      "the real problem behind fake news  via yahoonews\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04748132 0.6910599  0.25058314 0.01087566]\n",
      "-------------\n",
      "cheap widely available drug could stop thousands of mothers bleeding to death\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [6.0313612e-01 3.9280406e-01 3.9013431e-03 1.5857394e-04]\n",
      "-------------\n",
      "could we see four outfielders against certain players\n",
      "\n",
      "busterespn says the tactic could be making a comeback\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0482308  0.4333397  0.46687123 0.05155826]\n",
      "-------------\n",
      "did you like serial heres why their new podcast stown is better\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.45809236 0.5021022  0.03637912 0.00342632]\n",
      "-------------\n",
      "its time to travel solo traveldiaries\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9065185e-01 9.3014408e-03 3.1158299e-05 1.5633243e-05]\n",
      "-------------\n",
      "ghost in the shell is a pretty package with nothing inside\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.04100189 0.4130498  0.5071879  0.03876049]\n",
      "-------------\n",
      "realdonaldtrump to reporter its not a fence its a wall were gonna start building\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02192714 0.12852877 0.6099079  0.23963626]\n",
      "-------------\n",
      "the guardian view on internet privacy technology cant fix it  editorial\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00632364 0.10797316 0.7784068  0.10729644]\n",
      "-------------\n",
      "the grizzly steppe report identifies the wrong cyber bear  via bv\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.01368371 0.5017586  0.46923968 0.01531797]\n",
      "-------------\n",
      "once a captain always a captain msdhoni\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.06337883 0.5491258  0.35278586 0.03470944]\n",
      "-------------\n",
      "this joke about donald trump is extremely rude and we dont condone it even a little\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.47543022 0.4683227  0.04786729 0.00837967]\n",
      "-------------\n",
      "13 things to know about this weeks charts katy perrys rhythm already no 1 on trending140\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02365445 0.09489982 0.4610556  0.42039013]\n",
      "-------------\n",
      "heres something you probably never knew about golden girl rue mcclanahan\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03777457 0.11719975 0.42712936 0.4178963 ]\n",
      "-------------\n",
      "how many hours should a salaried employee work\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01229199 0.12245597 0.69111824 0.17413375]\n",
      "-------------\n",
      "people love this girls joyful response to her boyfriend gifting her an empty box\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03464718 0.21839641 0.6194807  0.12747566]\n",
      "-------------\n",
      "they think the rules dont apply to them and you know what they are right the rules dont\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.5969059  0.38742048 0.01445275 0.00122081]\n",
      "-------------\n",
      "goldman sachs is about to swallow donald trump\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [7.4988884e-01 2.4752988e-01 2.4437078e-03 1.3768778e-04]\n",
      "-------------\n",
      "change your definitions about networking building community is much better for your career\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.05304427 0.4464047  0.46123645 0.03931458]\n",
      "-------------\n",
      "details emerge of george michaels many quiet acts of kindness\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [6.1229461e-01 3.8021937e-01 7.0775100e-03 4.0844889e-04]\n",
      "-------------\n",
      "the sweet 16 is almost upon us who joins lonzo ball on chad fords list of top nba draft prospects  insider\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.36730725 0.59372085 0.03608822 0.00288375]\n",
      "-------------\n",
      "daylight saving time begins this weekend here are some tips for surviving the switch\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.13548936 0.73314476 0.1236736  0.00769234]\n",
      "-------------\n",
      "you wont believe why this woman is suing chipotle for over 2 billion\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [7.7337730e-01 2.2274752e-01 3.5814783e-03 2.9369505e-04]\n",
      "-------------\n",
      "this is how censorship starts says jimrutenberg not with a boot on your neck but with fear of the president\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.07731151 0.28478414 0.46554768 0.1723566 ]\n",
      "-------------\n",
      "how long do us retirees live compared to peers in other countries\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02894089 0.3507431  0.55726856 0.06304744]\n",
      "-------------\n",
      "this couple did a la la land engagement shoot and its pretty cute\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.0281227  0.18226862 0.64315766 0.14645107]\n",
      "-------------\n",
      "indias most valuable bank plans to launch the countrys biggest offering of perpetual debt\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01696892 0.12539928 0.69424284 0.16338892]\n",
      "-------------\n",
      "here are the perfect male and female bodies according to men and women\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.5577794e-01 4.3778278e-02 3.5760255e-04 8.6176056e-05]\n",
      "-------------\n",
      "do you recognise these 12 signs of breast cancer\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.01838089 0.0586787  0.29148242 0.631458  ]\n",
      "-------------\n",
      "trump is already taking credit for the economy heres why that could backfire\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.05110457 0.37267125 0.512195   0.06402919]\n",
      "-------------\n",
      "sherryontopp joins incindia welcomed by officeofrg\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9900466e-01 9.8381750e-04 3.5815906e-06 8.0166656e-06]\n",
      "-------------\n",
      "for tv series set in chicago grim facts collide with fiction\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.04533059 0.674856   0.2676766  0.01213682]\n",
      "-------------\n",
      "tinders inhouse sociologist on how to increase your chances of a valentines day date\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.03011444 0.2021511  0.63638294 0.13135152]\n",
      "-------------\n",
      "gruesome isis video shows turkish soldiers burned alive\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.3870175e-01 6.0834162e-02 4.0429097e-04 5.9730359e-05]\n",
      "-------------\n",
      "the cubs theo epstein had a home run response to getting named the worlds greatest leader\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [8.72860670e-01 1.24584936e-01 2.19853665e-03 3.55827477e-04]\n",
      "-------------\n",
      "the worlds bestyielding stock market is set to get even better\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.2117825  0.6843799  0.09636331 0.00747429]\n",
      "-------------\n",
      "what will it take to break the twohour marathon\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00880078 0.02914538 0.2062766  0.75577724]\n",
      "-------------\n",
      "the economy of both places did not turn cashless after the government scrapped higher currency notes on nov 8\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.49382895 0.47944668 0.02464685 0.00207758]\n",
      "-------------\n",
      "watch a priest rabbi and atheist smoke weed and talk religion\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.03049964 0.48088098 0.4598057  0.02881372]\n",
      "-------------\n",
      "dad of the year turns sons drawings into professional pieces of art\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.2019325e-01 7.9226367e-02 5.2328745e-04 5.7150697e-05]\n",
      "-------------\n",
      "a new mom flew to miami to get a brazilian butt lift she didnt survive the surgery\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.10543806 0.6746989  0.20490003 0.0149631 ]\n",
      "-------------\n",
      "scientists claim breakthrough shows ageing process could be reversed\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.7732735e-01 2.2521110e-02 1.1447512e-04 3.7073267e-05]\n",
      "-------------\n",
      "the best photos from the ncaa tournament so far\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.08518392 0.47422945 0.384329   0.05625761]\n",
      "-------------\n",
      "the gig economy will finally have to give workers the rights they deserve\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [0.09295338 0.84928465 0.05610072 0.00166123]\n",
      "-------------\n",
      "theyankeecandle issues recall what you need to know\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02615401 0.17094259 0.65226114 0.15064226]\n",
      "-------------\n",
      "the top 10 universities around the world in each of eight different areas of study\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02573309 0.08650336 0.45473078 0.43303278]\n",
      "-------------\n",
      "churchs 12000 fine for helping homeless\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9896491e-01 1.0247262e-03 3.3223173e-06 6.9694001e-06]\n",
      "-------------\n",
      "cutback crew for iss launch\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.9796093e-01 2.0270175e-03 5.3533954e-06 6.6968710e-06]\n",
      "-------------\n",
      "british twitter is losing its mind over cadbury roses\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00985765 0.12306206 0.7031911  0.16388917]\n",
      "-------------\n",
      "19 hilarious jokes about christmas guaranteed to make you laugh\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.00627855 0.03143101 0.32169324 0.64059716]\n",
      "-------------\n",
      "analysis donald trump really might start a trade war\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02802327 0.21778712 0.6253327  0.12885694]\n",
      "-------------\n",
      "an extraordinarily complex and costly experiment to mimic the sun takes shape in france\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02599913 0.24748857 0.64643145 0.08008081]\n",
      "-------------\n",
      "heres what life is like in the worlds most crowded cities\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.04259324 0.2415878  0.58037037 0.13544858]\n",
      "-------------\n",
      "ecuador fines media for not publishing a story\n",
      "Actual Label 1\n",
      "Prediction Lable 0\n",
      "Prediction [9.90458846e-01 9.50193126e-03 2.68130079e-05 1.24138205e-05]\n",
      "-------------\n",
      "fatboy slim ive witnessed religious moments to love is in the air\n",
      "Actual Label 0\n",
      "Prediction Lable 1\n",
      "Prediction [0.02202093 0.13004215 0.63368154 0.21425536]\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Error Analysis\n",
    "for i in range(1000):\n",
    "    if Y_test[i] - y_pred_binary[i] != 0:\n",
    "        print(X_test[i])\n",
    "        print(\"Actual Label\",Y_test[i])\n",
    "        print(\"Prediction Lable\",y_pred_binary[i])\n",
    "        print(\"Prediction\",y_pred_onehot[i])\n",
    "        print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(test_string):\n",
    "    test_string = cleanText(test_string)\n",
    "    test = np.array([test_string])\n",
    "    test_indices = sentences_to_indices(test, word_to_index, max_len = maxLen)\n",
    "    y_pred_onehot = model.predict(test_indices)\n",
    "    y_pred_binary = onehot_to_binary(y_pred_onehot)\n",
    "    if y_pred_binary == [1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "test_string = \"US election 2020: What is the presidential transition\"\n",
    "test(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
